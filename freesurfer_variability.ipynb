{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3799187",
   "metadata": {},
   "source": [
    "# Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7574be02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was run on 2023-11-23 15:08:58 UTC +0000\n"
     ]
    }
   ],
   "source": [
    "import livingpark_utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "utils = livingpark_utils.LivingParkUtils()\n",
    "random_seed = 2\n",
    "utils.notebook_init()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03637748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was run on 2023-11-23 15:08:58 UTC +0000\n",
      "Download skipped: No missing files!\n"
     ]
    }
   ],
   "source": [
    "import livingpark_utils\n",
    "from livingpark_utils.download import ppmi\n",
    "\n",
    "utils = livingpark_utils.LivingParkUtils()\n",
    "downloader = ppmi.Downloader(utils.study_files_dir)\n",
    "\n",
    "required_files = [\n",
    "    \"Demographics.csv\",\n",
    "    \"Age_at_visit.csv\",\n",
    "    \"Primary_Clinical_Diagnosis.csv\",\n",
    "    \"Cognitive_Categorization.csv\",\n",
    "    \"Medical_Conditions_Log.csv\",\n",
    "    \"Concomitant_Medication_Log.csv\",\n",
    "    \"MDS-UPDRS_Part_III.csv\",\n",
    "    \"Participant_Status.csv\",\n",
    "    \"Socio-Economics.csv\",\n",
    "    \"Montreal_Cognitive_Assessment__MoCA_.csv\",\n",
    "    \"PD_Diagnosis_History.csv\",\n",
    "    \"LEDD_Concomitant_Medication_Log.csv\",\n",
    "]\n",
    "\n",
    "utils.notebook_init()\n",
    "utils.get_study_files(required_files, default=downloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99fa821",
   "metadata": {},
   "source": [
    "# Cohort preparation\n",
    "\n",
    "We will build a cohort using data from Parkinson's Progression Markers Initiative (PPMI). We will select patients with Parkinson's disease (PD) with (PD-MCI) and without Mild Cognitive Impairment (PD-non-MCI) as well as healthy controls (HC). The cohort will be built directly from PPMI Study Data so that it can be replicated and updated whenever necessary.\n",
    "\n",
    "We will use the LivingPark utils library to download files from the notebook. If files are already present in the notebook cache, they won't be downloaded again. Otherwise, you will need to enter your PPMI username and password. **In case you don't have a PPMI account, you can request one [here](http://ppmi-info.org).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47af397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Read data files\n",
    "\n",
    "\n",
    "# Demographics\n",
    "dem = pd.read_csv(os.path.join(utils.study_files_dir, \"Demographics.csv\"))[\n",
    "    [\"PATNO\", \"SEX\", \"BIRTHDT\"]\n",
    "]\n",
    "\n",
    "# Age at visit\n",
    "age = pd.read_csv(os.path.join(utils.study_files_dir, \"Age_at_visit.csv\"))[\n",
    "    [\"PATNO\", \"EVENT_ID\", \"AGE_AT_VISIT\"]\n",
    "]\n",
    "\n",
    "# Education\n",
    "edu = pd.read_csv(os.path.join(utils.study_files_dir, \"Socio-Economics.csv\"))[\n",
    "    [\"PATNO\", \"EDUCYRS\"]\n",
    "]\n",
    "\n",
    "# Diagnosis\n",
    "diag = pd.read_csv(\n",
    "    os.path.join(utils.study_files_dir, \"Primary_Clinical_Diagnosis.csv\")\n",
    ")[[\"PATNO\", \"EVENT_ID\", \"PRIMDIAG\", \"OTHNEURO\"]]\n",
    "\n",
    "\n",
    "# Dx status\n",
    "dx_status = pd.read_csv(os.path.join(utils.study_files_dir, \"Participant_Status.csv\"))[\n",
    "    [\"PATNO\", \"COHORT\"]\n",
    "]\n",
    "\n",
    "# PD dx history / disease duration calc\n",
    "pd_hist = pd.read_csv(os.path.join(utils.study_files_dir, \"PD_Diagnosis_History.csv\"))[\n",
    "    [\"PATNO\", \"EVENT_ID\", \"PDDXDT\"]\n",
    "]\n",
    "\n",
    "# Cognitive Categorization\n",
    "cog_cat = pd.read_csv(\n",
    "    os.path.join(utils.study_files_dir, \"Cognitive_Categorization.csv\")\n",
    ")[[\"PATNO\", \"EVENT_ID\", \"COGSTATE\"]]\n",
    "\n",
    "# UPDRS and Hoehh Yahr\n",
    "# updrs = pd.read_csv(os.path.join(utils.study_files_dir, \"MDS-UPDRS_Part_III.csv\"))[\n",
    "#     [\"PATNO\", \"EVENT_ID\", \"PDSTATE\", \"NP3TOT\", \"NHY\"]\n",
    "# ]\n",
    "\n",
    "# Clean UPDRS file. Impute missing ON/OFF values.\n",
    "# It produces MDS_UPDRS_Part_III_clean.csv file\n",
    "# from livingpark_utils.scripts import pd_status\n",
    "\n",
    "updrs = pd.read_csv(\n",
    "    os.path.join(utils.study_files_dir, \"MDS_UPDRS_Part_III_clean.csv\")\n",
    ")[[\"PATNO\", \"EVENT_ID\", \"PDSTATE\", \"NP3TOT\", \"NHY\", \"PDTRTMNT\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9877938a",
   "metadata": {},
   "source": [
    "We will also need file `MRI_info.csv` produced by another LivingPark notebook available at https://github.com/LivingPark-MRI/livingpark-utils/blob/main/livingpark_utils/notebooks/mri_metadata.ipynb. This file contains a list of T1-weighted MRI images. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from livingpark_utils.scripts import run\n",
    "from livingpark_utils.scripts import mri_metadata\n",
    "\n",
    "run.mri_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59c345d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate disease duration\n",
    "\n",
    "from dateutil.parser import parse\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "pdxhist = pd_hist[(pd_hist[\"EVENT_ID\"] == \"SC\") & pd_hist[\"PDDXDT\"].notna()]\n",
    "\n",
    "pd_dur = pd.read_csv(\n",
    "    os.path.join(utils.study_files_dir, \"MDS_UPDRS_Part_III_clean.csv\"),\n",
    "    low_memory=False,\n",
    ")[[\"PATNO\", \"EVENT_ID\", \"INFODT\"]]\n",
    "\n",
    "PDDXDT_map = dict(zip(pdxhist[\"PATNO\"].values, pdxhist[\"PDDXDT\"].values))\n",
    "pd_dur[\"PDDXDT\"] = pd_dur[\"PATNO\"].map(PDDXDT_map)\n",
    "\n",
    "pd_dur[\"PDXDUR\"] = pd_dur.apply(\n",
    "    lambda row: relativedelta(parse(row[\"INFODT\"]), parse(row[\"PDDXDT\"])).months\n",
    "    if row[\"PDDXDT\"] is not np.nan\n",
    "    else np.nan,\n",
    "    axis=1,\n",
    ")\n",
    "pd_dur.drop(labels=[\"INFODT\", \"PDDXDT\"], inplace=True, axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce51891c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EVENT_ID\n",
       "BL     2120\n",
       "V10     457\n",
       "V04     398\n",
       "V06     342\n",
       "ST       10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MRI availability\n",
    "\n",
    "mri = pd.read_csv(os.path.join(utils.study_files_dir, \"MRI_info.csv\"))\n",
    "mri[\"EVENT_ID\"] = mri[\"Visit code\"]\n",
    "mri[\"PATNO\"] = mri[\"Subject ID\"]\n",
    "mri[\"Sex\"] = mri[\"Sex\"].map({\"F\": 0, \"M\": 1})\n",
    "mri = mri.drop([\"Subject ID\", \"Visit code\", \"Visit\", \"Age\", \"Sex\"], axis=1)\n",
    "mri.groupby(\"EVENT_ID\").size().sort_values(ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7400579",
   "metadata": {},
   "source": [
    "## Pair visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edcd393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find visit pairs\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "visit2month = {\n",
    "    \"BL\": 0,\n",
    "    \"V01\": 3,\n",
    "    \"V02\": 6,\n",
    "    \"V03\": 9,\n",
    "    \"V04\": 12,\n",
    "    \"V05\": 18,\n",
    "    \"V06\": 24,\n",
    "    \"V07\": 30,\n",
    "    \"V08\": 36,\n",
    "    \"V09\": 42,\n",
    "    \"V10\": 48,\n",
    "    \"V11\": 54,\n",
    "    \"V12\": 60,\n",
    "    \"V13\": 72,\n",
    "    \"V14\": 84,\n",
    "    \"V15\": 96,\n",
    "    \"V16\": 108,\n",
    "    \"V17\": 120,\n",
    "    \"V18\": 132,\n",
    "    \"V19\": 144,\n",
    "    \"V20\": 156,\n",
    "}\n",
    "\n",
    "\n",
    "def find_visit_pairs(months: int) -> int:\n",
    "    \"\"\"Return the pairs of visits closest to each other, given a target time difference in months.\"\"\"\n",
    "\n",
    "    diff = float(\"inf\")\n",
    "    diff_hist = defaultdict(dict)\n",
    "\n",
    "    for (k, v), (k_, v_) in combinations(visit2month.items(), 2):\n",
    "        if (diff_ := abs(abs(v - v_) - months)) <= diff:\n",
    "            diff = diff_\n",
    "            diff_hist[diff][k] = k_\n",
    "\n",
    "    return diff_hist[diff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93bd9861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_cohort(df, /, *, n):\n",
    "    _df = df.drop_duplicates(subset=[\"PATNO\"])\n",
    "    n = min(_df.index.size, n)\n",
    "    return _df.sample(n=n, replace=False, random_state=1)\n",
    "    return _df[_df.index.isin(sample)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08739511",
   "metadata": {},
   "source": [
    "# Select HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0acd4170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnosis - use screening instead of baseline when PRIMDIAG is missing at baseline\n",
    "\n",
    "diag_bl = diag[diag[\"EVENT_ID\"] == \"BL\"]\n",
    "diag_other = diag[diag[\"EVENT_ID\"] != \"BL\"]\n",
    "diag_other[\"EVENT_ID\"].mask(diag_other[\"EVENT_ID\"] == \"SC\", \"BL\", inplace=True)\n",
    "\n",
    "diag_hc = pd.concat([diag_bl, diag_other])\n",
    "diag_hc = diag_hc.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e1a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge into a single df\n",
    "\n",
    "df_hc = (\n",
    "    mri.merge(diag_hc, on=[\"PATNO\", \"EVENT_ID\"])\n",
    "    .merge(age, on=[\"PATNO\", \"EVENT_ID\"], how=\"left\")\n",
    "    .merge(dem, on=[\"PATNO\"], how=\"left\")\n",
    "    .merge(dx_status, on=[\"PATNO\"], how=\"left\")  # check\n",
    "    .merge(edu, on=[\"PATNO\"], how=\"left\")\n",
    "    .merge(cog_cat, on=[\"PATNO\", \"EVENT_ID\"], how=\"left\")\n",
    "    .merge(pd_hist, on=[\"PATNO\", \"EVENT_ID\"], how=\"left\")\n",
    "    .drop_duplicates()\n",
    "    .groupby(\"PATNO\")\n",
    "    .filter(lambda g: g[\"EVENT_ID\"].nunique() > 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1be5b831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique HC subjects per visit pairs:\n",
      "BL  & V04 =  74 | Month difference: 12\n",
      "BL  & V06 =  42 | Month difference: 24\n",
      "BL  & V08 =   2 | Month difference: 36\n",
      "BL  & V10 = 114 | Month difference: 48\n",
      "V04 & V06 =  13 | Month difference: 12\n",
      "V04 & V08 =   1 | Month difference: 24\n",
      "V04 & V10 =  13 | Month difference: 36\n",
      "V06 & V08 =   2 | Month difference: 12\n",
      "V06 & V10 =  17 | Month difference: 24\n"
     ]
    }
   ],
   "source": [
    "# find how many visit pairs are available for HC group\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "events = [\"BL\", \"V04\", \"V06\", \"V08\", \"V10\"]\n",
    "\n",
    "print(\"Unique HC subjects per visit pairs:\")\n",
    "for c in combinations(events, 2):\n",
    "    v0 = set(\n",
    "        df_hc[(df_hc[\"EVENT_ID\"] == c[0]) & (df_hc[\"PRIMDIAG\"] == 17)][\"PATNO\"].values\n",
    "    )\n",
    "    v1 = set(\n",
    "        df_hc[(df_hc[\"EVENT_ID\"] == c[1]) & (df_hc[\"PRIMDIAG\"] == 17)][\"PATNO\"].values\n",
    "    )\n",
    "    if len(v0 & v1):\n",
    "        print(\n",
    "            f\"{c[0]:3} & {c[1]:3} = {len(v0 & v1):>3}\"\n",
    "            f\" | Month difference: {visit2month[c[1]] - visit2month[c[0]]}\"\n",
    "        )\n",
    "#       print(v0 & v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "214a9e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairs_hc(arg):\n",
    "\n",
    "    visit_pairs = find_visit_pairs(arg)\n",
    "    visit_df = df_hc.copy()\n",
    "    visit_df[\"NEXT_VISIT\"] = visit_df[\"EVENT_ID\"].map(visit_pairs)\n",
    "\n",
    "    visit_df = visit_df.merge(\n",
    "        visit_df.drop(\n",
    "            [\"AGE_AT_VISIT\", \"SEX\", \"NEXT_VISIT\", \"EDUCYRS\"],\n",
    "            axis=1,\n",
    "        ),\n",
    "        left_on=[\n",
    "            \"PATNO\",\n",
    "            \"NEXT_VISIT\",\n",
    "        ],\n",
    "        right_on=[\n",
    "            \"PATNO\",\n",
    "            \"EVENT_ID\",\n",
    "        ],\n",
    "        suffixes=(None, \"_NX\"),\n",
    "    ).drop_duplicates()\n",
    "\n",
    "    return visit_df.loc[(visit_df[\"PRIMDIAG\"] == 17) & (visit_df[\"PRIMDIAG_NX\"] == 17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52c667ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique HC number before selection:  107\n"
     ]
    }
   ],
   "source": [
    "# build database of all available HC\n",
    "hc_12 = pairs_hc(12)\n",
    "hc_24 = pairs_hc(24)\n",
    "hc_36 = pairs_hc(36)\n",
    "hc = pd.concat([hc_12, hc_24, hc_36], ignore_index=True)\n",
    "hc = hc.loc[hc[\"COHORT\"].isin([2, 4])]\n",
    "hc = hc.drop_duplicates(subset=[\"PATNO\"])\n",
    "hc[\"dx_group\"] = \"HC\"\n",
    "print(\"Unique HC number before selection: \", hc[\"PATNO\"].unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bd3aea",
   "metadata": {},
   "source": [
    "# Data aggregation for PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa0ccf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge into a single df for PD\n",
    "\n",
    "df = (\n",
    "    mri.merge(diag, on=[\"PATNO\", \"EVENT_ID\"])\n",
    "    .merge(age, on=[\"PATNO\", \"EVENT_ID\"], how=\"left\")\n",
    "    .merge(dem, on=[\"PATNO\"])\n",
    "    .merge(edu, on=[\"PATNO\"], how=\"left\")\n",
    "    .merge(dx_status, on=[\"PATNO\"])\n",
    "    .merge(pd_hist, on=[\"PATNO\", \"EVENT_ID\"], how=\"left\")\n",
    "    .merge(cog_cat, on=[\"PATNO\", \"EVENT_ID\"])\n",
    "    .drop_duplicates()\n",
    "    .groupby(\"PATNO\")\n",
    "    .filter(lambda g: g[\"EVENT_ID\"].nunique() > 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa928506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique PD-non-MCI subjects per visit pairs:\n",
      "BL  & V04 =  72 | Month difference: 12\n",
      "BL  & V06 =   9 | Month difference: 24\n",
      "V04 & V06 =  79 | Month difference: 12\n",
      "V04 & V10 =  58 | Month difference: 36\n",
      "V06 & V10 =  81 | Month difference: 24\n"
     ]
    }
   ],
   "source": [
    "# Pair PD-non-MCI\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "events = [\"BL\", \"V04\", \"V06\", \"V08\", \"V10\"]\n",
    "\n",
    "print(\"Unique PD-non-MCI subjects per visit pairs:\")\n",
    "for c in combinations(events, 2):\n",
    "    v0 = set(\n",
    "        df[\n",
    "            (df[\"EVENT_ID\"] == c[0])\n",
    "            & (df[\"PRIMDIAG\"] == 1)\n",
    "            & (df[\"COGSTATE\"] == 1)\n",
    "            & (df[\"COHORT\"] == 1)\n",
    "            & (df[\"OTHNEURO\"].isnull())\n",
    "        ][\"PATNO\"].values\n",
    "    )\n",
    "    v1 = set(\n",
    "        df[\n",
    "            (df[\"EVENT_ID\"] == c[1])\n",
    "            & (df[\"PRIMDIAG\"] == 1)\n",
    "            & (df[\"COGSTATE\"] == 1)\n",
    "            & (df[\"COHORT\"] == 1)\n",
    "            & (df[\"OTHNEURO\"].isnull())\n",
    "        ][\"PATNO\"].values\n",
    "    )\n",
    "    if len(v0 & v1):\n",
    "        print(\n",
    "            f\"{c[0]:3} & {c[1]:3} = {len(v0 & v1):>3}\"\n",
    "            f\" | Month difference: {visit2month[c[1]] - visit2month[c[0]]}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c777416b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique PD-MCI subjects per visit pairs:\n",
      "BL  & V04 =   7 | Month difference: 12\n",
      "BL  & V06 =   1 | Month difference: 24\n",
      "V04 & V06 =   8 | Month difference: 12\n",
      "V04 & V10 =   6 | Month difference: 36\n",
      "V06 & V10 =  15 | Month difference: 24\n"
     ]
    }
   ],
   "source": [
    "# Pair PD-MCI\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "events = [\"BL\", \"V04\", \"V06\", \"V08\", \"V10\"]\n",
    "\n",
    "print(\"Unique PD-MCI subjects per visit pairs:\")\n",
    "for c in combinations(events, 2):\n",
    "    v0 = set(\n",
    "        df[\n",
    "            (df[\"EVENT_ID\"] == c[0])\n",
    "            & (df[\"PRIMDIAG\"] == 1)\n",
    "            & (df[\"COGSTATE\"] == 2)\n",
    "            & (df[\"COHORT\"] == 1)\n",
    "            & (df[\"OTHNEURO\"].isnull())\n",
    "        ][\"PATNO\"].values\n",
    "    )\n",
    "    v1 = set(\n",
    "        df[\n",
    "            (df[\"EVENT_ID\"] == c[1])\n",
    "            & (df[\"PRIMDIAG\"] == 1)\n",
    "            & (df[\"COGSTATE\"] == 2)\n",
    "            & (df[\"COHORT\"] == 1)\n",
    "            & (df[\"OTHNEURO\"].isnull())\n",
    "        ][\"PATNO\"].values\n",
    "    )\n",
    "    if len(v0 & v1):\n",
    "        print(\n",
    "            f\"{c[0]:3} & {c[1]:3} = {len(v0 & v1):>3}\"\n",
    "            f\" | Month difference: {visit2month[c[1]] - visit2month[c[0]]}\"\n",
    "        )\n",
    "        # print(v0 & v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ae357a",
   "metadata": {},
   "source": [
    "# Select PD-MCI patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddaa552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairs_mci(arg):\n",
    "\n",
    "    visit_pairs = find_visit_pairs(arg)\n",
    "    visit_df = df.copy()\n",
    "    visit_df[\"NEXT_VISIT\"] = visit_df[\"EVENT_ID\"].map(visit_pairs)\n",
    "\n",
    "    visit_df = visit_df.merge(\n",
    "        visit_df.drop(\n",
    "            [\"AGE_AT_VISIT\", \"SEX\", \"NEXT_VISIT\", \"EDUCYRS\"],\n",
    "            axis=1,\n",
    "        ),\n",
    "        left_on=[\n",
    "            \"PATNO\",\n",
    "            \"NEXT_VISIT\",\n",
    "        ],\n",
    "        right_on=[\n",
    "            \"PATNO\",\n",
    "            \"EVENT_ID\",\n",
    "        ],\n",
    "        suffixes=(None, \"_NX\"),\n",
    "    ).drop_duplicates()\n",
    "\n",
    "    return visit_df.loc[\n",
    "        (visit_df[\"COGSTATE\"] == 2)\n",
    "        & (visit_df[\"PRIMDIAG\"] == 1)\n",
    "        & (visit_df[\"COHORT\"] == 1)\n",
    "        & (visit_df[\"OTHNEURO\"].isnull())\n",
    "        & (visit_df[\"COGSTATE_NX\"] == 2)\n",
    "        & (visit_df[\"PRIMDIAG_NX\"] == 1)\n",
    "        & (visit_df[\"COHORT_NX\"] == 1)\n",
    "        & (visit_df[\"OTHNEURO_NX\"].isnull())\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fd36b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  29  PD-MCI patients.\n"
     ]
    }
   ],
   "source": [
    "mci = pairs_mci(12)\n",
    "mci = mci.drop_duplicates(subset=[\"PATNO\"])\n",
    "\n",
    "mci_24 = pairs_mci(24)\n",
    "mci = pd.concat([mci, mci_24], ignore_index=True)\n",
    "mci = mci.drop_duplicates(subset=[\"PATNO\"])\n",
    "\n",
    "mci_36 = pairs_mci(36)\n",
    "mci = pd.concat([mci, mci_36], ignore_index=True)\n",
    "mci = mci.drop_duplicates(subset=[\"PATNO\"])\n",
    "\n",
    "mci[\"dx_group\"] = \"PD-MCI\"\n",
    "print(\"There are \", len(mci), \" PD-MCI patients.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e5f46b",
   "metadata": {},
   "source": [
    "# Select PD-non-MCI patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f248cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairs_nonmci(arg):\n",
    "\n",
    "    visit_pairs = find_visit_pairs(arg)\n",
    "    visit_df = df.copy()\n",
    "    visit_df[\"NEXT_VISIT\"] = visit_df[\"EVENT_ID\"].map(visit_pairs)\n",
    "\n",
    "    visit_df = visit_df.merge(\n",
    "        visit_df.drop(\n",
    "            [\"AGE_AT_VISIT\", \"SEX\", \"NEXT_VISIT\", \"EDUCYRS\"],\n",
    "            axis=1,\n",
    "        ),\n",
    "        left_on=[\n",
    "            \"PATNO\",\n",
    "            \"NEXT_VISIT\",\n",
    "        ],\n",
    "        right_on=[\n",
    "            \"PATNO\",\n",
    "            \"EVENT_ID\",\n",
    "        ],\n",
    "        suffixes=(None, \"_NX\"),\n",
    "    ).drop_duplicates()\n",
    "\n",
    "    return visit_df.loc[\n",
    "        (visit_df[\"COGSTATE\"] == 1)\n",
    "        & (visit_df[\"PRIMDIAG\"] == 1)\n",
    "        & (visit_df[\"COHORT\"] == 1)\n",
    "        & (visit_df[\"OTHNEURO\"].isnull())\n",
    "        & (visit_df[\"COGSTATE_NX\"] == 1)\n",
    "        & (visit_df[\"PRIMDIAG_NX\"] == 1)\n",
    "        & (visit_df[\"COHORT_NX\"] == 1)\n",
    "        & (visit_df[\"OTHNEURO_NX\"].isnull())\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18266578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  181  PD-non-MCI patients.\n"
     ]
    }
   ],
   "source": [
    "wo_mci_12 = pairs_nonmci(12)\n",
    "wo_mci_24 = pairs_nonmci(24)\n",
    "wo_mci_36 = pairs_nonmci(36)\n",
    "wo_mci_all = pd.concat([wo_mci_12, wo_mci_24, wo_mci_36], ignore_index=True)\n",
    "wo_mci_all = wo_mci_all.drop_duplicates(subset=[\"PATNO\"])\n",
    "wo_mci_all[\"dx_group\"] = \"PD-non-MCI\"\n",
    "\n",
    "print(\"There are \", len(wo_mci_all), \" PD-non-MCI patients.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e22c87c",
   "metadata": {},
   "source": [
    "## cohort to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ada001b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  317  unique subjects.\n"
     ]
    }
   ],
   "source": [
    "cohort = pd.concat([mci, wo_mci_all, hc], ignore_index=True)\n",
    "cohort = cohort.drop_duplicates(subset=[\"PATNO\"])\n",
    "print(\"There are \", len(cohort), \" unique subjects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5575715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate time difference between the visits (Duration T2-T1)\n",
    "\n",
    "cohort[\"Study Date\"] = pd.to_datetime(cohort[\"Study Date\"])\n",
    "cohort[\"Study Date_NX\"] = pd.to_datetime(cohort[\"Study Date_NX\"])\n",
    "\n",
    "\n",
    "cohort[\"durationT2_T1\"] = (\n",
    "    cohort[\"Study Date_NX\"] - cohort[\"Study Date\"]\n",
    ") / np.timedelta64(1, \"M\")\n",
    "\n",
    "cohort[\"durationT2_T1_y\"] = cohort[\"durationT2_T1\"] / 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc397d5a",
   "metadata": {},
   "source": [
    "## Descriptive statistics (computational cohort)\n",
    "\n",
    "To calculate descriptive statistics we exclude images that failed preprocessing in the next steps. PPMI's Data Usage Agreement prevents us from publicaly sharing subjects' identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d9fb349",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_stat = cohort\n",
    "cohort_stat[\"PATNO_id\"] = (\n",
    "    \"sub-\" + cohort_stat[\"PATNO\"].astype(str) + \"_ses-\" + cohort_stat[\"EVENT_ID\"]\n",
    ")\n",
    "\n",
    "# exclude images due to the preprocessing failure\n",
    "failed = pd.read_csv(\"failed.csv\")\n",
    "\n",
    "for i in failed[\"PATNO_id\"]:\n",
    "    cohort_stat = cohort_stat[cohort_stat[\"PATNO_id\"].str.contains(f\"{i}\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9183b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "\n",
    "import rich\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "\n",
    "def cohort_summary(*, hc, nc, mci, title):\n",
    "    def gen_row(D, *, agg, col, f=\"4.1f\", sep=\" ± \"):\n",
    "        if not isinstance(agg, str) and isinstance(agg, Iterable):\n",
    "            return [f\"{sep}\".join([f\"{d.loc[a][col]:{f}}\" for a in agg]) for d in D]\n",
    "        else:\n",
    "            return [f\"{d.loc[agg][col]:{f}}\" for d in D]\n",
    "\n",
    "    def gender_ratio(df):\n",
    "        male_count = df[df[\"SEX\"] == 1][\"PATNO\"].nunique()\n",
    "        return f\"{male_count:.0f}, {male_count / df['PATNO'].nunique() * 100:.1f}%\"\n",
    "\n",
    "    D = [hc.describe(), nc.describe(), mci.describe()]\n",
    "\n",
    "    table = Table(title=title, box=rich.box.SIMPLE_HEAVY, show_footer=True)\n",
    "\n",
    "    table.add_column(\"Subject groups\", footer=\"Values expressed as mean ± SD.\")\n",
    "    table.add_column(\"HC\")\n",
    "    table.add_column(\"PD-non-MCI\")\n",
    "    table.add_column(\"PD-MCI\")\n",
    "\n",
    "    table.add_row(\"n\", *gen_row(D, agg=\"count\", col=\"PATNO\", f=\".0f\"))\n",
    "    table.add_row(\"Age (y)\", *gen_row(D, agg=[\"mean\", \"std\"], col=\"AGE_AT_VISIT\"))\n",
    "    table.add_row(\n",
    "        \"Age range\", *gen_row(D, agg=[\"min\", \"max\"], col=\"AGE_AT_VISIT\", sep=\" - \")\n",
    "    )\n",
    "    table.add_row(\n",
    "        \"Gender (male, %)\", gender_ratio(hc), gender_ratio(nc), gender_ratio(mci)\n",
    "    )\n",
    "    table.add_row(\"Education (y)\", *gen_row(D, agg=[\"mean\", \"std\"], col=\"EDUCYRS\"))\n",
    "\n",
    "    console = Console()\n",
    "    console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1145137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                  Demographic and clinical characteristics                  </span>\n",
       "                                                                            \n",
       " <span style=\"font-weight: bold\"> Subject groups                 </span> <span style=\"font-weight: bold\"> HC          </span> <span style=\"font-weight: bold\"> PD-non-MCI  </span> <span style=\"font-weight: bold\"> PD-MCI      </span> \n",
       " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
       "  n                                106           180           29           \n",
       "  Age (y)                          60.5 ± 10.2   61.7 ±  9.6   67.7 ±  7.7  \n",
       "  Age range                        30.6 - 84.3   36.3 - 83.3   49.9 - 80.5  \n",
       "  Gender (male, %)                 58, 54.7%     118, 65.6%    22, 75.9%    \n",
       "  Education (y)                    16.6 ±  3.3   15.9 ±  2.9   15.1 ±  3.5  \n",
       " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
       " <span style=\"font-weight: bold\"> Values expressed as mean ± SD. </span> <span style=\"font-weight: bold\">             </span> <span style=\"font-weight: bold\">             </span> <span style=\"font-weight: bold\">             </span> \n",
       "                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                  Demographic and clinical characteristics                  \u001b[0m\n",
       "                                                                            \n",
       " \u001b[1m \u001b[0m\u001b[1mSubject groups                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mHC         \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mPD-non-MCI \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mPD-MCI     \u001b[0m\u001b[1m \u001b[0m \n",
       " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
       "  n                                106           180           29           \n",
       "  Age (y)                          60.5 ± 10.2   61.7 ±  9.6   67.7 ±  7.7  \n",
       "  Age range                        30.6 - 84.3   36.3 - 83.3   49.9 - 80.5  \n",
       "  Gender (male, %)                 58, 54.7%     118, 65.6%    22, 75.9%    \n",
       "  Education (y)                    16.6 ±  3.3   15.9 ±  2.9   15.1 ±  3.5  \n",
       " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
       " \u001b[1m \u001b[0m\u001b[1mValues expressed as mean ± SD.\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m \n",
       "                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hc = cohort_stat[cohort_stat[\"dx_group\"] == \"HC\"]\n",
    "nc = cohort_stat[cohort_stat[\"dx_group\"] == \"PD-non-MCI\"]\n",
    "mci = cohort_stat[cohort_stat[\"dx_group\"] == \"PD-MCI\"]\n",
    "\n",
    "cohort_summary(\n",
    "    hc=hc,\n",
    "    nc=nc,\n",
    "    mci=mci,\n",
    "    title=\"Demographic and clinical characteristics\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6100b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value for group difference (PD vs HC) in age is  0.07495206665697139 , in education is  0.04269231747377141\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind, chi2_contingency\n",
    "\n",
    "pd_both = pd.concat([nc, mci])\n",
    "\n",
    "[t_age, p_age] = ttest_ind(pd_both[\"AGE_AT_VISIT\"], hc[\"AGE_AT_VISIT\"])\n",
    "[t_edu, p_edu] = ttest_ind(pd_both[\"EDUCYRS\"], hc[\"EDUCYRS\"], nan_policy=\"omit\")\n",
    "\n",
    "print(\n",
    "    \"p-value for group difference (PD vs HC) in age is \",\n",
    "    p_age,\n",
    "    \", in education is \",\n",
    "    p_edu,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8101a53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0239901664193,\n",
       " 0.04485746687707696,\n",
       " 1,\n",
       " array([[ 77.62857143, 131.37142857],\n",
       "        [ 39.37142857,  66.62857143]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test difference in sex frequency between PD and HC groups\n",
    "\n",
    "a1 = pd_both[\"SEX\"].value_counts()[0]\n",
    "a2 = pd_both[\"SEX\"].value_counts()[1]\n",
    "b1 = hc[\"SEX\"].value_counts()[0]\n",
    "b2 = hc[\"SEX\"].value_counts()[1]\n",
    "\n",
    "obs = np.array([[a1, a2], [b1, b2]])\n",
    "chi2_contingency(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f696af57",
   "metadata": {},
   "source": [
    "## Define PD cohort with UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "191a3b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge into a single dataframe\n",
    "\n",
    "df_clinical = (\n",
    "    mri.merge(diag, on=[\"PATNO\", \"EVENT_ID\"])\n",
    "    .merge(age, on=[\"PATNO\", \"EVENT_ID\"], how=\"left\")\n",
    "    .merge(dem, on=[\"PATNO\"])\n",
    "    .merge(edu, on=[\"PATNO\"], how=\"left\")\n",
    "    .merge(dx_status, on=[\"PATNO\"])\n",
    "    .merge(pd_hist, on=[\"PATNO\", \"EVENT_ID\"], how=\"left\")\n",
    "    .merge(cog_cat, on=[\"PATNO\", \"EVENT_ID\"])\n",
    "    .merge(updrs, on=[\"PATNO\", \"EVENT_ID\"])  #\n",
    "    .drop_duplicates()\n",
    "    .groupby(\"PATNO\")\n",
    "    .filter(lambda g: g[\"EVENT_ID\"].nunique() > 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b55e41d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find PD-non-MCI with UPDRS score\n",
    "\n",
    "\n",
    "def pairs_nonmci(arg):\n",
    "\n",
    "    visit_pairs = find_visit_pairs(arg)\n",
    "    visit_df = df_clinical.copy()\n",
    "    visit_df[\"NEXT_VISIT\"] = visit_df[\"EVENT_ID\"].map(visit_pairs)\n",
    "\n",
    "    visit_df = visit_df.merge(\n",
    "        visit_df.drop(\n",
    "            [\"AGE_AT_VISIT\", \"SEX\", \"NEXT_VISIT\", \"EDUCYRS\"],\n",
    "            axis=1,\n",
    "        ),\n",
    "        left_on=[\n",
    "            \"PATNO\",\n",
    "            \"NEXT_VISIT\",\n",
    "        ],\n",
    "        right_on=[\n",
    "            \"PATNO\",\n",
    "            \"EVENT_ID\",\n",
    "        ],\n",
    "        suffixes=(None, \"_NX\"),\n",
    "    ).drop_duplicates()\n",
    "\n",
    "    return visit_df.loc[\n",
    "        (visit_df[\"COGSTATE\"] == 1)\n",
    "        & (visit_df[\"PRIMDIAG\"] == 1)\n",
    "        & (visit_df[\"COHORT\"] == 1)\n",
    "        & (visit_df[\"OTHNEURO\"].isnull())\n",
    "        & (visit_df[\"PDSTATE\"] == \"OFF\")\n",
    "        & (visit_df[\"COGSTATE_NX\"] == 1)\n",
    "        & (visit_df[\"PRIMDIAG_NX\"] == 1)\n",
    "        & (visit_df[\"COHORT_NX\"] == 1)\n",
    "        & (visit_df[\"OTHNEURO_NX\"].isnull())\n",
    "        & (visit_df[\"PDSTATE_NX\"] == \"OFF\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91395a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  125  PD-non-MCI patients.\n"
     ]
    }
   ],
   "source": [
    "wo_mci_12 = pairs_nonmci(12)\n",
    "wo_mci_24 = pairs_nonmci(24)\n",
    "wo_mci_36 = pairs_nonmci(36)\n",
    "wo_mci_all = pd.concat([wo_mci_12, wo_mci_24, wo_mci_36], ignore_index=True)\n",
    "wo_mci_all = wo_mci_all.drop_duplicates(subset=[\"PATNO\"])\n",
    "wo_mci_all[\"dx_group\"] = \"PD-non-MCI\"\n",
    "\n",
    "wo_mci_all = wo_mci_all[~wo_mci_all[\"NP3TOT\"].isna()]\n",
    "wo_mci_all = wo_mci_all[~wo_mci_all[\"NP3TOT_NX\"].isna()]\n",
    "\n",
    "print(\"There are \", len(wo_mci_all), \" PD-non-MCI patients.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df2f24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the time difference between the visits\n",
    "pd_clinical = wo_mci_all\n",
    "\n",
    "pd_clinical[\"Study Date\"] = pd.to_datetime(pd_clinical[\"Study Date\"])\n",
    "pd_clinical[\"Study Date_NX\"] = pd.to_datetime(pd_clinical[\"Study Date_NX\"])\n",
    "\n",
    "pd_clinical[\"durationT2_T1\"] = (\n",
    "    pd_clinical[\"Study Date_NX\"] - pd_clinical[\"Study Date\"]\n",
    ") / np.timedelta64(1, \"M\")\n",
    "\n",
    "pd_clinical[\"durationT2_T1_y\"] = pd_clinical[\"durationT2_T1\"] / 12\n",
    "\n",
    "# visit ID\n",
    "pd_clinical[\"PATNO_id\"] = (\n",
    "    \"sub-\" + pd_clinical[\"PATNO\"].astype(str) + \"_ses-\" + pd_clinical[\"EVENT_ID\"]\n",
    ")\n",
    "\n",
    "# calculate the change of UPDRS score\n",
    "pd_clinical[\"NP3TOT_change\"] = pd_clinical[\"NP3TOT\"] - pd_clinical[\"NP3TOT_NX\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25ca14c",
   "metadata": {},
   "source": [
    "## Descriptive statistics (clinical cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dddeda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "\n",
    "import rich\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "\n",
    "def cohort_summary(*, hc, nc, title):\n",
    "    def gen_row(D, *, agg, col, f=\"4.1f\", sep=\" ± \"):\n",
    "        if not isinstance(agg, str) and isinstance(agg, Iterable):\n",
    "            return [f\"{sep}\".join([f\"{d.loc[a][col]:{f}}\" for a in agg]) for d in D]\n",
    "        else:\n",
    "            return [f\"{d.loc[agg][col]:{f}}\" for d in D]\n",
    "\n",
    "    def gender_ratio(df):\n",
    "        male_count = df[df[\"SEX\"] == 1][\"PATNO\"].nunique()\n",
    "        return f\"{male_count:.0f}, {male_count / df['PATNO'].nunique() * 100:.1f}%\"\n",
    "\n",
    "    D = [hc.describe(), nc.describe()]\n",
    "\n",
    "    table = Table(title=title, box=rich.box.SIMPLE_HEAVY, show_footer=True)\n",
    "\n",
    "    table.add_column(\"Subject groups\", footer=\"Values expressed as mean ± SD.\")\n",
    "    table.add_column(\"HC\")\n",
    "    table.add_column(\"PD-non-MCI\")\n",
    "    # table.add_column(\"[italic]p\")  # TODO\n",
    "\n",
    "    table.add_row(\"n\", *gen_row(D, agg=\"count\", col=\"PATNO\", f=\".0f\"))\n",
    "    table.add_row(\"Age (y)\", *gen_row(D, agg=[\"mean\", \"std\"], col=\"AGE_AT_VISIT\"))\n",
    "    table.add_row(\n",
    "        \"Age range\", *gen_row(D, agg=[\"min\", \"max\"], col=\"AGE_AT_VISIT\", sep=\" - \")\n",
    "    )\n",
    "    table.add_row(\"Gender (male, %)\", gender_ratio(hc), gender_ratio(nc))\n",
    "    table.add_row(\"Education (y)\", *gen_row(D, agg=[\"mean\", \"std\"], col=\"EDUCYRS\"))\n",
    "    table.add_row(\n",
    "        \"UPDRS III OFF baseline\", \"\", *gen_row(D[1:], agg=[\"mean\", \"std\"], col=\"NP3TOT\")\n",
    "    )\n",
    "    table.add_row(\n",
    "        \"UPDRS III OFF follow-up\",\n",
    "        \"\",\n",
    "        *gen_row(D[1:], agg=[\"mean\", \"std\"], col=\"NP3TOT_NX\"),\n",
    "    )\n",
    "    table.add_row(\n",
    "        \"Duration T2 - T1 (y)\", *gen_row(D, agg=[\"mean\", \"std\"], col=\"durationT2_T1_y\")\n",
    "    )\n",
    "\n",
    "    console = Console()\n",
    "    console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2027592f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">           Demographic and clinical characteristics           </span>\n",
       "                                                              \n",
       " <span style=\"font-weight: bold\"> Subject groups                 </span> <span style=\"font-weight: bold\"> HC          </span> <span style=\"font-weight: bold\"> PD-non-MCI  </span> \n",
       " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
       "  n                                106           125          \n",
       "  Age (y)                          60.5 ± 10.2   61.1 ±  9.3  \n",
       "  Age range                        30.6 - 84.3   39.2 - 83.3  \n",
       "  Gender (male, %)                 58, 54.7%     84, 67.2%    \n",
       "  Education (y)                    16.6 ±  3.3   16.1 ±  3.0  \n",
       "  UPDRS III OFF baseline                         23.8 ± 10.2  \n",
       "  UPDRS III OFF follow-up                        26.3 ± 11.6  \n",
       "  Duration T2 - T1 (y)              1.4 ±  0.5    1.4 ±  0.7  \n",
       " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
       " <span style=\"font-weight: bold\"> Values expressed as mean ± SD. </span> <span style=\"font-weight: bold\">             </span> <span style=\"font-weight: bold\">             </span> \n",
       "                                                              \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m           Demographic and clinical characteristics           \u001b[0m\n",
       "                                                              \n",
       " \u001b[1m \u001b[0m\u001b[1mSubject groups                \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mHC         \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mPD-non-MCI \u001b[0m\u001b[1m \u001b[0m \n",
       " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
       "  n                                106           125          \n",
       "  Age (y)                          60.5 ± 10.2   61.1 ±  9.3  \n",
       "  Age range                        30.6 - 84.3   39.2 - 83.3  \n",
       "  Gender (male, %)                 58, 54.7%     84, 67.2%    \n",
       "  Education (y)                    16.6 ±  3.3   16.1 ±  3.0  \n",
       "  UPDRS III OFF baseline                         23.8 ± 10.2  \n",
       "  UPDRS III OFF follow-up                        26.3 ± 11.6  \n",
       "  Duration T2 - T1 (y)              1.4 ±  0.5    1.4 ±  0.7  \n",
       " ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \n",
       " \u001b[1m \u001b[0m\u001b[1mValues expressed as mean ± SD.\u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m \n",
       "                                                              \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd_nonmci_clinical = pd_clinical[pd_clinical[\"dx_group\"] == \"PD-non-MCI\"]\n",
    "\n",
    "cohort_summary(\n",
    "    hc=hc,\n",
    "    nc=pd_nonmci_clinical,\n",
    "    title=\"Demographic and clinical characteristics\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f2b151a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value for group difference (PD vs HC) in age is  0.6256727892248035 , in education is  0.29257700905001893  in time difference between the two visits  0.4919926562609551\n"
     ]
    }
   ],
   "source": [
    "[t_age, p_age] = ttest_ind(pd_nonmci_clinical[\"AGE_AT_VISIT\"], hc[\"AGE_AT_VISIT\"])\n",
    "[t_edu, p_edu] = ttest_ind(\n",
    "    pd_nonmci_clinical[\"EDUCYRS\"], hc[\"EDUCYRS\"], nan_policy=\"omit\"\n",
    ")\n",
    "[t_dur, p_dur] = ttest_ind(pd_nonmci_clinical[\"durationT2_T1_y\"], hc[\"durationT2_T1_y\"])\n",
    "\n",
    "print(\n",
    "    \"p-value for group difference (PD vs HC) in age is \",\n",
    "    p_age,\n",
    "    \", in education is \",\n",
    "    p_edu,\n",
    "    \" in time difference between the two visits \",\n",
    "    p_dur,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb9086d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.2652222840967777,\n",
       " 0.07076343181983659,\n",
       " 1,\n",
       " array([[48.16017316, 76.83982684],\n",
       "        [40.83982684, 65.16017316]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test difference in sex frequency between PD and HC groups\n",
    "\n",
    "a1 = pd_nonmci_clinical[\"SEX\"].value_counts()[0]\n",
    "a2 = pd_nonmci_clinical[\"SEX\"].value_counts()[1]\n",
    "b1 = hc[\"SEX\"].value_counts()[0]\n",
    "b2 = hc[\"SEX\"].value_counts()[1]\n",
    "\n",
    "obs = np.array([[a1, a2], [b1, b2]])\n",
    "chi2_contingency(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5151a3a",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df1d411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_visit = cohort\n",
    "\n",
    "second_visit = first_visit\n",
    "second_visit = second_visit.drop([\"Description\", \"EVENT_ID\"], axis=1)\n",
    "second_visit.rename(\n",
    "    columns={\"Description_NX\": \"Description\", \"EVENT_ID_NX\": \"EVENT_ID\"}, inplace=True\n",
    ")\n",
    "\n",
    "download_data = first_visit.append(second_visit)\n",
    "\n",
    "download_data[\"PATNO_id\"] = (\n",
    "    \"sub-\" + download_data[\"PATNO\"].astype(str) + \"_ses-\" + download_data[\"EVENT_ID\"]\n",
    ")\n",
    "\n",
    "# download_data.to_csv('download_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750fa7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.download_missing_nifti_files(download_data, link_in_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6241cb7e",
   "metadata": {},
   "source": [
    "We will compare PD cohorts from the computational stage and clinical (longitudinal) stage of analyses. Clinical sample is a subsample of the computational stample (i.e., no new subjects are added). However, there might be a difference which visit is considered as baseline or follow-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbefb3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_visit_clin = pd_clinical\n",
    "\n",
    "second_visit_clin = first_visit_clin\n",
    "second_visit_clin = second_visit_clin.drop([\"Description\", \"EVENT_ID\"], axis=1)\n",
    "second_visit_clin.rename(\n",
    "    columns={\"Description_NX\": \"Description\", \"EVENT_ID_NX\": \"EVENT_ID\"}, inplace=True\n",
    ")\n",
    "\n",
    "visit_clin = first_visit_clin.append(second_visit_clin)\n",
    "\n",
    "visit_clin[\"PATNO_id\"] = (\n",
    "    \"sub-\" + visit_clin[\"PATNO\"].astype(str) + \"_ses-\" + visit_clin[\"EVENT_ID\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ae27c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if there are any new images in the clinical sample\n",
    "\n",
    "visit_clin_pat = visit_clin[[\"PATNO\", \"PATNO_id\"]]\n",
    "download_data_pat = download_data[[\"PATNO\", \"PATNO_id\"]]\n",
    "\n",
    "test = visit_clin_pat.merge(download_data_pat)\n",
    "df_diff = pd.concat([visit_clin_pat, test]).drop_duplicates(keep=False)\n",
    "\n",
    "len(visit_clin_pat.merge(download_data_pat)) == len(visit_clin_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf24fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download missing images in clinical stage\n",
    "\n",
    "visit_clin_download = pd.read_csv(\"clinical_diff.csv\")\n",
    "\n",
    "utils.download_missing_nifti_files(visit_clin_download, link_in_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccac72dc",
   "metadata": {},
   "source": [
    "# Image preprocessing\n",
    "\n",
    "Data is preprocessed using Freesurfer's recon-all.\n",
    "\n",
    "Analyses were performed on Compute Canada servers (Advanced Research Computing facilities provided by the Compute Canada Federation). If you don't have Compute Canada account you may be able to request one [here](https://ccdb.computecanada.ca/security/login).\n",
    "\n",
    "Otherwise, please use any other available server or your local machine to run the analyses. You may need to adjust the following code depending on the method you use.\n",
    "\n",
    "<a href=https://github.com/boutiques> Boutiques</a> is used to manage Freesurfer's functions within a container. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db62232",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext slurm_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03bf337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df with all timepoints as json\n",
    "\n",
    "import json\n",
    "\n",
    "download_data[\"PATNO_id\"] = (\n",
    "    \"sub-\" + download_data[\"PATNO\"].astype(str) + \"_ses-\" + download_data[\"EVENT_ID\"]\n",
    ")\n",
    "\n",
    "data_to_process = download_data.reset_index()\n",
    "small_df = data_to_process[[\"PATNO_id\", \"File name\"]]\n",
    "json_data = small_df.to_json()\n",
    "meta = json.loads(json_data)\n",
    "with open(\"json_data.json\", \"w\") as fout:\n",
    "    json.dump(meta, fout, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50804412",
   "metadata": {},
   "source": [
    "## Step 1 - preprocess all images cross-sectionally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb15275",
   "metadata": {},
   "source": [
    "## Freesurfer 5 - preprocessing step 1 - cross-sectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c668c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS5.py\n",
    "\n",
    "# save proprocessing script to submit jobs to the server later \n",
    "# copy your FreeSurfer license to FS_license/license.txt or update the license path below\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7738457\"\n",
    "from boutiques.descriptor2func import function\n",
    "#bosh([\"exec\", \"prepare\", zid])\n",
    "freesurfer = function(zid)\n",
    "\n",
    "task_id = str(os.environ[\"SLURM_ARRAY_TASK_ID\"])\n",
    "license = str(os.environ[\"FS_LICENSE\"]) \n",
    "\n",
    "with open('json_data.json') as fin:\n",
    "    subject_map = json.load(fin)\n",
    "\n",
    "    \n",
    "out_fs = freesurfer('-v', f'{license}:/usr/local/freesurfer/license.txt',\n",
    "                    '--imagepath', 'ansokol-freesurfer_5.3.simg',\n",
    "                                        input=subject_map[\"File name\"][task_id], qcache_flag=True,\n",
    "                                        subjid=str(subject_map[\"PATNO_id\"][task_id]),\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a59a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch --array=0-633\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS5_preproc\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS5_preproc.%a.out\n",
    "#SBATCH --error=logs/FS5_preproc.%a.err\n",
    "#SBATCH --time=10:0:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "export FS_LICENSE=$(realpath FS_licence/license.txt)\n",
    "python preprocess_FS5.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea96880",
   "metadata": {},
   "source": [
    "## Freesurfer 6 - preprocessing step 1 - cross-sectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02320114",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS6.py\n",
    "\n",
    "# save proprocessing script to submit jobs to the server later \n",
    "# copy your FreeSurfer license to FS_license/license.txt or update the license path below\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7542266\"\n",
    "from boutiques.descriptor2func import function\n",
    "#bosh([\"exec\", \"prepare\", zid])\n",
    "freesurfer = function(zid)\n",
    "\n",
    "task_id = str(os.environ[\"SLURM_ARRAY_TASK_ID\"])\n",
    "\n",
    "with open('json_data.json') as fin:\n",
    "    subject_map = json.load(fin)\n",
    "\n",
    "    \n",
    "out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_6.0.1.simg',\n",
    "                                        input=subject_map[\"File name\"][task_id], qcache_flag=True,\n",
    "                                        license=\"FS_license/license.txt\",\n",
    "                                        subjid=str(subject_map[\"PATNO_id\"][task_id]),\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb7c4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch --array=0-633\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS6_preproc\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS6_preproc.%a.out\n",
    "#SBATCH --error=logs/FS6_preproc.%a.err\n",
    "#SBATCH --time=10:0:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "\n",
    "python preprocess_FS6.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ef0258",
   "metadata": {},
   "source": [
    "## Freesurfer 7 - preprocessing step 1 - cross-sectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d6a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS7.py\n",
    "\n",
    "# save proprocessing script to submit jobs to the server later \n",
    "# copy your FreeSurfer license to FS_license/license.txt or update the license path below\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7545769\"\n",
    "from boutiques.descriptor2func import function\n",
    "#bosh([\"exec\", \"prepare\", zid])\n",
    "freesurfer = function(zid)\n",
    "\n",
    "task_id = str(os.environ[\"SLURM_ARRAY_TASK_ID\"])\n",
    "\n",
    "with open('json_data.json') as fin:\n",
    "    subject_map = json.load(fin)\n",
    "\n",
    "    \n",
    "out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_7.3.2.simg',\n",
    "                                        input=subject_map[\"File name\"][task_id], qcache_flag=True,\n",
    "                                        license=\"FS_license/license.txt\",\n",
    "                                        subjid=str(subject_map[\"PATNO_id\"][task_id]),\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch --array=0-633\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS7_preproc\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS7_preproc.%a.out\n",
    "#SBATCH --error=logs/FS7_preproc.%a.err\n",
    "#SBATCH --time=10:0:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "\n",
    "python preprocess_FS7.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fd8767",
   "metadata": {},
   "source": [
    "# Longitudinal preprocessing\n",
    "\n",
    "\n",
    "Data from the clinical cohort are preprocessed using longitudinal stream implemented in Freesurfer. <a href=https://surfer.nmr.mgh.harvard.edu/fswiki/LongitudinalProcessing> Click here for details.</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f503b161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine HC + PD UPDRS cohorts\n",
    "\n",
    "hc_only = cohort[cohort[\"dx_group\"] == \"HC\"]\n",
    "\n",
    "stage_two = pd.concat([pd_clinical, hc_only])\n",
    "\n",
    "# get IDs for the first and second visit\n",
    "stage_two[\"first_visit\"] = (\n",
    "    \"sub-\" + stage_two[\"PATNO\"].astype(str) + \"_ses-\" + stage_two[\"EVENT_ID\"]\n",
    ")\n",
    "stage_two[\"second_visit\"] = (\n",
    "    \"sub-\" + stage_two[\"PATNO\"].astype(str) + \"_ses-\" + stage_two[\"NEXT_VISIT\"]\n",
    ")\n",
    "\n",
    "# exclude failed images\n",
    "failed_long = pd.read_csv(\"failed_long.csv\")\n",
    "\n",
    "for i in failed_long[\"PATNO\"]:\n",
    "    stage_two = stage_two[stage_two[\"PATNO\"].astype(str).str.contains(f\"{i}\") == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d479af",
   "metadata": {},
   "source": [
    "## Freesurfer 5 - preprocessing step 2 - base template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caa32a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df with a single input for each subject as json\n",
    "# double check if the visit pairs are correct!\n",
    "\n",
    "import json\n",
    "\n",
    "data_to_process = stage_two\n",
    "data_to_process = data_to_process.reset_index()\n",
    "data_to_process[\"PATNO\"] = data_to_process[\"PATNO\"].astype(str)\n",
    "data_to_process[\"PATNO_base\"] = \"sub-\" + data_to_process[\"PATNO\"] + \"_base\"\n",
    "small_df = data_to_process[[\"first_visit\", \"second_visit\", \"PATNO_base\"]]\n",
    "json_data = small_df.to_json()\n",
    "meta = json.loads(json_data)\n",
    "with open(\"json_data_base.json\", \"w\") as fout:\n",
    "    json.dump(meta, fout, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56300bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS5_base.py\n",
    "\n",
    "# Step 2. create an unbiased template from all time points for each subject and process it with recon-all:\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7868966\"\n",
    "from boutiques.descriptor2func import function\n",
    "#bosh([\"exec\", \"prepare\", zid])\n",
    "freesurfer = function(zid)\n",
    "\n",
    "task_id = str(os.environ[\"SLURM_ARRAY_TASK_ID\"])\n",
    "license = str(os.environ[\"FS_LICENSE\"]) \n",
    "\n",
    "with open('json_data_base.json') as fin:\n",
    "    subject_map = json.load(fin)\n",
    "\n",
    "    \n",
    "    \n",
    "out_fs = freesurfer('-v', f'{license}:/usr/local/freesurfer/license.txt',\n",
    "                    '--imagepath', 'ansokol-freesurfer_5.3.simg',\n",
    "                                        tp1=subject_map[\"first_visit\"][task_id],\n",
    "                                        tp2=subject_map[\"second_visit\"][task_id],\n",
    "                                        outputdir=subject_map[\"PATNO_base\"][task_id],\n",
    "                                       )\n",
    "print(out_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef5344",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch --array=0-249\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS5_base\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS5_preproc_base.%a.out\n",
    "#SBATCH --error=logs/FS5_preproc_base.%a.err\n",
    "#SBATCH --time=10:0:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "export FS_LICENSE=$(realpath FS_licence/license.txt)\n",
    "python preprocess_FS5_base.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b57cda",
   "metadata": {},
   "source": [
    "## Freesurfer 5 - preprocessing step 3 - longitudinally processed timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fee9c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save json fine for longitudinal processing\n",
    "# first arg = all timepoints, second arg = base directory\n",
    "# double check if the visit and base are are correct\n",
    "\n",
    "df_long1 = pd.DataFrame(small_df).rename(columns={\"first_visit\": \"visit\"})\n",
    "df_long2 = pd.DataFrame(small_df).rename(columns={\"second_visit\": \"visit\"})\n",
    "df_both = [df_long1, df_long2]\n",
    "df_long = pd.concat(df_both, ignore_index=True)\n",
    "df_long = df_long[[\"visit\", \"PATNO_base\"]]\n",
    "json_data = df_long.to_json()\n",
    "meta = json.loads(json_data)\n",
    "with open(\"json_data_long.json\", \"w\") as fout:\n",
    "    json.dump(meta, fout, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80edd71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS5_long.py\n",
    "\n",
    "# Step 3. \"-long\" longitudinally process all timepoints (recon-all -long):\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7884225\"\n",
    "from boutiques.descriptor2func import function\n",
    "#bosh([\"exec\", \"prepare\", zid])\n",
    "freesurfer = function(zid)\n",
    "\n",
    "task_id = str(os.environ[\"SLURM_ARRAY_TASK_ID\"])\n",
    "license = str(os.environ[\"FS_LICENSE\"]) \n",
    "\n",
    "with open('json_data_long.json') as fin:\n",
    "    subject_map = json.load(fin)\n",
    "\n",
    "out_fs = freesurfer('-v', f'{license}:/usr/local/freesurfer/license.txt',\n",
    "                    '--imagepath', 'ansokol-freesurfer_5.3.simg',\n",
    "                                        tp=subject_map[\"visit\"][task_id],\n",
    "                                        base=subject_map[\"PATNO_base\"][task_id]\n",
    "                                       )\n",
    "\n",
    "\n",
    "print(out_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714a2e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch --array=0-495\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS5_long\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS5_preproc_long.%a.out\n",
    "#SBATCH --error=logs/FS5_preproc_long.%a.err\n",
    "#SBATCH --time=10:0:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "export FS_LICENSE=$(realpath FS_licence/license.txt)\n",
    "python preprocess_FS5_long.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d18a023",
   "metadata": {},
   "source": [
    "## Freesurfer 5 - preprocessing step 4 - Qcache¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1c759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS5_long_qcache.py\n",
    "\n",
    "# save proprocessing script to submit jobs to the server later \n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7884255\"\n",
    "from boutiques.descriptor2func import function\n",
    "#bosh([\"exec\", \"prepare\", zid])\n",
    "freesurfer = function(zid)\n",
    "\n",
    "task_id = str(os.environ[\"SLURM_ARRAY_TASK_ID\"])\n",
    "license = str(os.environ[\"FS_LICENSE\"]) \n",
    "\n",
    "with open('json_data_long.json') as fin:\n",
    "    subject_map = json.load(fin)\n",
    "\n",
    "    \n",
    "out_fs = freesurfer('-v', f'{license}:/usr/local/freesurfer/license.txt',\n",
    "                    '--imagepath', 'ansokol-freesurfer_5.3.simg',\n",
    "                                        tp=subject_map[\"visit\"][task_id],\n",
    "                                        base=subject_map[\"PATNO_base\"][task_id],\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f278eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch --array=0-495\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS5_longQcache\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS5_preproc_longQcache.%a.out\n",
    "#SBATCH --error=logs/FS5_preproc_longQcache.%a.err\n",
    "#SBATCH --time=2:0:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "export FS_LICENSE=$(realpath FS_licence/license.txt)\n",
    "python preprocess_FS5_long_qcache.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f31189",
   "metadata": {},
   "source": [
    "## FS5 - Prepare the vertex data with long_mris_slopes for longitudinal two stage model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f468266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create longitudinal QDEC table\n",
    "\n",
    "stage_two[\"PATNO_base\"] = \"sub-\" + stage_two[\"PATNO\"].astype(str) + \"_base\"\n",
    "\n",
    "df_1 = stage_two[[\"first_visit\", \"PATNO_base\", \"durationT2_T1_y\", \"dx_group\"]]\n",
    "df_1.rename(columns={\"first_visit\": \"visit\"}, inplace=True)\n",
    "df_2 = stage_two[[\"second_visit\", \"PATNO_base\", \"durationT2_T1_y\", \"dx_group\"]]\n",
    "df_2.rename(columns={\"second_visit\": \"visit\"}, inplace=True)\n",
    "\n",
    "df_all = [df_1, df_2]\n",
    "df_all = pd.concat(df_all, ignore_index=True)\n",
    "df_all = df_all.sort_values(\"visit\")\n",
    "df_all = df_all.reset_index()\n",
    "\n",
    "qdec_table = df_all\n",
    "\n",
    "qdec_table[\"fsid\"] = qdec_table[\"visit\"]\n",
    "qdec_table[\"fsid-base\"] = qdec_table[\"PATNO_base\"]\n",
    "qdec_table[\"years\"] = np.where(\n",
    "    qdec_table.index % 2 == 0, 0, qdec_table[\"durationT2_T1_y\"]\n",
    ")\n",
    "qdec_table = qdec_table[[\"fsid\", \"fsid-base\", \"years\", \"dx_group\"]]\n",
    "\n",
    "qdec_table.to_csv(\"qdec_long_groups.dat\", sep=\" \", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ca8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS5_long_mris_slopes.py\n",
    "\n",
    "# Prepare the data with long_mris_slopes for longitudinal two stage model\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7893178\"\n",
    "from boutiques.descriptor2func import function\n",
    "#bosh([\"exec\", \"prepare\", zid])\n",
    "freesurfer = function(zid)\n",
    "\n",
    "license = str(os.environ[\"FS_LICENSE\"]) \n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    out_fs = freesurfer('-v', f'{license}:/usr/local/freesurfer/license.txt',\n",
    "                    '--imagepath', 'ansokol-freesurfer_5.3.simg',\n",
    "                                        qdec='qdec_long_groups.dat',\n",
    "                                        meas='thickness',\n",
    "                                        hemi=hemi,\n",
    "                                        time='years',\n",
    "                                        stack_avg='{hemi}.long.thickness-avg.stack.mgh'.format(hemi=hemi),\n",
    "                                        stack_rate='{hemi}.long.thickness-rate.stack.mgh'.format(hemi=hemi),\n",
    "                                        stack_pc1fit='{hemi}.long.thickness-pc1fit.stack.mgh'.format(hemi=hemi),\n",
    "                                        stack_pc1='{hemi}.long.thickness-pc1.stack.mgh'.format(hemi=hemi),\n",
    "                                        stack_spc='{hemi}.long.thickness-spc.stack.mgh'.format(hemi=hemi),\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75546217",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS5_mris_slopes\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS5_mris_slopes.out\n",
    "#SBATCH --error=logs/FS5_mris_slopes.err\n",
    "#SBATCH --time=10:0:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "export FS_LICENSE=$(realpath FS_licence/license.txt)\n",
    "python preprocess_FS5_long_mris_slopes.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b992e94",
   "metadata": {},
   "source": [
    "## FS 5 - Create FSGD file for the group analysis - baseline - t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f347dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdmci_first = stage_two.loc[stage_two[\"dx_group\"] == \"PD-MCI\"]\n",
    "df_pdnonmci_first = stage_two.loc[stage_two[\"dx_group\"] == \"PD-non-MCI\"]\n",
    "df_hc_first = stage_two.loc[stage_two[\"dx_group\"] == \"HC\"]\n",
    "\n",
    "cohort_df_PDnonMCI_HC = pd.concat([df_hc_first, df_pdnonmci_first])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a10aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PD-non-MCI and HC group\n",
    "\n",
    "fsgd_cortThick_diff = cohort_df_PDnonMCI_HC[\n",
    "    [\"first_visit\", \"AGE_AT_VISIT\", \"SEX\", \"dx_group\"]\n",
    "]\n",
    "fsgd_cortThick_diff[\"Input\"] = \"Input\"\n",
    "fsgd_cortThick_diff = fsgd_cortThick_diff[\n",
    "    [\"Input\", \"first_visit\", \"dx_group\", \"AGE_AT_VISIT\", \"SEX\"]\n",
    "]\n",
    "\n",
    "# generate sample matrix\n",
    "fsgd_cortThick_diff.to_csv(\n",
    "    \"fsgd_group_cort_PDnonMCI_HC_baseline.txt\", sep=\"\\t\", index=False, header=None\n",
    ")\n",
    "\n",
    "# generate file header\n",
    "with open(\"fsgd_group_desc_PDnonMCI_HC_baseline.txt\", \"w\") as f:\n",
    "    f.write(\n",
    "        \"GroupDescriptorFile 1\\nTitle GroupDifferences\\nClass HC\\nClass PD-non-MCI\\nVariables age sex \\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "with open(\"fsgd_cort_group_HC_PDnonMCI_baseline.fsgd\", \"wb\") as outfile:\n",
    "    for f in [\n",
    "        \"fsgd_group_desc_PDnonMCI_HC_baseline.txt\",\n",
    "        \"fsgd_group_cort_PDnonMCI_HC_baseline.txt\",\n",
    "    ]:\n",
    "        with open(f, \"rb\") as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cf1e80",
   "metadata": {},
   "source": [
    "## FS 5 - Stack images for group analyses - baseline - t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e39b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS5_mris_preproc_group_baseline_ttest.py\n",
    "\n",
    "# Concatenate images from group analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7893729\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "license = str(os.environ[\"FS_LICENSE\"]) \n",
    "\n",
    "for group in [\"HC_PDnonMCI\"]:\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        out_fs = freesurfer('-v', f'{license}:/usr/local/freesurfer/license.txt',\n",
    "                            '--imagepath', 'ansokol-freesurfer_5.3.simg',\n",
    "                                        hemi=hemi,\n",
    "                                        cachein=\"thickness.fwhm10.fsaverage\",\n",
    "                                        target=\"fsaverage\",\n",
    "                                        fsgd='fsgd_cort_group_{group}_baseline.fsgd'.format(group=group),\n",
    "                                        out='stack.{hemi}.group.{group}.thickness.10.baseline.mgh'.format(hemi=hemi,group=group),\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9808558",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS5_mris_preproc_group\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS5_mris_preproc_group_baseline_ttest.out\n",
    "#SBATCH --error=logs/FS5_mris_preproc_group_baseline_ttest.err\n",
    "#SBATCH --time=0:20:0\n",
    "#SBATCH --account=rrg-glatard\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "export FS_LICENSE=$(realpath FS_licence/license.txt)\n",
    "python preprocess_FS5_mris_preproc_group_baseline_ttest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f12f19",
   "metadata": {},
   "source": [
    "## FS 5 - Create FSGD file for the group analysis - longitudinal - t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579d7777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PD-non-MCI and HC group\n",
    "\n",
    "fsgd_cortThick_diff = cohort_df_PDnonMCI_HC[\n",
    "    [\"PATNO_base\", \"AGE_AT_VISIT\", \"SEX\", \"dx_group\", \"durationT2_T1_y\"]\n",
    "]\n",
    "fsgd_cortThick_diff[\"Input\"] = \"Input\"\n",
    "fsgd_cortThick_diff = fsgd_cortThick_diff[\n",
    "    [\"Input\", \"PATNO_base\", \"dx_group\", \"AGE_AT_VISIT\", \"SEX\", \"durationT2_T1_y\"]\n",
    "]\n",
    "\n",
    "# generate sample matrix\n",
    "fsgd_cortThick_diff.to_csv(\n",
    "    \"fsgd_group_cort_PDnonMCI_HC_long.txt\", sep=\"\\t\", index=False, header=None\n",
    ")\n",
    "\n",
    "# generate file header\n",
    "with open(\"fsgd_group_desc_PDnonMCI_HC_long.txt\", \"w\") as f:\n",
    "    f.write(\n",
    "        \"GroupDescriptorFile 1\\nTitle GroupDifferences\\nClass HC\\nClass PD-non-MCI\\nVariables age sex durationT2_T1_y\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "with open(\"fsgd_cort_group_HC_PDnonMCI_long.fsgd\", \"wb\") as outfile:\n",
    "    for f in [\n",
    "        \"fsgd_group_desc_PDnonMCI_HC_long.txt\",\n",
    "        \"fsgd_group_cort_PDnonMCI_HC_long.txt\",\n",
    "    ]:\n",
    "        with open(f, \"rb\") as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617693e4",
   "metadata": {},
   "source": [
    "## FS 5 - Stack images for group analyses - longitudinal - t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1da506",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS5_mris_preproc_group_long_ttest.py\n",
    "\n",
    "# Concatenate images from group analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7893729\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "license = str(os.environ[\"FS_LICENSE\"]) \n",
    "\n",
    "for group in [\"HC_PDnonMCI\"]:\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        out_fs = freesurfer('-v', f'{license}:/usr/local/freesurfer/license.txt',\n",
    "                            '--imagepath', 'ansokol-freesurfer_5.3.simg',\n",
    "                                        hemi=hemi,\n",
    "                                        cachein=\"long.thickness-rate.fwhm10.fsaverage\",\n",
    "                                        target=\"fsaverage\",\n",
    "                                        fsgd='fsgd_cort_group_{group}_long.fsgd'.format(group=group),\n",
    "                                        out='stack.{hemi}.group.{group}.thickness.rate.10.long.mgh'.format(hemi=hemi,group=group),\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c829f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS5_mris_preproc_group\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS5_mris_preproc_group_long_ttest.out\n",
    "#SBATCH --error=logs/FS5_mris_preproc_group_long_ttest.err\n",
    "#SBATCH --time=0:20:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "export FS_LICENSE=$(realpath FS_licence/license.txt)\n",
    "python preprocess_FS5_mris_preproc_group_long_ttest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e2f95",
   "metadata": {},
   "source": [
    "## Create FSGD file for the correlational analysis - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe623a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_df_PD = pd.concat([df_pdnonmci_first, df_pdmci_first])\n",
    "\n",
    "fsgd_cortThick_mcat = cohort_df_PD[\n",
    "    [\"first_visit\", \"AGE_AT_VISIT\", \"SEX\", \"NP3TOT\", \"dx_group\"]\n",
    "]\n",
    "fsgd_cortThick_mcat[\"Input\"] = \"Input\"\n",
    "fsgd_cortThick_mcat = fsgd_cortThick_mcat[\n",
    "    [\"Input\", \"first_visit\", \"dx_group\", \"NP3TOT\", \"AGE_AT_VISIT\", \"SEX\"]\n",
    "]\n",
    "\n",
    "\n",
    "fsgd_cortThick_mcat_PDnonMCI = fsgd_cortThick_mcat.loc[\n",
    "    fsgd_cortThick_mcat[\"dx_group\"] == \"PD-non-MCI\"\n",
    "]\n",
    "fsgd_cortThick_mcat_PDnonMCI[\"dx_group\"] = \"PDnonMCI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d55658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fsgd files for correlational analysis\n",
    "\n",
    "for group in [\"PDnonMCI\"]:\n",
    "\n",
    "    # generate sample matrix\n",
    "    exec(\n",
    "        \"fsgd_cortThick_mcat_%s.to_csv('fsgd_corr_%s_cort.txt', sep='\\t', index=False, header=None)\"\n",
    "        % (group, group)\n",
    "    )\n",
    "\n",
    "    # generate file header\n",
    "    with open(\"fsgd_corr_{group}_desc.txt\".format(group=group), \"w\") as f:\n",
    "        f.write(\n",
    "            \"GroupDescriptorFile 1\\nTitle GroupDifferences\\nMeasurementName NP3TOT\\nClass {group}\\nVariables NP3TOT age sex \\n\".format(\n",
    "                group=group\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # generate fsgd file\n",
    "    with open(\"fsgd_corr_{group}_group.fsgd\".format(group=group), \"wb\") as outfile:\n",
    "        for f in [\n",
    "            \"fsgd_corr_{group}_desc.txt\".format(group=group),\n",
    "            \"fsgd_corr_{group}_cort.txt\".format(group=group),\n",
    "        ]:\n",
    "            with open(f, \"rb\") as infile:\n",
    "                outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257ff85c",
   "metadata": {},
   "source": [
    "## FS 5 - Stack images for correlational analyses - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff75c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS5_mris_preproc_corr.py\n",
    "\n",
    "# Concatenate images from correlation analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7893729\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "license = str(os.environ[\"FS_LICENSE\"]) \n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    for group in [\"PDnonMCI\"]:\n",
    "        out_fs = freesurfer('-v', f'{license}:/usr/local/freesurfer/license.txt',\n",
    "                            '--imagepath', 'ansokol-freesurfer_5.3.simg',\n",
    "                                        hemi=hemi,\n",
    "                                        cachein=\"thickness.fwhm10.fsaverage\",\n",
    "                                        target=\"fsaverage\",\n",
    "                                        fsgd='fsgd_corr_{group}_group.fsgd'.format(group=group),\n",
    "                                        out='stack.{hemi}.corr.{group}.thickness.10.mgh'.format(hemi=hemi, group=group),\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef3d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS5_mris_preproc_corr\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS5_mris_preproc_corr.out\n",
    "#SBATCH --error=logs/FS5_mris_preproc_corr.err\n",
    "#SBATCH --time=0:20:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "export FS_LICENSE=$(realpath FS_licence/license.txt)\n",
    "python preprocess_FS5_mris_preproc_corr.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b907a06",
   "metadata": {},
   "source": [
    "## Create FSGD file for the correlational analysis - longitudinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58b0600",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsgd_cortThick_mcat = stage_two[\n",
    "    [\n",
    "        \"PATNO_base\",\n",
    "        \"durationT2_T1_y\",\n",
    "        \"dx_group\",\n",
    "        \"AGE_AT_VISIT\",\n",
    "        \"SEX\",\n",
    "        \"NP3TOT_change\",\n",
    "    ]\n",
    "]\n",
    "fsgd_cortThick_mcat[\"Input\"] = \"Input\"\n",
    "fsgd_cortThick_mcat = fsgd_cortThick_mcat[\n",
    "    [\n",
    "        \"Input\",\n",
    "        \"PATNO_base\",\n",
    "        \"dx_group\",\n",
    "        \"NP3TOT_change\",\n",
    "        \"AGE_AT_VISIT\",\n",
    "        \"SEX\",\n",
    "        \"durationT2_T1_y\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "fsgd_cortThick_mcat_PDnonMCI = fsgd_cortThick_mcat.loc[\n",
    "    fsgd_cortThick_mcat[\"dx_group\"] == \"PD-non-MCI\"\n",
    "]\n",
    "fsgd_cortThick_mcat_PDnonMCI[\"dx_group\"] = \"PDnonMCI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf32693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fsgd files for correlational analysis\n",
    "\n",
    "for group in [\"PDnonMCI\"]:\n",
    "\n",
    "    # generate sample matrix\n",
    "    exec(\n",
    "        \"fsgd_cortThick_mcat_%s.to_csv('fsgd_corr_%s_cort_long.txt', sep='\\t', index=False, header=None)\"\n",
    "        % (group, group)\n",
    "    )\n",
    "\n",
    "    # generate file header\n",
    "    with open(\"fsgd_corr_{group}_desc_long.txt\".format(group=group), \"w\") as f:\n",
    "        f.write(\n",
    "            \"GroupDescriptorFile 1\\nTitle GroupDifferences\\nMeasurementName NP3TOT\\nClass {group}\\nVariables NP3TOT age sex durationT2_T1_y\\n\".format(\n",
    "                group=group\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # generate fsgd file\n",
    "    with open(\"fsgd_corr_{group}_group_long.fsgd\".format(group=group), \"wb\") as outfile:\n",
    "        for f in [\n",
    "            \"fsgd_corr_{group}_desc_long.txt\".format(group=group),\n",
    "            \"fsgd_corr_{group}_cort_long.txt\".format(group=group),\n",
    "        ]:\n",
    "            with open(f, \"rb\") as infile:\n",
    "                outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53d3083",
   "metadata": {},
   "source": [
    "## FS5 - Stack images for correlational analyses - longitudinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1443bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS_mris_preproc_corr_long.py\n",
    "\n",
    "# Concatenate images from correlation analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7893729\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "license = str(os.environ[\"FS_LICENSE\"]) \n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    for group in [\"PDnonMCI\"]:\n",
    "        out_fs = freesurfer('-v', f'{license}:/usr/local/freesurfer/license.txt',\n",
    "                            '--imagepath', 'ansokol-freesurfer_5.3.simg',\n",
    "                                        hemi=hemi,\n",
    "                                        cachein=\"long.thickness-rate.fwhm10.fsaverage\",\n",
    "                                        target=\"fsaverage\",\n",
    "                                        fsgd='fsgd_corr_{group}_group_long.fsgd'.format(group=group),\n",
    "                                        out='stack.{hemi}.corr.{group}.thickness.rate.10.mgh'.format(hemi=hemi, group=group),\n",
    "                                       )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1715bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS_mris_preproc_corr\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS_mris_preproc_corr_long.out\n",
    "#SBATCH --error=logs/FS_mris_preproc_corr_long.err\n",
    "#SBATCH --time=0:20:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "export FS_LICENSE=$(realpath FS_licence/license.txt)\n",
    "python preprocess_FS_mris_preproc_corr_long.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd2a09c",
   "metadata": {},
   "source": [
    "## FS 5 - Run GLM model for the group analysis - baseline - t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e78d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create group contrasts\n",
    "\n",
    "with open(\"con_group_HC_PDnonMCI_base.mtx\", \"w\") as f:\n",
    "    f.write(\"1 -1 0 0 0 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e9233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile glm_FS5_group_base_ttest.py\n",
    "\n",
    "# GLM model for the group analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7893796\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "license = str(os.environ[\"FS_LICENSE\"]) \n",
    "\n",
    "for group in [\"HC_PDnonMCI\"]:\n",
    "    for hemi in [\"lh\", \"rh\"]:  \n",
    "        out_fs = freesurfer('-v', f'{license}:/usr/local/freesurfer/license.txt',\n",
    "                            '--imagepath', 'ansokol-freesurfer_5.3.simg',\n",
    "                                        hemi=hemi,\n",
    "                                        outdir='results_group_base_{group}_{hemi}'.format(group=group,hemi=hemi),\n",
    "                                        inputdata='stack.{hemi}.group.{group}.thickness.10.baseline.mgh'.format(hemi=hemi,group=group),\n",
    "                                        fsgd='fsgd_cort_group_{group}_baseline.fsgd'.format(group=group),\n",
    "                                        con='con_group_{group}_base.mtx'.format(group=group) \n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6a675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=glm5_gr_base\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS5_glm_group_base_ttest.out\n",
    "#SBATCH --error=logs/FS5_glm_group_base_test.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "export FS_LICENSE=$(realpath FS_licence/license.txt)\n",
    "python glm_FS5_group_base_ttest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66805d9",
   "metadata": {},
   "source": [
    "## FS 5 - Run GLM model for the group analysis - longitudinal - t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af380d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create group contrasts\n",
    "\n",
    "with open(\"con_group_HC_PDnonMCI_long.mtx\", \"w\") as f:\n",
    "    f.write(\"1 -1 0 0 0 0 0 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9784896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile glm_FS5_group_long_ttest.py\n",
    "\n",
    "# GLM model for the group analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7893796\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "license = str(os.environ[\"FS_LICENSE\"]) \n",
    "\n",
    "for group in [\"HC_PDnonMCI\"]:\n",
    "    for hemi in [\"lh\", \"rh\"]:  \n",
    "        out_fs = freesurfer('-v', f'{license}:/usr/local/freesurfer/license.txt',\n",
    "                            '--imagepath', 'ansokol-freesurfer_5.3.simg',\n",
    "                                        hemi=hemi,\n",
    "                                        outdir='results_group_long_{group}_{hemi}'.format(group=group,hemi=hemi),\n",
    "                                        inputdata='stack.{hemi}.group.{group}.thickness.rate.10.long.mgh'.format(hemi=hemi,group=group),\n",
    "                                        fsgd='fsgd_cort_group_{group}_long.fsgd'.format(group=group),\n",
    "                                        con='con_group_{group}_long.mtx'.format(group=group) \n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48380600",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=glm5_gr_long\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS5_glm_group_long_ttest.out\n",
    "#SBATCH --error=logs/FS5_glm_group_long_ttest.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "export FS_LICENSE=$(realpath FS_licence/license.txt)\n",
    "python glm_FS5_group_long_ttest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c1c80b",
   "metadata": {},
   "source": [
    "## FS 5 - Run GLM model for the correlational analysis - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ba678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create contrast for UDPRS scores\n",
    "\n",
    "with open(\"con_corr_UPDRS_base.mtx\", \"w\") as f:\n",
    "    f.write(\"0 1 0 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0354d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile glm5_corr_base.py\n",
    "\n",
    "# GLM model for the correlational analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7893796\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "license = str(os.environ[\"FS_LICENSE\"]) \n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    for group in [\"PDnonMCI\"]:   \n",
    "        out_fs = freesurfer('-v', f'{license}:/usr/local/freesurfer/license.txt',\n",
    "                            '--imagepath', 'ansokol-freesurfer_5.3.simg',\n",
    "                                        hemi=hemi,\n",
    "                                        outdir='results_corr_{group}_{hemi}_base'.format(group=group, hemi=hemi),\n",
    "                                        inputdata='stack.{hemi}.corr.{group}.thickness.10.mgh'.format(hemi=hemi,group=group),\n",
    "                                        fsgd='fsgd_corr_{group}_group.fsgd'.format(group=group),\n",
    "                                        con='con_corr_UPDRS_base.mtx'\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6832e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=glm5_corr\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS5_glm_corr.out\n",
    "#SBATCH --error=logs/FS5_glm_corr.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "export FS_LICENSE=$(realpath FS_licence/license.txt)\n",
    "python glm5_corr_base.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f64a6",
   "metadata": {},
   "source": [
    "## FS5 - Run GLM model for the correlational analysis - longitudinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdfb137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create contrast for UPDRS scores\n",
    "\n",
    "with open(\"con_corr_UPDRS_long.mtx\", \"w\") as f:\n",
    "    f.write(\"0 1 0 0 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836edf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile glm_corr_long.py\n",
    "\n",
    "# GLM model for the correlational analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7893796\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "license = str(os.environ[\"FS_LICENSE\"]) \n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    for group in [\"PDnonMCI\"]:   \n",
    "        out_fs = freesurfer('-v', f'{license}:/usr/local/freesurfer/license.txt',\n",
    "                            '--imagepath', 'ansokol-freesurfer_5.3.simg',\n",
    "                                        hemi=hemi,\n",
    "                                        outdir='results_corr_{group}_{hemi}_long'.format(group=group, hemi=hemi),\n",
    "                                        inputdata='stack.{hemi}.corr.{group}.thickness.rate.10.mgh'.format(hemi=hemi,group=group),\n",
    "                                        fsgd='fsgd_corr_{group}_group_long.fsgd'.format(group=group),\n",
    "                                        con='con_corr_UPDRS_long.mtx'\n",
    "                                       )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9cac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=glm5_corr_long\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS5_glm_corr_long.out\n",
    "#SBATCH --error=logs/FS5_glm_corr_long.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "export FS_LICENSE=$(realpath FS_licence/license.txt)\n",
    "python glm_corr_long.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e538a8dd",
   "metadata": {},
   "source": [
    "## FS 5 - Correction for multiple comparison (with mri_glmfit-sim) - t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c36b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile glm_FS5_group_sim_ttest.py\n",
    "\n",
    "# GLM model for the group analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7893807\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "license = str(os.environ[\"FS_LICENSE\"]) \n",
    "\n",
    "for group in [\"HC_PDnonMCI\"]:\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        for time in [\"baseline\", \"long\"]:\n",
    "            out_fs = freesurfer('-v', f'{license}:/usr/local/freesurfer/license.txt',\n",
    "                                '--imagepath', 'ansokol-freesurfer_5.3.simg',\n",
    "                                        dir='results_group_{time}_{group}_{hemi}'.format(time=time,hemi=hemi,group=group),\n",
    "                                        CACHE_abs='1.3',\n",
    "                                        cwp=\"0.05\"\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10044e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=glm5_group_sim\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS5_glm_sim_group_ttest.out\n",
    "#SBATCH --error=logs/FS5_glm_sim_group_ttest.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "export FS_LICENSE=$(realpath FS_licence/license.txt)\n",
    "python glm_FS5_group_sim_ttest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686f56c8",
   "metadata": {},
   "source": [
    "## FS 5 - Correction for multiple comparison (with mri_glmfit-sim) - correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de24219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile glm5_corr_sim.py\n",
    "\n",
    "# GLM model for the correlational analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7893807\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "license = str(os.environ[\"FS_LICENSE\"]) \n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    for group in [\"PDnonMCI\"]:\n",
    "        for ses in [\"long\", \"base\"]:\n",
    "            out_fs = freesurfer('-v', f'{license}:/usr/local/freesurfer/license.txt',\n",
    "                            '--imagepath', 'ansokol-freesurfer_5.3.simg',\n",
    "                                        dir='results_corr_{group}_{hemi}_{ses}'.format(group=group, hemi=hemi, ses=ses),\n",
    "                                        CACHE_abs='1.3',\n",
    "                                        cwp=\"0.05\"\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e56d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=glm5_corr_sim\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS5_glm_sim_corr.out\n",
    "#SBATCH --error=logs/FS5_glm_sim_corr.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "export FS_LICENSE=$(realpath FS_licence/license.txt)\n",
    "python glm5_corr_sim.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654b30f8",
   "metadata": {},
   "source": [
    "# Freesurfer 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648812eb",
   "metadata": {},
   "source": [
    "## Freesurfer 6 - preprocessing step 2 - base template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d3062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS6_base.py\n",
    "\n",
    "# Step 2. create an unbiased template from all time points for each subject and process it with recon-all:\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7900700\"\n",
    "from boutiques.descriptor2func import function\n",
    "#bosh([\"exec\", \"prepare\", zid])\n",
    "freesurfer = function(zid)\n",
    "\n",
    "task_id = str(os.environ[\"SLURM_ARRAY_TASK_ID\"])\n",
    "\n",
    "with open('json_data_base.json') as fin:\n",
    "    subject_map = json.load(fin)\n",
    "\n",
    "    \n",
    "    \n",
    "out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_6.0.1.simg',\n",
    "                    license=\"FS_license/license.txt\",\n",
    "                                        tp1=subject_map[\"first_visit\"][task_id],\n",
    "                                        tp2=subject_map[\"second_visit\"][task_id],\n",
    "                                        outputdir=subject_map[\"PATNO_base\"][task_id],\n",
    "                                       )\n",
    "print(out_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch --array=0-249\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS6_base\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS6_preproc_base.%a.out\n",
    "#SBATCH --error=logs/FS6_preproc_base.%a.err\n",
    "#SBATCH --time=10:0:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python preprocess_FS6_base.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224b0cc6",
   "metadata": {},
   "source": [
    "## Freesurfer 6 - preprocessing step 3 - longitudinally processed timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f07af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS6_long.py\n",
    "\n",
    "# Step 3. \"-long\" longitudinally process all timepoints (recon-all -long):\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7900706\"\n",
    "from boutiques.descriptor2func import function\n",
    "#bosh([\"exec\", \"prepare\", zid])\n",
    "freesurfer = function(zid)\n",
    "\n",
    "task_id = str(os.environ[\"SLURM_ARRAY_TASK_ID\"])\n",
    "\n",
    "with open('json_data_long.json') as fin:\n",
    "    subject_map = json.load(fin)\n",
    "\n",
    "out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_6.0.1.simg',\n",
    "                    license=\"FS_license/license.txt\",\n",
    "                                        tp=subject_map[\"visit\"][task_id],\n",
    "                                        base=subject_map[\"PATNO_base\"][task_id]\n",
    "                                       )\n",
    "\n",
    "\n",
    "print(out_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd781a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch --array=0-495\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS6_long\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS6_preproc_long.%a.out\n",
    "#SBATCH --error=logs/FS6_preproc_long.%a.err\n",
    "#SBATCH --time=10:0:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python preprocess_FS6_long.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be0c4c5",
   "metadata": {},
   "source": [
    "## Freesurfer 6 - preprocessing step 4 - Qcache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c55d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS6_long_qcache.py\n",
    "\n",
    "# save proprocessing script to submit jobs to the server later \n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7900708\"\n",
    "from boutiques.descriptor2func import function\n",
    "#bosh([\"exec\", \"prepare\", zid])\n",
    "freesurfer = function(zid)\n",
    "\n",
    "task_id = str(os.environ[\"SLURM_ARRAY_TASK_ID\"])\n",
    "\n",
    "with open('json_data_long.json') as fin:\n",
    "    subject_map = json.load(fin)\n",
    "\n",
    "    \n",
    "out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_6.0.1.simg',\n",
    "                    license=\"FS_license/license.txt\",\n",
    "                                        tp=subject_map[\"visit\"][task_id],\n",
    "                                        base=subject_map[\"PATNO_base\"][task_id],\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5281ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch --array=0-495\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS6_longQcache\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS6_preproc_longQcache.%a.out\n",
    "#SBATCH --error=logs/FS6_preproc_longQcache.%a.err\n",
    "#SBATCH --time=2:0:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python preprocess_FS6_long_qcache.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253a8a96",
   "metadata": {},
   "source": [
    "## FS 6 - Prepare the vertex data with long_mris_slopes for longitudinal two stage model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bd50f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS6_long_mris_slopes.py\n",
    "\n",
    "# Prepare the data with long_mris_slopes for longitudinal two stage model\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7900742\"\n",
    "from boutiques.descriptor2func import function\n",
    "#bosh([\"exec\", \"prepare\", zid])\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_6.0.1.simg',\n",
    "                        license=\"FS_license/license.txt\",\n",
    "                                        qdec='qdec_long_groups.dat',\n",
    "                                        meas='thickness',\n",
    "                                        hemi=hemi,\n",
    "                                        time='years',\n",
    "                                        stack_avg='{hemi}.long.thickness-avg.stack.mgh'.format(hemi=hemi),\n",
    "                                        stack_rate='{hemi}.long.thickness-rate.stack.mgh'.format(hemi=hemi),\n",
    "                                        stack_pc1fit='{hemi}.long.thickness-pc1fit.stack.mgh'.format(hemi=hemi),\n",
    "                                        stack_pc1='{hemi}.long.thickness-pc1.stack.mgh'.format(hemi=hemi),\n",
    "                                        stack_spc='{hemi}.long.thickness-spc.stack.mgh'.format(hemi=hemi),\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4c6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS6_mris_slopes\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS6_mris_slopes.out\n",
    "#SBATCH --error=logs/FS6_mris_slopes.err\n",
    "#SBATCH --time=10:0:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python preprocess_FS6_long_mris_slopes.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99191053",
   "metadata": {},
   "source": [
    "## FS 6 - Stack images for group analyses - baseline - t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e42e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS6_mris_preproc_group_baseline_ttest.py\n",
    "\n",
    "# Concatenate images from group analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7900745\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for group in [\"HC_PDnonMCI\"]:\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_6.0.1.simg',\n",
    "                            license=\"FS_license/license.txt\",\n",
    "                                        hemi=hemi,\n",
    "                                        cachein=\"thickness.fwhm10.fsaverage\",\n",
    "                                        target=\"fsaverage\",\n",
    "                                        fsgd='fsgd_cort_group_{group}_baseline.fsgd'.format(group=group),\n",
    "                                        out='stack.{hemi}.group.{group}.thickness.10.baseline.mgh'.format(hemi=hemi,group=group),\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbb350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS6_mris_preproc_group\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS6_mris_preproc_group_baseline_ttest.out\n",
    "#SBATCH --error=logs/FS6_mris_preproc_group_baseline_ttest.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python preprocess_FS6_mris_preproc_group_baseline_ttest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50bc5a5",
   "metadata": {},
   "source": [
    "## FS 6 - Stack images for group analyses - longitudinal - t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d7ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS6_mris_preproc_group_long_ttest.py\n",
    "\n",
    "# Concatenate images from group analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7900745\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for group in [\"HC_PDnonMCI\"]:\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_6.0.1.simg',\n",
    "                            license=\"FS_license/license.txt\",\n",
    "                                        hemi=hemi,\n",
    "                                        cachein=\"long.thickness-rate.fwhm10.fsaverage\",\n",
    "                                        target=\"fsaverage\",\n",
    "                                        fsgd='fsgd_cort_group_{group}_long.fsgd'.format(group=group),\n",
    "                                        out='stack.{hemi}.group.{group}.thickness.rate.10.long.mgh'.format(hemi=hemi,group=group),\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d01f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS6_mris_preproc_group\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS6_mris_preproc_group_long_ttest.out\n",
    "#SBATCH --error=logs/FS6_mris_preproc_group_long_ttest.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python preprocess_FS6_mris_preproc_group_long_ttest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e400b",
   "metadata": {},
   "source": [
    "## FS 6 - Stack images for correlational analyses - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb43958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS6_mris_preproc_corr.py\n",
    "\n",
    "# Concatenate images from correlation analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7900745\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    for group in [\"PDnonMCI\"]:\n",
    "        out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_6.0.1.simg',\n",
    "                            license=\"FS_license/license.txt\",\n",
    "                                        hemi=hemi,\n",
    "                                        cachein=\"thickness.fwhm10.fsaverage\",\n",
    "                                        target=\"fsaverage\",\n",
    "                                        fsgd='fsgd_corr_{group}_group.fsgd'.format(group=group),\n",
    "                                        out='stack.{hemi}.corr.{group}.thickness.10.baseline.mgh'.format(hemi=hemi, group=group),\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d62f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS6_mris_preproc_corr\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS6_mris_preproc_corr.out\n",
    "#SBATCH --error=logs/FS6_mris_preproc_corr.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python preprocess_FS6_mris_preproc_corr.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5a173f",
   "metadata": {},
   "source": [
    "## FS 6 - Stack images for correlational analyses - longitudinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f821f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS6_mris_preproc_corr_long.py\n",
    "\n",
    "# Concatenate images from correlation analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7900745\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    for group in [\"PDnonMCI\"]:\n",
    "        out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_6.0.1.simg',\n",
    "                            license=\"FS_license/license.txt\",\n",
    "                                        hemi=hemi,\n",
    "                                        cachein=\"long.thickness-rate.fwhm10.fsaverage\",\n",
    "                                        target=\"fsaverage\",\n",
    "                                        fsgd='fsgd_corr_{group}_group_long.fsgd'.format(group=group),\n",
    "                                        out='stack.{hemi}.corr.{group}.thickness.rate.10.mgh'.format(hemi=hemi, group=group),\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32b60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS6_mris_preproc_corr\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS6_mris_preproc_corr_long.out\n",
    "#SBATCH --error=logs/FS6_mris_preproc_corr_long.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python preprocess_FS6_mris_preproc_corr_long.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecca457d",
   "metadata": {},
   "source": [
    "## FS 6 - Run GLM model for the group analysis - baseline - t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0189b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile glm_FS6_group_base_ttest.py\n",
    "\n",
    "# GLM model for the group analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7900725\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for group in [\"HC_PDnonMCI\"]:\n",
    "    for hemi in [\"lh\", \"rh\"]:  \n",
    "        out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_6.0.1.simg',\n",
    "                            license=\"FS_license/license.txt\",\n",
    "                                        hemi=hemi,\n",
    "                                        outdir='results_group_base_{group}_{hemi}'.format(group=group,hemi=hemi),\n",
    "                                        inputdata='stack.{hemi}.group.{group}.thickness.10.baseline.mgh'.format(hemi=hemi,group=group),\n",
    "                                        fsgd='fsgd_cort_group_{group}_baseline.fsgd'.format(group=group),\n",
    "                                        con='con_group_{group}_base.mtx'.format(group=group) \n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771da1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=glm6_gr_base\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS6_glm_group_base_ttest.out\n",
    "#SBATCH --error=logs/FS6_glm_group_base_test.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python glm_FS6_group_base_ttest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efcc548",
   "metadata": {},
   "source": [
    "## FS 6 - Run GLM model for the group analysis - longitudinal - t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4308802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile glm_FS6_group_long_ttest.py\n",
    "\n",
    "# GLM model for the group analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7900725\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for group in [\"HC_PDnonMCI\"]:\n",
    "    for hemi in [\"lh\", \"rh\"]:  \n",
    "        out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_6.0.1.simg',\n",
    "                            license=\"FS_license/license.txt\",\n",
    "                                        hemi=hemi,\n",
    "                                        outdir='results_group_long_{group}_{hemi}'.format(group=group,hemi=hemi),\n",
    "                                        inputdata='stack.{hemi}.group.{group}.thickness.rate.10.long.mgh'.format(hemi=hemi,group=group),\n",
    "                                        fsgd='fsgd_cort_group_{group}_long.fsgd'.format(group=group),\n",
    "                                        con='con_group_{group}_long.mtx'.format(group=group) \n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a316770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=glm6_gr_long\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS6_glm_group_long_ttest.out\n",
    "#SBATCH --error=logs/FS6_glm_group_long_ttest.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python glm_FS6_group_long_ttest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84f31",
   "metadata": {},
   "source": [
    "## FS 6 - Run GLM model for the correlational analysis - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b22d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile glm6_corr.py\n",
    "\n",
    "# GLM model for the correlational analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7900725\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    for group in [\"PDnonMCI\"]:   \n",
    "        out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_6.0.1.simg',\n",
    "                            license=\"FS_license/license.txt\",\n",
    "                                        hemi=hemi,\n",
    "                                        outdir='results_corr_base_{group}_{hemi}'.format(group=group, hemi=hemi),\n",
    "                                        inputdata='stack.{hemi}.corr.{group}.thickness.10.baseline.mgh'.format(hemi=hemi,group=group),\n",
    "                                        fsgd='fsgd_corr_{group}_group.fsgd'.format(group=group),\n",
    "                                        con='con_corr_UPDRS_base.mtx'\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243a8a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=glm6_corr\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS6_glm_corr.out\n",
    "#SBATCH --error=logs/FS6_glm_corr.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python glm6_corr.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218ff49a",
   "metadata": {},
   "source": [
    "## FS 6 - Run GLM model for the correlational analysis - longitudinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9eda83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile glm6_corr_long.py\n",
    "\n",
    "# GLM model for the correlational analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7900725\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    for group in [\"PDnonMCI\"]:   \n",
    "        out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_6.0.1.simg',\n",
    "                            license=\"FS_license/license.txt\",\n",
    "                                        hemi=hemi,\n",
    "                                        outdir='results_corr_long_{group}_{hemi}'.format(group=group, hemi=hemi),\n",
    "                                        inputdata='stack.{hemi}.corr.{group}.thickness.rate.10.mgh'.format(hemi=hemi,group=group),\n",
    "                                        fsgd='fsgd_corr_{group}_group_long.fsgd'.format(group=group),\n",
    "                                        con='con_corr_UPDRS_long.mtx'\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=glm6_corr\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS6_glm_corr_long.out\n",
    "#SBATCH --error=logs/FS6_glm_corr_long.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python glm6_corr_long.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c7656d",
   "metadata": {},
   "source": [
    "## FS 6 - Correction for multiple comparison (with mri_glmfit-sim) - t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a0fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile glm_FS6_group_sim_ttest.py\n",
    "\n",
    "# GLM model for the group analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7900735\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for group in [\"HC_PDnonMCI\"]:\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        for time in [\"base\", \"long\"]:\n",
    "            out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_6.0.1.simg',\n",
    "                                license=\"FS_license/license.txt\",\n",
    "                                        dir='results_group_{time}_{group}_{hemi}'.format(time=time,hemi=hemi,group=group),\n",
    "                                        CACHE_abs='1.3',\n",
    "                                        cwp=\"0.05\"\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ecf555",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=glm6_group_sim\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS6_glm_sim_group_ttest.out\n",
    "#SBATCH --error=logs/FS6_glm_sim_group_ttest.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python glm_FS6_group_sim_ttest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b2ed85",
   "metadata": {},
   "source": [
    "## FS 6 - Correction for multiple comparison (with mri_glmfit-sim) - correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a904ba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile glm6_corr_sim.py\n",
    "\n",
    "# GLM model for the correlational analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7900735\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    for group in [\"PDnonMCI\"]:\n",
    "        for time in [\"base\", \"long\"]:\n",
    "            out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_6.0.1.simg',\n",
    "                            license=\"FS_license/license.txt\",\n",
    "                                        dir='results_corr_{time}_{group}_{hemi}'.format(time=time, group=group, hemi=hemi),\n",
    "                                        CACHE_abs='1.3',\n",
    "                                        cwp=\"0.05\"\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ef3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=glm6_corr_sim\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS6_glm_sim_corr.out\n",
    "#SBATCH --error=logs/FS6_glm_sim_corr.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python glm6_corr_sim.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e1de0b",
   "metadata": {},
   "source": [
    "# Freesurfer 7.3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9c1771",
   "metadata": {},
   "source": [
    "## Freesurfer 7 - preprocessing step 2 - base template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b8460",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS7_base.py\n",
    "\n",
    "# Step 2. create an unbiased template from all time points for each subject and process it with recon-all:\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7916240\"\n",
    "from boutiques.descriptor2func import function\n",
    "#bosh([\"exec\", \"prepare\", zid])\n",
    "freesurfer = function(zid)\n",
    "\n",
    "task_id = str(os.environ[\"SLURM_ARRAY_TASK_ID\"])\n",
    "\n",
    "with open('json_data_base.json') as fin:\n",
    "    subject_map = json.load(fin)\n",
    "\n",
    "out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_7.3.2.simg',\n",
    "                                        tp1=subject_map[\"first_visit\"][task_id],\n",
    "                                        tp2=subject_map[\"second_visit\"][task_id],\n",
    "                                        license=\"FS_license/license.txt\",\n",
    "                                        outputdir=subject_map[\"PATNO_base\"][task_id],\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7442c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch --array=0-249\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS7_base\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS7_preproc_base.%a.out\n",
    "#SBATCH --error=logs/FS7_preproc_base.%a.err\n",
    "#SBATCH --time=10:0:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "\n",
    "python preprocess_FS7_base.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e371d9",
   "metadata": {},
   "source": [
    "## Freesurfer 7 - preprocessing step 3 - longitudinally processed timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac71b261",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS7_long.py\n",
    "\n",
    "# Step 3. \"-long\" longitudinally process all timepoints (recon-all -long):\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7920788\"\n",
    "from boutiques.descriptor2func import function\n",
    "#bosh([\"exec\", \"prepare\", zid])\n",
    "freesurfer = function(zid)\n",
    "\n",
    "task_id = str(os.environ[\"SLURM_ARRAY_TASK_ID\"])\n",
    "\n",
    "with open('json_data_long.json') as fin:\n",
    "    subject_map = json.load(fin)\n",
    "\n",
    "out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_7.3.2.simg',\n",
    "                                        tp=subject_map[\"visit\"][task_id],\n",
    "                                        base=subject_map[\"PATNO_base\"][task_id],\n",
    "                                        license=\"FS_license/license.txt\",\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ac5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch --array=0-495\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS7_long\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS7_preproc_long.%a.out\n",
    "#SBATCH --error=logs/FS7_preproc_long.%a.err\n",
    "#SBATCH --time=10:0:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "\n",
    "python preprocess_FS7_long.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2704c66",
   "metadata": {},
   "source": [
    "## Freesurfer 7 - preprocessing step 4 - Qcache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS7_long_qcache.py\n",
    "\n",
    "# save proprocessing script to submit jobs to the server later \n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7920876\"\n",
    "from boutiques.descriptor2func import function\n",
    "#bosh([\"exec\", \"prepare\", zid])\n",
    "freesurfer = function(zid)\n",
    "\n",
    "task_id = str(os.environ[\"SLURM_ARRAY_TASK_ID\"])\n",
    "\n",
    "with open('json_data_long.json') as fin:\n",
    "    subject_map = json.load(fin)\n",
    "\n",
    "    \n",
    "out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_7.3.2.simg',\n",
    "                                        tp=subject_map[\"visit\"][task_id],\n",
    "                                        base=subject_map[\"PATNO_base\"][task_id],\n",
    "                                        license=\"FS_license/license.txt\",\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87087ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch --array=0-495\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS7_preproc_longQcache\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS7_preproc_longQcache.%a.out\n",
    "#SBATCH --error=logs/FS7_preproc_longQcache.%a.err\n",
    "#SBATCH --time=2:0:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "\n",
    "python preprocess_FS7_long_qcache.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62fb47a",
   "metadata": {},
   "source": [
    "## FS 7 - Prepare the vertex data with long_mris_slopes for longitudinal two stage model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc86137",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS7_long_mris_slopes.py\n",
    "\n",
    "# Prepare the data with long_mris_slopes for longitudinal two stage model\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7920880\"\n",
    "from boutiques.descriptor2func import function\n",
    "#bosh([\"exec\", \"prepare\", zid])\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_7.3.2.simg',\n",
    "                        license=\"FS_license/license.txt\",\n",
    "                                        qdec='qdec_long_groups.dat',\n",
    "                                        meas='thickness',\n",
    "                                        hemi=hemi,\n",
    "                                        time='years',\n",
    "                                        stack_avg='{hemi}.long.thickness-avg.stack.mgh'.format(hemi=hemi),\n",
    "                                        stack_rate='{hemi}.long.thickness-rate.stack.mgh'.format(hemi=hemi),\n",
    "                                        stack_pc1fit='{hemi}.long.thickness-pc1fit.stack.mgh'.format(hemi=hemi),\n",
    "                                        stack_pc1='{hemi}.long.thickness-pc1.stack.mgh'.format(hemi=hemi),\n",
    "                                        stack_spc='{hemi}.long.thickness-spc.stack.mgh'.format(hemi=hemi),\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24f182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS7_mris_slopes\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS7_mris_slopes.out\n",
    "#SBATCH --error=logs/FS7_mris_slopes.err\n",
    "#SBATCH --time=10:0:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python preprocess_FS7_long_mris_slopes.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046b7781",
   "metadata": {},
   "source": [
    "## FS 7 - Stack images for group analyses - baseline - t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab9ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS7_mris_preproc_group_baseline_ttest.py\n",
    "\n",
    "# Concatenate images from group analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7920888\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for group in [\"HC_PDnonMCI\"]:\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_7.3.2.simg',\n",
    "                            license=\"FS_license/license.txt\",\n",
    "                                        hemi=hemi,\n",
    "                                        cachein=\"thickness.fwhm10.fsaverage\",\n",
    "                                        target=\"fsaverage\",\n",
    "                                        fsgd='fsgd_cort_group_{group}_baseline.fsgd'.format(group=group),\n",
    "                                        out='stack.{hemi}.group.{group}.thickness.10.baseline.mgh'.format(hemi=hemi,group=group),\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5702bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS7_mris_preproc_group\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS7_mris_preproc_group_baseline_ttest.out\n",
    "#SBATCH --error=logs/FS7_mris_preproc_group_baseline_ttest.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python preprocess_FS7_mris_preproc_group_baseline_ttest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58516f6f",
   "metadata": {},
   "source": [
    "## FS 7 - Stack images for group analyses - longitudinal - t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c75009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS7_mris_preproc_group_long_ttest.py\n",
    "\n",
    "# Concatenate images from group analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7920888\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for group in [\"HC_PDnonMCI\"]:\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_7.3.2.simg',\n",
    "                            license=\"FS_license/license.txt\",\n",
    "                                        hemi=hemi,\n",
    "                                        cachein=\"long.thickness-rate.fwhm10.fsaverage\",\n",
    "                                        target=\"fsaverage\",\n",
    "                                        fsgd='fsgd_cort_group_{group}_long.fsgd'.format(group=group),\n",
    "                                        out='stack.{hemi}.group.{group}.thickness.rate.10.long.mgh'.format(hemi=hemi,group=group),\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS7_mris_preproc_group\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS7_mris_preproc_group_long_ttest.out\n",
    "#SBATCH --error=logs/FS7_mris_preproc_group_long_ttest.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python preprocess_FS7_mris_preproc_group_long_ttest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69114fbe",
   "metadata": {},
   "source": [
    "## FS 7 - Stack images for correlational analyses - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b1a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS7_mris_preproc_corr.py\n",
    "\n",
    "# Concatenate images from correlation analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7920888\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    for group in [\"PDnonMCI\"]:\n",
    "        out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_7.3.2.simg',\n",
    "                            license=\"FS_license/license.txt\",\n",
    "                                        hemi=hemi,\n",
    "                                        cachein=\"thickness.fwhm10.fsaverage\",\n",
    "                                        target=\"fsaverage\",\n",
    "                                        fsgd='fsgd_corr_{group}_group.fsgd'.format(group=group),\n",
    "                                        out='stack.{hemi}.corr.{group}.thickness.10.baseline.mgh'.format(hemi=hemi, group=group),\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac407046",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS7_mris_preproc_corr\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS7_mris_preproc_corr.out\n",
    "#SBATCH --error=logs/FS7_mris_preproc_corr.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python preprocess_FS7_mris_preproc_corr.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b85d782",
   "metadata": {},
   "source": [
    "## FS 7 - Stack images for correlational analyses - longitudinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f8582",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile preprocess_FS7_mris_preproc_corr_long.py\n",
    "\n",
    "# Concatenate images from correlation analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7920888\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    for group in [\"PDnonMCI\"]:\n",
    "        out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_7.3.2.simg',\n",
    "                            license=\"FS_license/license.txt\",\n",
    "                                        hemi=hemi,\n",
    "                                        cachein=\"long.thickness-rate.fwhm10.fsaverage\",\n",
    "                                        target=\"fsaverage\",\n",
    "                                        fsgd='fsgd_corr_{group}_group_long.fsgd'.format(group=group),\n",
    "                                        out='stack.{hemi}.corr.{group}.thickness.rate.10.mgh'.format(hemi=hemi, group=group),\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d9992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=FS7_mris_preproc_corr\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS7_mris_preproc_corr_long.out\n",
    "#SBATCH --error=logs/FS7_mris_preproc_corr_long.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python preprocess_FS7_mris_preproc_corr_long.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9bd14a",
   "metadata": {},
   "source": [
    "## FS 7 - Run GLM model for the group analysis - baseline - t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8dc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile glm_FS7_group_base_ttest.py\n",
    "\n",
    "# GLM model for the group analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7920892\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for group in [\"HC_PDnonMCI\"]:\n",
    "    for hemi in [\"lh\", \"rh\"]:  \n",
    "        out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_7.3.2.simg',\n",
    "                            license=\"FS_license/license.txt\",\n",
    "                                        hemi=hemi,\n",
    "                                        outdir='results_group_base_{group}_{hemi}'.format(group=group,hemi=hemi),\n",
    "                                        inputdata='stack.{hemi}.group.{group}.thickness.10.baseline.mgh'.format(hemi=hemi,group=group),\n",
    "                                        fsgd='fsgd_cort_group_{group}_baseline.fsgd'.format(group=group),\n",
    "                                        con='con_group_{group}_base.mtx'.format(group=group) \n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5b74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=glm7_gr_base\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS7_glm_group_base_ttest.out\n",
    "#SBATCH --error=logs/FS7_glm_group_base_test.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python glm_FS7_group_base_ttest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae49266",
   "metadata": {},
   "source": [
    "## FS 7 - Run GLM model for the group analysis - longitudinal - t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c2f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile glm_FS7_group_long_ttest.py\n",
    "\n",
    "# GLM model for the group analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7920892\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for group in [\"HC_PDnonMCI\"]:\n",
    "    for hemi in [\"lh\", \"rh\"]:  \n",
    "        out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_7.3.2.simg',\n",
    "                            license=\"FS_license/license.txt\",\n",
    "                                        hemi=hemi,\n",
    "                                        outdir='results_group_long_{group}_{hemi}'.format(group=group,hemi=hemi),\n",
    "                                        inputdata='stack.{hemi}.group.{group}.thickness.rate.10.long.mgh'.format(hemi=hemi,group=group),\n",
    "                                        fsgd='fsgd_cort_group_{group}_long.fsgd'.format(group=group),\n",
    "                                        con='con_group_{group}_long.mtx'.format(group=group) \n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1715d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=glm7_gr_long\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS7_glm_group_long_ttest.out\n",
    "#SBATCH --error=logs/FS7_glm_group_long_ttest.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python glm_FS7_group_long_ttest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06079082",
   "metadata": {},
   "source": [
    "## FS 7 - Run GLM model for the correlational analysis - baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e3ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile glm7_corr.py\n",
    "\n",
    "# GLM model for the correlational analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7920892\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    for group in [\"PDnonMCI\"]:   \n",
    "        out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_7.3.2.simg',\n",
    "                            license=\"FS_license/license.txt\",\n",
    "                                        hemi=hemi,\n",
    "                                        outdir='results_corr_base_{group}_{hemi}'.format(group=group, hemi=hemi),\n",
    "                                        inputdata='stack.{hemi}.corr.{group}.thickness.10.baseline.mgh'.format(hemi=hemi,group=group),\n",
    "                                        fsgd='fsgd_corr_{group}_group.fsgd'.format(group=group),\n",
    "                                        con='con_corr_UPDRS_base.mtx'\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f349a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=glm7_corr\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS7_glm_corr.out\n",
    "#SBATCH --error=logs/FS7_glm_corr.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python glm7_corr.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8065422f",
   "metadata": {},
   "source": [
    "## FS 7 - Run GLM model for the correlational analysis - longitudinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21987d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile glm7_corr_long.py\n",
    "\n",
    "# GLM model for the correlational analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7920892\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    for group in [\"PDnonMCI\"]:   \n",
    "        out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_7.3.2.simg',\n",
    "                            license=\"FS_license/license.txt\",\n",
    "                                        hemi=hemi,\n",
    "                                        outdir='results_corr_long_{group}_{hemi}'.format(group=group, hemi=hemi),\n",
    "                                        inputdata='stack.{hemi}.corr.{group}.thickness.rate.10.mgh'.format(hemi=hemi,group=group),\n",
    "                                        fsgd='fsgd_corr_{group}_group_long.fsgd'.format(group=group),\n",
    "                                        con='con_corr_UPDRS_long.mtx'\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fbd1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=glm7_corr\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS7_glm_corr.out\n",
    "#SBATCH --error=logs/FS7_glm_corr.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python glm7_corr_long.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233f65ba",
   "metadata": {},
   "source": [
    "## FS 7 - Correction for multiple comparison (with mri_glmfit-sim) - t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03401181",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile glm_FS7_group_sim_ttest.py\n",
    "\n",
    "# GLM model for the group analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7920896\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for group in [\"HC_PDnonMCI\"]:\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        for time in [\"base\", \"long\"]:\n",
    "            out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_7.3.2.simg',\n",
    "                                license=\"FS_license/license.txt\",\n",
    "                                        dir='results_group_{time}_{group}_{hemi}'.format(time=time,hemi=hemi,group=group),\n",
    "                                        CACHE_abs='1.3',\n",
    "                                        cwp=\"0.05\"\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e03a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=glm7_group_sim\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS7_glm_sim_group_ttest.out\n",
    "#SBATCH --error=logs/FS7_glm_sim_group_ttest.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python glm_FS7_group_sim_ttest.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf23e71",
   "metadata": {},
   "source": [
    "## FS 7 - Correction for multiple comparison (with mri_glmfit-sim) - correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85af07c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile glm7_corr_sim.py\n",
    "\n",
    "# GLM model for the correlational analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import boutiques\n",
    "from boutiques import bosh\n",
    "zid = \"zenodo.7920896\"\n",
    "from boutiques.descriptor2func import function\n",
    "freesurfer = function(zid)\n",
    "\n",
    "for hemi in [\"lh\", \"rh\"]:\n",
    "    for group in [\"PDnonMCI\"]:\n",
    "        for time in [\"base\", \"long\"]:\n",
    "            out_fs = freesurfer('--imagepath', 'ansokol-freesurfer_7.3.2.simg',\n",
    "                            license=\"FS_license/license.txt\",\n",
    "                                        dir='results_corr_{time}_{group}_{hemi}'.format(time=time, group=group, hemi=hemi),\n",
    "                                        CACHE_abs='1.3',\n",
    "                                        cwp=\"0.05\"\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c7d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=glm7_corr_sim\n",
    "#SBATCH --mem=1G\n",
    "#SBATCH --cpus-per-task=2\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --output=logs/FS7_glm_sim_corr.out\n",
    "#SBATCH --error=logs/FS7_glm_sim_corr.err\n",
    "#SBATCH --time=0:10:0\n",
    "\n",
    ". venv/bin/activate # opens virtual environment. change depending where you proprocess the data  \n",
    "\n",
    "module load singularity\n",
    "python glm7_corr_sim.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49dfd42",
   "metadata": {},
   "source": [
    "# Quality control of preprocessed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64722e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio as iio\n",
    "from pathlib import Path\n",
    "\n",
    "for stage in [\"clinical\", \"comput\"]:\n",
    "    for ver in [\"FS5\", \"FS6\", \"FS7\"]:\n",
    "        for view in [\"axial\", \"sagittal\", \"coronal\"]:\n",
    "            images = list()\n",
    "            for file in Path(f\"segm/{stage}/{ver}/{view}\").iterdir():\n",
    "                if not file.is_file():\n",
    "                    continue\n",
    "\n",
    "                images.append(iio.imread(file))\n",
    "                iio.mimsave(\n",
    "                    f\"segm/{stage}/{ver}/segm_{stage}_{view}.gif\", images, duration=1\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a404b11",
   "metadata": {},
   "source": [
    "## Computational data\n",
    "\n",
    "## FS5\n",
    "\n",
    "### FS 5 axial view\n",
    "![SegmentLocal](images/segm_comput_FS5_axial.gif \"segment\")\n",
    "\n",
    "### FS 5 coronal view\n",
    "![SegmentLocal](images/segm_comput_FS5_coronal.gif \"segment\")\n",
    "\n",
    "### FS 5 sagittal view\n",
    "![SegmentLocal](images/segm_comput_FS5_sagittal.gif \"segment\")\n",
    "\n",
    "## FS6\n",
    "\n",
    "### FS 6 axial view\n",
    "![SegmentLocal](images/segm_comput_FS6_axial.gif \"segment\")\n",
    "\n",
    "### FS 6 coronal view\n",
    "![SegmentLocal](images/segm_comput_FS6_coronal.gif \"segment\")\n",
    "\n",
    "### FS 6 sagittal view\n",
    "![SegmentLocal](images/segm_comput_FS6_sagittal.gif \"segment\")\n",
    "\n",
    "## FS7\n",
    "\n",
    "### FS 7 axial view\n",
    "![SegmentLocal](images/segm_comput_FS7_axial.gif \"segment\")\n",
    "\n",
    "### FS 7 coronal view\n",
    "![SegmentLocal](images/segm_comput_FS7_coronal.gif \"segment\")\n",
    "\n",
    "### FS 7 sagittal view\n",
    "![SegmentLocal](images/segm_comput_FS7_sagittal.gif \"segment\")\n",
    "\n",
    "\n",
    "## Clinical data\n",
    "\n",
    "## FS5\n",
    "\n",
    "### FS 5 axial view\n",
    "![SegmentLocal](images/segm_clinical_FS5_axial.gif \"segment\")\n",
    "\n",
    "### FS 5 coronal view\n",
    "![SegmentLocal](images/segm_clinical_FS5_coronal.gif \"segment\")\n",
    "\n",
    "### FS 5 sagittal view\n",
    "![SegmentLocal](images/segm_clinical_FS5_sagittal.gif \"segment\")\n",
    "\n",
    "## FS6\n",
    "\n",
    "### FS 6 axial view\n",
    "![SegmentLocal](images/segm_clinical_FS6_axial.gif \"segment\")\n",
    "\n",
    "### FS 6 coronal view\n",
    "![SegmentLocal](images/segm_clinical_FS6_coronal.gif \"segment\")\n",
    "\n",
    "### FS 6 sagittal view\n",
    "![SegmentLocal](images/segm_clinical_FS6_sagittal.gif \"segment\")\n",
    "\n",
    "## FS7\n",
    "\n",
    "### FS 7 axial view\n",
    "![SegmentLocal](images/segm_clinical_FS7_axial.gif \"segment\")\n",
    "\n",
    "### FS 7 coronal view\n",
    "![SegmentLocal](images/segm_clinical_FS7_coronal.gif \"segment\")\n",
    "\n",
    "### FS 7 sagittal view\n",
    "![SegmentLocal](images/segm_clinical_FS7_sagittal.gif \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45638e5",
   "metadata": {},
   "source": [
    "# MRIQC\n",
    "\n",
    "Quality control of the input images performed with MRIQC 22.0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ea05aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = cohort\n",
    "df_data[\"PATNO_id\"] = (\n",
    "    \"sub-\" + df_data[\"PATNO\"].astype(str) + \"_ses-\" + df_data[\"EVENT_ID\"]\n",
    ")\n",
    "\n",
    "# exclude images due to the preprocessing failure\n",
    "failed = pd.read_csv(\"failed.csv\")\n",
    "\n",
    "for i in failed[\"PATNO_id\"]:\n",
    "    df_data = df_data[df_data[\"PATNO_id\"].str.contains(f\"{i}\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "917f814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qc = df_data\n",
    "\n",
    "metrics = [\n",
    "    \"cjv\",\n",
    "    \"cnr\",\n",
    "    \"fber\",\n",
    "    \"qi_1\",\n",
    "    \"qi_2\",\n",
    "    \"rpve_gm\",\n",
    "    \"snr_gm\",\n",
    "    \"snr_total\",\n",
    "    \"snrd_gm\",\n",
    "    \"snrd_total\",\n",
    "]\n",
    "\n",
    "for subj in df_qc[\"PATNO\"]:\n",
    "    for metric in metrics:\n",
    "        event = df_qc.loc[df_qc[\"PATNO\"] == subj, \"EVENT_ID\"].iloc[0]\n",
    "        file = f\"mriqc/output/sub-{subj}/ses-{event}/anat/sub-{subj}_T1w.json\"\n",
    "\n",
    "        with open(file, \"r\") as fp:\n",
    "            lines = fp.readlines()\n",
    "            for line in lines:\n",
    "                if line.find(f\"{metric}\") != -1:\n",
    "                    # print(float(line.split()[1].rstrip(',')))\n",
    "                    df_qc.loc[\n",
    "                        df_qc[\"PATNO\"] == subj,\n",
    "                        metric,\n",
    "                    ] = float(line.split()[1].rstrip(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21fa5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "group1 = df_qc.loc[df_qc[\"dx_group\"].isin([\"PD-MCI\", \"PD-non-MCI\"])]\n",
    "group2 = df_qc[df_qc[\"dx_group\"] == \"HC\"]\n",
    "\n",
    "group_qc = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    group_qc[f\"t_{metric}\"], group_qc[f\"p_{metric}\"] = ttest_ind(\n",
    "        group1[f\"{metric}\"], group2[f\"{metric}\"], nan_policy=\"omit\"\n",
    "    )\n",
    "    group_qc[f\"t_{metric}\"], group_qc[f\"p_{metric}\"] = ttest_ind(\n",
    "        group1[f\"{metric}\"], group2[f\"{metric}\"], nan_policy=\"omit\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b25232c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t_cjv': -0.7766789986180176,\n",
       " 'p_cjv': 0.437934720731634,\n",
       " 't_cnr': 1.0049122283881682,\n",
       " 'p_cnr': 0.31571535034484033,\n",
       " 't_fber': -1.1696356002964046,\n",
       " 'p_fber': 0.2430375340598295,\n",
       " 't_qi_1': 2.023467147723185,\n",
       " 'p_qi_1': 0.043874509911540266,\n",
       " 't_qi_2': 0.4917854785797646,\n",
       " 'p_qi_2': 0.6232157103253076,\n",
       " 't_rpve_gm': -1.120845699018451,\n",
       " 'p_rpve_gm': 0.2632127745550855,\n",
       " 't_snr_gm': 2.9057287112429977,\n",
       " 'p_snr_gm': 0.003925155899501688,\n",
       " 't_snr_total': 3.232567120661708,\n",
       " 'p_snr_total': 0.0013576246535719739,\n",
       " 't_snrd_gm': 1.8129864091092671,\n",
       " 'p_snrd_gm': 0.07079173089514203,\n",
       " 't_snrd_total': 1.7383590539942884,\n",
       " 'p_snrd_total': 0.0831309393696809}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_qc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082c9267",
   "metadata": {},
   "source": [
    "# Postprocessing\n",
    "\n",
    "## Computational analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5543b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract structural measures\n",
    "\n",
    "aseg_table = df_data\n",
    "\n",
    "ROIs = [\n",
    "    \"Left-Lateral-Ventricle\",\n",
    "    \"Left-Inf-Lat-Vent\",\n",
    "    \"Left-Cerebellum-White-Matter\",\n",
    "    \"Left-Cerebellum-Cortex\",\n",
    "    \"Left-Thalamus\",\n",
    "    \"Left-Caudate\",\n",
    "    \"Left-Putamen\",\n",
    "    \"Left-Pallidum\",\n",
    "    \"3rd-Ventricle\",\n",
    "    \"4th-Ventricle\",\n",
    "    \"Brain-Stem\",\n",
    "    \"Left-Hippocampus\",\n",
    "    \"Left-Amygdala\",\n",
    "    \"CSF\",\n",
    "    \"Left-Accumbens-area\",\n",
    "    \"Left-VentralDC\",\n",
    "    \"Left-vessel\",\n",
    "    \"Left-choroid-plexus\",\n",
    "    \"Right-Lateral-Ventricle\",\n",
    "    \"Right-Inf-Lat-Vent\",\n",
    "    \"Right-Cerebellum-White-Matter\",\n",
    "    \"Right-Cerebellum-Cortex\",\n",
    "    \"Right-Thalamus\",\n",
    "    \"Right-Caudate\",\n",
    "    \"Right-Putamen\",\n",
    "    \"Right-Pallidum\",\n",
    "    \"Right-Hippocampus\",\n",
    "    \"Right-Amygdala\",\n",
    "    \"Right-Accumbens-area\",\n",
    "    \"Right-VentralDC\",\n",
    "    \"Right-vessel\",\n",
    "    \"Right-choroid-plexus\",\n",
    "    \"5th-Ventricle\",\n",
    "    \"Optic-Chiasm\",\n",
    "    \"CC_Posterior\",\n",
    "    \"CC_Mid_Posterior\",\n",
    "    \"CC_Central\",\n",
    "    \"CC_Mid_Anterior\",\n",
    "    \"CC_Anterior\",\n",
    "]\n",
    "\n",
    "ROIs_aparc = [\n",
    "    \"G_and_S_frontomargin\",\n",
    "    \"G_and_S_occipital_inf\",\n",
    "    \"G_and_S_paracentral\",\n",
    "    \"G_and_S_subcentral\",\n",
    "    \"G_and_S_transv_frontopol\",\n",
    "    \"G_and_S_cingul-Ant\",\n",
    "    \"G_and_S_cingul-Mid-Ant\",\n",
    "    \"G_and_S_cingul-Mid-Post\",\n",
    "    \"G_cingul-Post-dorsal\",\n",
    "    \"G_cingul-Post-ventral\",\n",
    "    \"G_cuneus\",\n",
    "    \"G_front_inf-Opercular\",\n",
    "    \"G_front_inf-Orbital\",\n",
    "    \"G_front_inf-Triangul\",\n",
    "    \"G_front_middle\",\n",
    "    \"G_front_sup\",\n",
    "    \"G_Ins_lg_and_S_cent_ins\",\n",
    "    \"G_insular_short\",\n",
    "    \"G_occipital_middle\",\n",
    "    \"G_occipital_sup\",\n",
    "    \"G_oc-temp_lat-fusifor\",\n",
    "    \"G_oc-temp_med-Lingual\",\n",
    "    \"G_oc-temp_med-Parahip\",\n",
    "    \"G_orbital\",\n",
    "    \"G_pariet_inf-Angular\",\n",
    "    \"G_pariet_inf-Supramar\",\n",
    "    \"G_parietal_sup\",\n",
    "    \"G_postcentral\",\n",
    "    \"G_precentral\",\n",
    "    \"G_precuneus\",\n",
    "    \"G_rectus\",\n",
    "    \"G_subcallosal\",\n",
    "    \"G_temp_sup-G_T_transv\",\n",
    "    \"G_temp_sup-Lateral\",\n",
    "    \"G_temp_sup-Plan_polar\",\n",
    "    \"G_temp_sup-Plan_tempo\",\n",
    "    \"G_temporal_inf\",\n",
    "    \"G_temporal_middle\",\n",
    "    \"Lat_Fis-ant-Horizont\",\n",
    "    \"Lat_Fis-ant-Vertical\",\n",
    "    \"Lat_Fis-post\",\n",
    "    \"Pole_occipital\",\n",
    "    \"Pole_temporal\",\n",
    "    \"S_calcarine\",\n",
    "    \"S_central\",\n",
    "    \"S_cingul-Marginalis\",\n",
    "    \"S_circular_insula_ant\",\n",
    "    \"S_circular_insula_inf\",\n",
    "    \"S_circular_insula_sup\",\n",
    "    \"S_collat_transv_ant\",\n",
    "    \"S_collat_transv_post\",\n",
    "    \"S_front_inf\",\n",
    "    \"S_front_middle\",\n",
    "    \"S_front_sup\",\n",
    "    \"S_interm_prim-Jensen\",\n",
    "    \"S_intrapariet_and_P_trans\",\n",
    "    \"S_oc_middle_and_Lunatus\",\n",
    "    \"S_oc_sup_and_transversal\",\n",
    "    \"S_occipital_ant\",\n",
    "    \"S_oc-temp_lat\",\n",
    "    \"S_oc-temp_med_and_Lingual\",\n",
    "    \"S_orbital_lateral\",\n",
    "    \"S_orbital_med-olfact\",\n",
    "    \"S_orbital-H_Shaped\",\n",
    "    \"S_parieto_occipital\",\n",
    "    \"S_pericallosal\",\n",
    "    \"S_postcentral\",\n",
    "    \"S_precentral-inf-part\",\n",
    "    \"S_precentral-sup-part\",\n",
    "    \"S_suborbital\",\n",
    "    \"S_subparietal\",\n",
    "    \"S_temporal_inf\",\n",
    "    \"S_temporal_sup\",\n",
    "    \"S_temporal_transverse\",\n",
    "]\n",
    "\n",
    "\n",
    "# FS 6 has different ROI labels\n",
    "ROIs_aparc_FS6 = [\n",
    "    \"G&S_frontomargin\",\n",
    "    \"G&S_occipital_inf\",\n",
    "    \"G&S_paracentral\",\n",
    "    \"G&S_subcentral\",\n",
    "    \"G&S_transv_frontopol\",\n",
    "    \"G&S_cingul-Ant\",\n",
    "    \"G&S_cingul-Mid-Ant\",\n",
    "    \"G&S_cingul-Mid-Post\",\n",
    "    \"G_Ins_lg&S_cent_ins\",\n",
    "    \"S_intrapariet&P_trans\",\n",
    "    \"S_oc_middle&Lunatus\",\n",
    "    \"S_oc_sup&transversal\",\n",
    "    \"S_oc-temp_med&Lingual\",\n",
    "]\n",
    "\n",
    "for subj in aseg_table[\"PATNO_id\"]:\n",
    "    for version in [\"FS5\", \"FS6\", \"FS7\"]:\n",
    "        # extract TIV\n",
    "        file = \"stats/{version}/{subidd}/stats/aseg.stats\".format(\n",
    "            subidd=subj, version=version\n",
    "        )\n",
    "        with open(file, \"r\") as fp:\n",
    "            # read all lines in a list\n",
    "            lines = fp.readlines()\n",
    "            for line in lines:\n",
    "                # check if string present on a current line\n",
    "                if line.find(\"Estimated Total Intracranial Volume\") != -1:\n",
    "                    aseg_table.loc[\n",
    "                        aseg_table[\"PATNO_id\"] == subj,\n",
    "                        \"TIV_{version}\".format(version=version),\n",
    "                    ] = float(line.split(\",\")[3])\n",
    "\n",
    "                    # aseg_table[\"TIV{ses}\".format(ses = session)] = float(out)\n",
    "\n",
    "        # extract ROIs volume\n",
    "        for roi in ROIs:\n",
    "\n",
    "            file = \"stats/{version}/{subidd}/stats/aseg.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        aseg_table.loc[\n",
    "                            aseg_table[\"PATNO_id\"] == subj,\n",
    "                            roi + \"_\" + version,\n",
    "                        ] = float(line.split()[3])\n",
    "        # volumes\n",
    "        # extract cortical lh volumes\n",
    "        for roi in ROIs_aparc:\n",
    "\n",
    "            file = \"stats/{version}/{subidd}/stats/lh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        aseg_table.loc[\n",
    "                            aseg_table[\"PATNO_id\"] == subj,\n",
    "                            roi + \"_lh_vol_\" + version,\n",
    "                        ] = float(line.split()[3])\n",
    "\n",
    "        # extract cortical rh volumes\n",
    "        for roi in ROIs_aparc:\n",
    "\n",
    "            file = \"stats/{version}/{subidd}/stats/rh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        aseg_table.loc[\n",
    "                            aseg_table[\"PATNO_id\"] == subj,\n",
    "                            roi + \"_rh_vol_\" + version,\n",
    "                        ] = float(line.split()[3])\n",
    "\n",
    "        # surface area\n",
    "        # extract cortical lh surface area\n",
    "        for roi in ROIs_aparc:\n",
    "\n",
    "            file = \"stats/{version}/{subidd}/stats/lh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        aseg_table.loc[\n",
    "                            aseg_table[\"PATNO_id\"] == subj,\n",
    "                            roi + \"_lh_surf_\" + version,\n",
    "                        ] = float(line.split()[2])\n",
    "\n",
    "        # extract cortical rh surface area\n",
    "        for roi in ROIs_aparc:\n",
    "\n",
    "            file = \"stats/{version}/{subidd}/stats/rh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        aseg_table.loc[\n",
    "                            aseg_table[\"PATNO_id\"] == subj,\n",
    "                            roi + \"_rh_surf_\" + version,\n",
    "                        ] = float(line.split()[2])\n",
    "\n",
    "        # cortical thickness\n",
    "        # extract cortical lh cortical thickness\n",
    "        for roi in ROIs_aparc:\n",
    "\n",
    "            file = \"stats/{version}/{subidd}/stats/lh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        aseg_table.loc[\n",
    "                            aseg_table[\"PATNO_id\"] == subj,\n",
    "                            roi + \"_lh_ct_\" + version,\n",
    "                        ] = float(line.split()[4])\n",
    "\n",
    "        # extract cortical rh cortical thickness\n",
    "        for roi in ROIs_aparc:\n",
    "\n",
    "            file = \"stats/{version}/{subidd}/stats/rh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        aseg_table.loc[\n",
    "                            aseg_table[\"PATNO_id\"] == subj,\n",
    "                            roi + \"_rh_ct_\" + version,\n",
    "                        ] = float(line.split()[4])\n",
    "\n",
    "for subj in aseg_table[\"PATNO_id\"]:\n",
    "    for version in [\"FS6\"]:\n",
    "\n",
    "        # extract cortical lh volume\n",
    "        for roi in ROIs_aparc_FS6:\n",
    "\n",
    "            file = \"stats/{version}/{subidd}/stats/lh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        aseg_table.loc[\n",
    "                            aseg_table[\"PATNO_id\"] == subj,\n",
    "                            roi + \"_lh_vol_\" + version,\n",
    "                        ] = float(line.split()[3])\n",
    "\n",
    "        # extract cortical rh volume\n",
    "        for roi in ROIs_aparc_FS6:\n",
    "\n",
    "            file = \"stats/{version}/{subidd}/stats/rh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        aseg_table.loc[\n",
    "                            aseg_table[\"PATNO_id\"] == subj,\n",
    "                            roi + \"_rh_vol_\" + version,\n",
    "                        ] = float(line.split()[3])\n",
    "\n",
    "        # extract cortical lh surface area\n",
    "        for roi in ROIs_aparc_FS6:\n",
    "\n",
    "            file = \"stats/{version}/{subidd}/stats/lh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        aseg_table.loc[\n",
    "                            aseg_table[\"PATNO_id\"] == subj,\n",
    "                            roi + \"_lh_surf_\" + version,\n",
    "                        ] = float(line.split()[2])\n",
    "\n",
    "        # extract cortical rh surface area\n",
    "        for roi in ROIs_aparc_FS6:\n",
    "\n",
    "            file = \"stats/{version}/{subidd}/stats/rh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        aseg_table.loc[\n",
    "                            aseg_table[\"PATNO_id\"] == subj,\n",
    "                            roi + \"_rh_surf_\" + version,\n",
    "                        ] = float(line.split()[2])\n",
    "\n",
    "        # extract cortical lh cortical thickness\n",
    "        for roi in ROIs_aparc_FS6:\n",
    "\n",
    "            file = \"stats/{version}/{subidd}/stats/lh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        aseg_table.loc[\n",
    "                            aseg_table[\"PATNO_id\"] == subj,\n",
    "                            roi + \"_lh_ct_\" + version,\n",
    "                        ] = float(line.split()[4])\n",
    "\n",
    "        # extract cortical rh cortical thickness\n",
    "        for roi in ROIs_aparc_FS6:\n",
    "\n",
    "            file = \"stats/{version}/{subidd}/stats/rh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        aseg_table.loc[\n",
    "                            aseg_table[\"PATNO_id\"] == subj,\n",
    "                            roi + \"_rh_ct_\" + version,\n",
    "                        ] = float(line.split()[4])\n",
    "\n",
    "# rename FS6 ROIs to match ROI labels in FS5 and 7\n",
    "aseg_table.columns = aseg_table.columns.str.replace(\"&\", \"_and_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "974c9c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate V2-V1/V1 and take an absolute value\n",
    "\n",
    "ROIs = [\n",
    "    \"Left-Lateral-Ventricle\",\n",
    "    \"Left-Inf-Lat-Vent\",\n",
    "    \"Left-Cerebellum-White-Matter\",\n",
    "    \"Left-Cerebellum-Cortex\",\n",
    "    \"Left-Thalamus\",\n",
    "    \"Left-Caudate\",\n",
    "    \"Left-Putamen\",\n",
    "    \"Left-Pallidum\",\n",
    "    \"3rd-Ventricle\",\n",
    "    \"4th-Ventricle\",\n",
    "    \"Brain-Stem\",\n",
    "    \"Left-Hippocampus\",\n",
    "    \"Left-Amygdala\",\n",
    "    \"CSF\",\n",
    "    \"Left-Accumbens-area\",\n",
    "    \"Left-VentralDC\",\n",
    "    \"Left-vessel\",\n",
    "    \"Left-choroid-plexus\",\n",
    "    \"Right-Lateral-Ventricle\",\n",
    "    \"Right-Inf-Lat-Vent\",\n",
    "    \"Right-Cerebellum-White-Matter\",\n",
    "    \"Right-Cerebellum-Cortex\",\n",
    "    \"Right-Thalamus\",\n",
    "    \"Right-Caudate\",\n",
    "    \"Right-Putamen\",\n",
    "    \"Right-Pallidum\",\n",
    "    \"Right-Hippocampus\",\n",
    "    \"Right-Amygdala\",\n",
    "    \"Right-Accumbens-area\",\n",
    "    \"Right-VentralDC\",\n",
    "    \"Right-vessel\",\n",
    "    \"Right-choroid-plexus\",\n",
    "    \"5th-Ventricle\",\n",
    "    \"Optic-Chiasm\",\n",
    "    \"CC_Posterior\",\n",
    "    \"CC_Mid_Posterior\",\n",
    "    \"CC_Central\",\n",
    "    \"CC_Mid_Anterior\",\n",
    "    \"CC_Anterior\",\n",
    "]\n",
    "\n",
    "ROIs_bil = [\n",
    "    \"G_and_S_frontomargin\",\n",
    "    \"G_and_S_occipital_inf\",\n",
    "    \"G_and_S_paracentral\",\n",
    "    \"G_and_S_subcentral\",\n",
    "    \"G_and_S_transv_frontopol\",\n",
    "    \"G_and_S_cingul-Ant\",\n",
    "    \"G_and_S_cingul-Mid-Ant\",\n",
    "    \"G_and_S_cingul-Mid-Post\",\n",
    "    \"G_cingul-Post-dorsal\",\n",
    "    \"G_cingul-Post-ventral\",\n",
    "    \"G_cuneus\",\n",
    "    \"G_front_inf-Opercular\",\n",
    "    \"G_front_inf-Orbital\",\n",
    "    \"G_front_inf-Triangul\",\n",
    "    \"G_front_middle\",\n",
    "    \"G_front_sup\",\n",
    "    \"G_Ins_lg_and_S_cent_ins\",\n",
    "    \"G_insular_short\",\n",
    "    \"G_occipital_middle\",\n",
    "    \"G_occipital_sup\",\n",
    "    \"G_oc-temp_lat-fusifor\",\n",
    "    \"G_oc-temp_med-Lingual\",\n",
    "    \"G_oc-temp_med-Parahip\",\n",
    "    \"G_orbital\",\n",
    "    \"G_pariet_inf-Angular\",\n",
    "    \"G_pariet_inf-Supramar\",\n",
    "    \"G_parietal_sup\",\n",
    "    \"G_postcentral\",\n",
    "    \"G_precentral\",\n",
    "    \"G_precuneus\",\n",
    "    \"G_rectus\",\n",
    "    \"G_subcallosal\",\n",
    "    \"G_temp_sup-G_T_transv\",\n",
    "    \"G_temp_sup-Lateral\",\n",
    "    \"G_temp_sup-Plan_polar\",\n",
    "    \"G_temp_sup-Plan_tempo\",\n",
    "    \"G_temporal_inf\",\n",
    "    \"G_temporal_middle\",\n",
    "    \"Lat_Fis-ant-Horizont\",\n",
    "    \"Lat_Fis-ant-Vertical\",\n",
    "    \"Lat_Fis-post\",\n",
    "    \"Pole_occipital\",\n",
    "    \"Pole_temporal\",\n",
    "    \"S_calcarine\",\n",
    "    \"S_central\",\n",
    "    \"S_cingul-Marginalis\",\n",
    "    \"S_circular_insula_ant\",\n",
    "    \"S_circular_insula_inf\",\n",
    "    \"S_circular_insula_sup\",\n",
    "    \"S_collat_transv_ant\",\n",
    "    \"S_collat_transv_post\",\n",
    "    \"S_front_inf\",\n",
    "    \"S_front_middle\",\n",
    "    \"S_front_sup\",\n",
    "    \"S_interm_prim-Jensen\",\n",
    "    \"S_intrapariet_and_P_trans\",\n",
    "    \"S_oc_middle_and_Lunatus\",\n",
    "    \"S_oc_sup_and_transversal\",\n",
    "    \"S_occipital_ant\",\n",
    "    \"S_oc-temp_lat\",\n",
    "    \"S_oc-temp_med_and_Lingual\",\n",
    "    \"S_orbital_lateral\",\n",
    "    \"S_orbital_med-olfact\",\n",
    "    \"S_orbital-H_Shaped\",\n",
    "    \"S_parieto_occipital\",\n",
    "    \"S_pericallosal\",\n",
    "    \"S_postcentral\",\n",
    "    \"S_precentral-inf-part\",\n",
    "    \"S_precentral-sup-part\",\n",
    "    \"S_suborbital\",\n",
    "    \"S_subparietal\",\n",
    "    \"S_temporal_inf\",\n",
    "    \"S_temporal_sup\",\n",
    "    \"S_temporal_transverse\",\n",
    "]\n",
    "\n",
    "\n",
    "for roi in ROIs:\n",
    "    for subj in aseg_table[\"PATNO_id\"]:\n",
    "        # calculate (Vol 2 - Vol 1) / Vol 1\n",
    "        aseg_table[\"FS7_6_pct_{roi}\".format(roi=roi)] = (\n",
    "            (\n",
    "                aseg_table[\"{roi}_FS7\".format(roi=roi)]\n",
    "                - aseg_table[\"{roi}_FS6\".format(roi=roi)]\n",
    "            )\n",
    "            / aseg_table[\"{roi}_FS6\".format(roi=roi)]\n",
    "        ).abs()\n",
    "        aseg_table[\"FS7_5_pct_{roi}\".format(roi=roi)] = (\n",
    "            (\n",
    "                aseg_table[\"{roi}_FS7\".format(roi=roi)]\n",
    "                - aseg_table[\"{roi}_FS5\".format(roi=roi)]\n",
    "            )\n",
    "            / aseg_table[\"{roi}_FS5\".format(roi=roi)]\n",
    "        ).abs()\n",
    "        aseg_table[\"FS6_5_pct_{roi}\".format(roi=roi)] = (\n",
    "            (\n",
    "                aseg_table[\"{roi}_FS6\".format(roi=roi)]\n",
    "                - aseg_table[\"{roi}_FS5\".format(roi=roi)]\n",
    "            )\n",
    "            / aseg_table[\"{roi}_FS5\".format(roi=roi)]\n",
    "        ).abs()\n",
    "\n",
    "for roi in ROIs_bil:\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        for subj in aseg_table[\"PATNO_id\"]:\n",
    "            for i in [\"vol\", \"surf\", \"ct\"]:\n",
    "                # calculate (Vol 2 - Vol 1) / Vol 1\n",
    "                aseg_table[f\"FS7_6_pct_{hemi}_{roi}_{i}\"] = (\n",
    "                    (\n",
    "                        aseg_table[f\"{roi}_{hemi}_{i}_FS7\"]\n",
    "                        - aseg_table[f\"{roi}_{hemi}_{i}_FS6\"]\n",
    "                    )\n",
    "                    / aseg_table[f\"{roi}_{hemi}_{i}_FS6\"]\n",
    "                ).abs()\n",
    "                aseg_table[f\"FS7_5_pct_{hemi}_{roi}_{i}\"] = (\n",
    "                    (\n",
    "                        aseg_table[f\"{roi}_{hemi}_{i}_FS7\"]\n",
    "                        - aseg_table[f\"{roi}_{hemi}_{i}_FS5\"]\n",
    "                    )\n",
    "                    / aseg_table[f\"{roi}_{hemi}_{i}_FS5\"]\n",
    "                ).abs()\n",
    "                aseg_table[f\"FS6_5_pct_{hemi}_{roi}_{i}\"] = (\n",
    "                    (\n",
    "                        aseg_table[f\"{roi}_{hemi}_{i}_FS6\"]\n",
    "                        - aseg_table[f\"{roi}_{hemi}_{i}_FS5\"]\n",
    "                    )\n",
    "                    / aseg_table[f\"{roi}_{hemi}_{i}_FS5\"]\n",
    "                ).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b720ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate V1 - V2 diff and take an absolute value\n",
    "\n",
    "\n",
    "for roi in ROIs:\n",
    "    for subj in aseg_table[\"PATNO_id\"]:\n",
    "        # calculate (Vol 2 - Vol 1)\n",
    "        aseg_table[\"FS7_6_diff_{roi}\".format(roi=roi)] = (\n",
    "            (\n",
    "                aseg_table[\"{roi}_FS7\".format(roi=roi)]\n",
    "                - aseg_table[\"{roi}_FS6\".format(roi=roi)]\n",
    "            )\n",
    "        ).abs()\n",
    "        aseg_table[\"FS7_5_diff_{roi}\".format(roi=roi)] = (\n",
    "            (\n",
    "                aseg_table[\"{roi}_FS7\".format(roi=roi)]\n",
    "                - aseg_table[\"{roi}_FS5\".format(roi=roi)]\n",
    "            )\n",
    "        ).abs()\n",
    "        aseg_table[\"FS6_5_diff_{roi}\".format(roi=roi)] = (\n",
    "            (\n",
    "                aseg_table[\"{roi}_FS6\".format(roi=roi)]\n",
    "                - aseg_table[\"{roi}_FS5\".format(roi=roi)]\n",
    "            )\n",
    "        ).abs()\n",
    "\n",
    "for roi in ROIs_bil:\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        for subj in aseg_table[\"PATNO_id\"]:\n",
    "            for i in [\"vol\", \"surf\", \"ct\"]:\n",
    "                # calculate (Vol 2 - Vol 1)\n",
    "                aseg_table[f\"FS7_6_diff_{hemi}_{roi}_{i}\"] = (\n",
    "                    (\n",
    "                        aseg_table[f\"{roi}_{hemi}_{i}_FS7\"]\n",
    "                        - aseg_table[f\"{roi}_{hemi}_{i}_FS6\"]\n",
    "                    )\n",
    "                ).abs()\n",
    "                aseg_table[f\"FS7_5_diff_{hemi}_{roi}_{i}\"] = (\n",
    "                    (\n",
    "                        aseg_table[f\"{roi}_{hemi}_{i}_FS7\"]\n",
    "                        - aseg_table[f\"{roi}_{hemi}_{i}_FS5\"]\n",
    "                    )\n",
    "                ).abs()\n",
    "                aseg_table[f\"FS6_5_diff_{hemi}_{roi}_{i}\"] = (\n",
    "                    (\n",
    "                        aseg_table[f\"{roi}_{hemi}_{i}_FS6\"]\n",
    "                        - aseg_table[f\"{roi}_{hemi}_{i}_FS5\"]\n",
    "                    )\n",
    "                ).abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ea91cb",
   "metadata": {},
   "source": [
    "## stats - between version differences (software variability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b0a52c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paired t-test\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "t_paired_76 = {}\n",
    "t_paired_75 = {}\n",
    "t_paired_65 = {}\n",
    "\n",
    "for roi in ROIs:\n",
    "    (\n",
    "        t_paired_76[\"t_{roi}\".format(roi=roi)],\n",
    "        t_paired_76[\"p_{roi}\".format(roi=roi)],\n",
    "    ) = stats.ttest_rel(\n",
    "        aseg_table[\"{roi}_FS7\".format(roi=roi)],\n",
    "        aseg_table[\"{roi}_FS6\".format(roi=roi)],\n",
    "        nan_policy=\"omit\",\n",
    "    )\n",
    "    (\n",
    "        t_paired_75[\"t_{roi}\".format(roi=roi)],\n",
    "        t_paired_75[\"p_{roi}\".format(roi=roi)],\n",
    "    ) = stats.ttest_rel(\n",
    "        aseg_table[\"{roi}_FS7\".format(roi=roi)],\n",
    "        aseg_table[\"{roi}_FS5\".format(roi=roi)],\n",
    "        nan_policy=\"omit\",\n",
    "    )\n",
    "    (\n",
    "        t_paired_65[\"t_{roi}\".format(roi=roi)],\n",
    "        t_paired_65[\"p_{roi}\".format(roi=roi)],\n",
    "    ) = stats.ttest_rel(\n",
    "        aseg_table[\"{roi}_FS6\".format(roi=roi)],\n",
    "        aseg_table[\"{roi}_FS5\".format(roi=roi)],\n",
    "        nan_policy=\"omit\",\n",
    "    )\n",
    "\n",
    "for i in [\"vol\", \"surf\", \"ct\"]:\n",
    "    for roi in ROIs_bil:\n",
    "        for hemi in [\"lh\", \"rh\"]:\n",
    "            (\n",
    "                t_paired_76[\"t_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                t_paired_76[\"p_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "            ) = stats.ttest_rel(\n",
    "                aseg_table[\"{roi}_{hemi}_{i}_FS7\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                aseg_table[\"{roi}_{hemi}_{i}_FS6\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "            (\n",
    "                t_paired_75[\"t_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                t_paired_75[\"p_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "            ) = stats.ttest_rel(\n",
    "                aseg_table[\"{roi}_{hemi}_{i}_FS7\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                aseg_table[\"{roi}_{hemi}_{i}_FS5\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "            (\n",
    "                t_paired_65[\"t_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                t_paired_65[\"p_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "            ) = stats.ttest_rel(\n",
    "                aseg_table[\"{roi}_{hemi}_{i}_FS6\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                aseg_table[\"{roi}_{hemi}_{i}_FS5\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "\n",
    "# temp = pd.DataFrame.from_dict(t_paired_76, orient = 'index')\n",
    "# temp.to_csv(\"results_ttest_paired_76.csv\")\n",
    "# temp = pd.DataFrame.from_dict(t_paired_75, orient = 'index')\n",
    "# temp.to_csv(\"results_ttest_paired_75.csv\")\n",
    "# temp = pd.DataFrame.from_dict(t_paired_65, orient = 'index')\n",
    "# temp.to_csv(\"results_ttest_paired_65.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a800b84",
   "metadata": {},
   "source": [
    "## stats - between group differences (PD vs HC) in software variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92e6f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "group1 = aseg_table.loc[aseg_table[\"dx_group\"].isin([\"PD-MCI\", \"PD-non-MCI\"])]\n",
    "group2 = aseg_table[aseg_table[\"dx_group\"] == \"HC\"]\n",
    "\n",
    "t_groups_76 = {}\n",
    "t_groups_75 = {}\n",
    "t_groups_65 = {}\n",
    "\n",
    "for roi in ROIs:\n",
    "    (\n",
    "        t_groups_76[\"t_{roi}\".format(roi=roi)],\n",
    "        t_groups_76[\"p_{roi}\".format(roi=roi)],\n",
    "    ) = ttest_ind(\n",
    "        group1[\"FS7_6_pct_{roi}\".format(roi=roi)],\n",
    "        group2[\"FS7_6_pct_{roi}\".format(roi=roi)],\n",
    "        nan_policy=\"omit\",\n",
    "    )\n",
    "    (\n",
    "        t_groups_75[\"t_{roi}\".format(roi=roi)],\n",
    "        t_groups_75[\"p_{roi}\".format(roi=roi)],\n",
    "    ) = ttest_ind(\n",
    "        group1[\"FS7_5_pct_{roi}\".format(roi=roi)],\n",
    "        group2[\"FS7_5_pct_{roi}\".format(roi=roi)],\n",
    "        nan_policy=\"omit\",\n",
    "    )\n",
    "    (\n",
    "        t_groups_65[\"t_{roi}\".format(roi=roi)],\n",
    "        t_groups_65[\"p_{roi}\".format(roi=roi)],\n",
    "    ) = ttest_ind(\n",
    "        group1[\"FS6_5_pct_{roi}\".format(roi=roi)],\n",
    "        group2[\"FS6_5_pct_{roi}\".format(roi=roi)],\n",
    "        nan_policy=\"omit\",\n",
    "    )\n",
    "\n",
    "for i in [\"vol\", \"surf\", \"ct\"]:\n",
    "    for roi in ROIs_bil:\n",
    "        for hemi in [\"lh\", \"rh\"]:\n",
    "            (\n",
    "                t_groups_76[\"t_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "                t_groups_76[\"p_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "            ) = ttest_ind(\n",
    "                group1[\"FS7_6_pct_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "                group2[\"FS7_6_pct_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "            (\n",
    "                t_groups_75[\"t_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "                t_groups_75[\"p_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "            ) = ttest_ind(\n",
    "                group1[\"FS7_5_pct_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "                group2[\"FS7_5_pct_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "            (\n",
    "                t_groups_65[\"t_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "                t_groups_65[\"p_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "            ) = ttest_ind(\n",
    "                group1[\"FS6_5_pct_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "                group2[\"FS6_5_pct_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "\n",
    "\n",
    "# temp = pd.DataFrame.from_dict(t_groups_76, orient = 'index')\n",
    "# temp.to_csv(\"results_ttest_groups_76.csv\")\n",
    "# temp = pd.DataFrame.from_dict(t_groups_75, orient = 'index')\n",
    "# temp.to_csv(\"results_ttest_groups_75.csv\")\n",
    "# temp = pd.DataFrame.from_dict(t_groups_65, orient = 'index')\n",
    "# temp.to_csv(\"results_ttest_groups_65.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0545499",
   "metadata": {},
   "source": [
    "## stats - correlation between MRIQC and software variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "634c3d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "def correlation(data, yvar, xvars):\n",
    "    Y = data[yvar]\n",
    "    X = data[xvars]\n",
    "    [corr_r, corr_p] = pearsonr(Y, X)\n",
    "    return [corr_r, corr_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e08c188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    \"cjv\",\n",
    "    \"cnr\",\n",
    "    \"fber\",\n",
    "    \"qi_1\",\n",
    "    \"qi_2\",\n",
    "    \"rpve_gm\",\n",
    "    \"snr_gm\",\n",
    "    \"snr_total\",\n",
    "    \"snrd_gm\",\n",
    "    \"snrd_total\",\n",
    "]\n",
    "\n",
    "qc_table = df_qc\n",
    "\n",
    "qc_corr_76 = {}\n",
    "qc_corr_75 = {}\n",
    "qc_corr_65 = {}\n",
    "\n",
    "for i in [\"vol\", \"surf\", \"ct\"]:\n",
    "    for roi in ROIs_bil:\n",
    "        for hemi in [\"lh\", \"rh\"]:\n",
    "            for m in metrics:\n",
    "                qc_table_stat = qc_table.dropna(subset=f\"FS7_6_pct_{hemi}_{roi}_{i}\")\n",
    "                qc_table_stat = qc_table_stat.dropna(subset=f\"{m}\")\n",
    "                (\n",
    "                    qc_corr_76[f\"r_{hemi}_{roi}_{i}_{m}\"],\n",
    "                    qc_corr_76[f\"p_{hemi}_{roi}_{i}_{m}\"],\n",
    "                ) = correlation(qc_table_stat, f\"FS7_6_pct_{hemi}_{roi}_{i}\", f\"{m}\")\n",
    "\n",
    "                qc_table_stat = qc_table.dropna(subset=f\"FS7_5_pct_{hemi}_{roi}_{i}\")\n",
    "                qc_table_stat = qc_table_stat.dropna(subset=f\"{m}\")\n",
    "                (\n",
    "                    qc_corr_75[f\"r_{hemi}_{roi}_{i}_{m}\"],\n",
    "                    qc_corr_75[f\"p_{hemi}_{roi}_{i}_{m}\"],\n",
    "                ) = correlation(qc_table_stat, f\"FS7_5_pct_{hemi}_{roi}_{i}\", f\"{m}\")\n",
    "\n",
    "                qc_table_stat = qc_table.dropna(subset=f\"FS6_5_pct_{hemi}_{roi}_{i}\")\n",
    "                qc_table_stat = qc_table_stat.dropna(subset=f\"{m}\")\n",
    "                (\n",
    "                    qc_corr_65[f\"r_{hemi}_{roi}_{i}_{m}\"],\n",
    "                    qc_corr_65[f\"p_{hemi}_{roi}_{i}_{m}\"],\n",
    "                ) = correlation(qc_table_stat, f\"FS6_5_pct_{hemi}_{roi}_{i}\", f\"{m}\")\n",
    "\n",
    "for roi in ROIs:\n",
    "    for m in metrics:\n",
    "        qc_table_stat = qc_table.replace(np.inf, np.nan)\n",
    "        qc_table_stat = qc_table_stat.dropna(subset=f\"FS7_6_pct_{roi}\")\n",
    "        qc_table_stat = qc_table_stat.dropna(subset=f\"{m}\")\n",
    "        qc_corr_76[f\"r_{roi}_{m}\"], qc_corr_76[f\"p_{roi}_{m}\"] = correlation(\n",
    "            qc_table_stat, f\"FS7_6_pct_{roi}\", f\"{m}\"\n",
    "        )\n",
    "\n",
    "        qc_table_stat = qc_table.replace(np.inf, np.nan)\n",
    "        qc_table_stat = qc_table_stat.dropna(subset=f\"FS7_5_pct_{roi}\")\n",
    "        qc_table_stat = qc_table_stat.dropna(subset=f\"{m}\")\n",
    "        qc_corr_75[f\"r_{roi}_{m}\"], qc_corr_75[f\"p_{roi}_{m}\"] = correlation(\n",
    "            qc_table_stat, f\"FS7_5_pct_{roi}\", f\"{m}\"\n",
    "        )\n",
    "\n",
    "        qc_table_stat = qc_table.replace(np.inf, np.nan)\n",
    "        qc_table_stat = qc_table_stat.dropna(subset=f\"FS6_5_pct_{roi}\")\n",
    "        qc_table_stat = qc_table_stat.dropna(subset=f\"{m}\")\n",
    "        qc_corr_65[f\"r_{roi}_{m}\"], qc_corr_65[f\"p_{roi}_{m}\"] = correlation(\n",
    "            qc_table_stat, f\"FS6_5_pct_{roi}\", f\"{m}\"\n",
    "        )\n",
    "\n",
    "# temp = pd.DataFrame.from_dict(qc_corr_76, orient = 'index')\n",
    "# temp.to_csv(\"qc_corr_76.csv\")\n",
    "# temp = pd.DataFrame.from_dict(qc_corr_75, orient = 'index')\n",
    "# temp.to_csv(\"qc_corr_75.csv\")\n",
    "# temp = pd.DataFrame.from_dict(qc_corr_65, orient = 'index')\n",
    "# temp.to_csv(\"qc_corr_65.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fe6cf5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation for PD PPMI cohort only\n",
    "\n",
    "metrics = [\n",
    "    \"cjv\",\n",
    "    \"cnr\",\n",
    "    \"fber\",\n",
    "    \"qi_1\",\n",
    "    \"qi_2\",\n",
    "    \"rpve_gm\",\n",
    "    \"snr_gm\",\n",
    "    \"snr_total\",\n",
    "    \"snrd_gm\",\n",
    "    \"snrd_total\",\n",
    "]\n",
    "\n",
    "qc_table = df_qc.loc[df_qc[\"dx_group\"].isin([\"PD-MCI\", \"PD-non-MCI\"])]\n",
    "\n",
    "qc_corr_76 = {}\n",
    "qc_corr_75 = {}\n",
    "qc_corr_65 = {}\n",
    "\n",
    "for i in [\"vol\", \"surf\", \"ct\"]:\n",
    "    for roi in ROIs_bil:\n",
    "        for hemi in [\"lh\", \"rh\"]:\n",
    "            for m in metrics:\n",
    "                qc_table_stat = qc_table.dropna(subset=f\"FS7_6_pct_{hemi}_{roi}_{i}\")\n",
    "                qc_table_stat = qc_table_stat.dropna(subset=f\"{m}\")\n",
    "                (\n",
    "                    qc_corr_76[f\"r_{hemi}_{roi}_{i}_{m}\"],\n",
    "                    qc_corr_76[f\"p_{hemi}_{roi}_{i}_{m}\"],\n",
    "                ) = correlation(qc_table_stat, f\"FS7_6_pct_{hemi}_{roi}_{i}\", f\"{m}\")\n",
    "\n",
    "                qc_table_stat = qc_table.dropna(subset=f\"FS7_5_pct_{hemi}_{roi}_{i}\")\n",
    "                qc_table_stat = qc_table_stat.dropna(subset=f\"{m}\")\n",
    "                (\n",
    "                    qc_corr_75[f\"r_{hemi}_{roi}_{i}_{m}\"],\n",
    "                    qc_corr_75[f\"p_{hemi}_{roi}_{i}_{m}\"],\n",
    "                ) = correlation(qc_table_stat, f\"FS7_5_pct_{hemi}_{roi}_{i}\", f\"{m}\")\n",
    "\n",
    "                qc_table_stat = qc_table.dropna(subset=f\"FS6_5_pct_{hemi}_{roi}_{i}\")\n",
    "                qc_table_stat = qc_table_stat.dropna(subset=f\"{m}\")\n",
    "                (\n",
    "                    qc_corr_65[f\"r_{hemi}_{roi}_{i}_{m}\"],\n",
    "                    qc_corr_65[f\"p_{hemi}_{roi}_{i}_{m}\"],\n",
    "                ) = correlation(qc_table_stat, f\"FS6_5_pct_{hemi}_{roi}_{i}\", f\"{m}\")\n",
    "\n",
    "for roi in ROIs:\n",
    "    for m in metrics:\n",
    "        qc_table_stat = qc_table.replace(np.inf, np.nan)\n",
    "        qc_table_stat = qc_table_stat.dropna(subset=f\"FS7_6_pct_{roi}\")\n",
    "        qc_table_stat = qc_table_stat.dropna(subset=f\"{m}\")\n",
    "        qc_corr_76[f\"r_{roi}_{m}\"], qc_corr_76[f\"p_{roi}_{m}\"] = correlation(\n",
    "            qc_table_stat, f\"FS7_6_pct_{roi}\", f\"{m}\"\n",
    "        )\n",
    "\n",
    "        qc_table_stat = qc_table.replace(np.inf, np.nan)\n",
    "        qc_table_stat = qc_table_stat.dropna(subset=f\"FS7_5_pct_{roi}\")\n",
    "        qc_table_stat = qc_table_stat.dropna(subset=f\"{m}\")\n",
    "        qc_corr_75[f\"r_{roi}_{m}\"], qc_corr_75[f\"p_{roi}_{m}\"] = correlation(\n",
    "            qc_table_stat, f\"FS7_5_pct_{roi}\", f\"{m}\"\n",
    "        )\n",
    "\n",
    "        qc_table_stat = qc_table.replace(np.inf, np.nan)\n",
    "        qc_table_stat = qc_table_stat.dropna(subset=f\"FS6_5_pct_{roi}\")\n",
    "        qc_table_stat = qc_table_stat.dropna(subset=f\"{m}\")\n",
    "        qc_corr_65[f\"r_{roi}_{m}\"], qc_corr_65[f\"p_{roi}_{m}\"] = correlation(\n",
    "            qc_table_stat, f\"FS6_5_pct_{roi}\", f\"{m}\"\n",
    "        )\n",
    "\n",
    "# temp = pd.DataFrame.from_dict(qc_corr_76, orient = 'index')\n",
    "# temp.to_csv(\"qc_PD_corr_76.csv\")\n",
    "# temp = pd.DataFrame.from_dict(qc_corr_75, orient = 'index')\n",
    "# temp.to_csv(\"qc_PD_corr_75.csv\")\n",
    "# temp = pd.DataFrame.from_dict(qc_corr_65, orient = 'index')\n",
    "# temp.to_csv(\"qc_PD_corr_65.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffb0271",
   "metadata": {},
   "source": [
    "## stats - Sørensen–Dice coefficient variability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b8db5b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build sets of significant results\n",
    "\n",
    "set_76_vol = {}\n",
    "set_75_vol = {}\n",
    "set_65_vol = {}\n",
    "set_76_surf = {}\n",
    "set_75_surf = {}\n",
    "set_65_surf = {}\n",
    "set_76_ct = {}\n",
    "set_75_ct = {}\n",
    "set_65_ct = {}\n",
    "\n",
    "for roi in ROIs:\n",
    "    set_76_vol[f\"p_{roi}\"] = t_paired_76[f\"p_{roi}\"] < (0.05 / 187)\n",
    "    set_75_vol[f\"p_{roi}\"] = t_paired_75[f\"p_{roi}\"] < (0.05 / 187)\n",
    "    set_65_vol[f\"p_{roi}\"] = t_paired_65[f\"p_{roi}\"] < (0.05 / 187)\n",
    "\n",
    "for roi in ROIs_bil:\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        set_76_vol[f\"{hemi}_{roi}_vol\"] = t_paired_76[f\"p_{hemi}_{roi}_vol\"] < (\n",
    "            0.05 / 187\n",
    "        )\n",
    "        set_75_vol[f\"{hemi}_{roi}_vol\"] = t_paired_75[f\"p_{hemi}_{roi}_vol\"] < (\n",
    "            0.05 / 187\n",
    "        )\n",
    "        set_65_vol[f\"{hemi}_{roi}_vol\"] = t_paired_65[f\"p_{hemi}_{roi}_vol\"] < (\n",
    "            0.05 / 187\n",
    "        )\n",
    "\n",
    "        set_76_surf[f\"{hemi}_{roi}_surf\"] = t_paired_76[f\"p_{hemi}_{roi}_surf\"] < (\n",
    "            0.05 / 148\n",
    "        )\n",
    "        set_75_surf[f\"{hemi}_{roi}_surf\"] = t_paired_75[f\"p_{hemi}_{roi}_surf\"] < (\n",
    "            0.05 / 148\n",
    "        )\n",
    "        set_65_surf[f\"{hemi}_{roi}_surf\"] = t_paired_65[f\"p_{hemi}_{roi}_surf\"] < (\n",
    "            0.05 / 148\n",
    "        )\n",
    "\n",
    "        set_76_ct[f\"{hemi}_{roi}_ct\"] = t_paired_76[f\"p_{hemi}_{roi}_ct\"] < (0.05 / 148)\n",
    "        set_75_ct[f\"{hemi}_{roi}_ct\"] = t_paired_75[f\"p_{hemi}_{roi}_ct\"] < (0.05 / 148)\n",
    "        set_65_ct[f\"{hemi}_{roi}_ct\"] = t_paired_65[f\"p_{hemi}_{roi}_ct\"] < (0.05 / 148)\n",
    "\n",
    "set_76_vol = pd.DataFrame.from_dict(set_76_vol, orient=\"index\")\n",
    "set_75_vol = pd.DataFrame.from_dict(set_75_vol, orient=\"index\")\n",
    "set_65_vol = pd.DataFrame.from_dict(set_65_vol, orient=\"index\")\n",
    "\n",
    "set_76_surf = pd.DataFrame.from_dict(set_76_surf, orient=\"index\")\n",
    "set_75_surf = pd.DataFrame.from_dict(set_75_surf, orient=\"index\")\n",
    "set_65_surf = pd.DataFrame.from_dict(set_65_surf, orient=\"index\")\n",
    "\n",
    "set_76_ct = pd.DataFrame.from_dict(set_76_ct, orient=\"index\")\n",
    "set_75_ct = pd.DataFrame.from_dict(set_75_ct, orient=\"index\")\n",
    "set_65_ct = pd.DataFrame.from_dict(set_65_ct, orient=\"index\")\n",
    "\n",
    "set_76_vol = set_76_vol.loc[set_76_vol[0] == True]\n",
    "set_75_vol = set_75_vol.loc[set_75_vol[0] == True]\n",
    "set_65_vol = set_65_vol.loc[set_65_vol[0] == True]\n",
    "set_76_surf = set_76_surf.loc[set_76_surf[0] == True]\n",
    "set_75_surf = set_75_surf.loc[set_75_surf[0] == True]\n",
    "set_65_surf = set_65_surf.loc[set_65_surf[0] == True]\n",
    "set_76_ct = set_76_ct.loc[set_76_ct[0] == True]\n",
    "set_75_ct = set_75_ct.loc[set_75_ct[0] == True]\n",
    "set_65_ct = set_65_ct.loc[set_65_ct[0] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e5379f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate intersection between the sets\n",
    "\n",
    "set_76_75_vol_inter = set_76_vol.index.intersection(set_75_vol.index)\n",
    "set_76_65_vol_inter = set_76_vol.index.intersection(set_65_vol.index)\n",
    "set_75_65_vol_inter = set_75_vol.index.intersection(set_65_vol.index)\n",
    "\n",
    "set_76_75_surf_inter = set_76_surf.index.intersection(set_75_surf.index)\n",
    "set_76_65_surf_inter = set_76_surf.index.intersection(set_65_surf.index)\n",
    "set_75_65_surf_inter = set_75_surf.index.intersection(set_65_surf.index)\n",
    "\n",
    "set_76_75_ct_inter = set_76_ct.index.intersection(set_75_ct.index)\n",
    "set_76_65_ct_inter = set_76_ct.index.intersection(set_65_ct.index)\n",
    "set_75_65_ct_inter = set_75_ct.index.intersection(set_65_ct.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "777ca405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate coefficients\n",
    "\n",
    "dice_76_75_vol = (2 * len(set_76_75_vol_inter)) / (len(set_76_vol) + len(set_75_vol))\n",
    "dice_76_65_vol = (2 * len(set_76_65_vol_inter)) / (len(set_76_vol) + len(set_65_vol))\n",
    "dice_75_65_vol = (2 * len(set_75_65_vol_inter)) / (len(set_75_vol) + len(set_65_vol))\n",
    "\n",
    "dice_76_75_surf = (2 * len(set_76_75_surf_inter)) / (\n",
    "    len(set_76_surf) + len(set_75_surf)\n",
    ")\n",
    "dice_76_65_surf = (2 * len(set_76_65_surf_inter)) / (\n",
    "    len(set_76_surf) + len(set_65_surf)\n",
    ")\n",
    "dice_75_65_surf = (2 * len(set_75_65_surf_inter)) / (\n",
    "    len(set_75_surf) + len(set_65_surf)\n",
    ")\n",
    "\n",
    "dice_76_75_ct = (2 * len(set_76_75_ct_inter)) / (len(set_76_ct) + len(set_75_ct))\n",
    "dice_76_65_ct = (2 * len(set_76_65_ct_inter)) / (len(set_76_ct) + len(set_65_ct))\n",
    "dice_75_65_ct = (2 * len(set_75_65_ct_inter)) / (len(set_75_ct) + len(set_65_ct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d584df9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6256684491978609 % regions differed in volume between FS7 and FS6\n",
      "0.786096256684492 % regions differed in volume between FS7 and FS5\n",
      "0.7540106951871658 % regions differed in volume between FS6 and FS5\n",
      "0.7567567567567568 % regions differed in surface between FS7 and FS6\n",
      "0.7297297297297297 % regions differed in surface between FS7 and FS5\n",
      "0.722972972972973 % regions differed in surface between FS6 and FS5\n",
      "0.7432432432432432 % regions differed in thickness between FS7 and FS6\n",
      "0.6824324324324325 % regions differed in thickness between FS7 and FS5\n",
      "0.8581081081081081 % regions differed in thickness between FS6 and FS5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    str(len(set_76_vol) / 187)\n",
    "    + \" % regions differed in volume between FS7 and FS6\\n\"\n",
    "    + str(len(set_75_vol) / 187)\n",
    "    + \" % regions differed in volume between FS7 and FS5\\n\"\n",
    "    + str(len(set_65_vol) / 187)\n",
    "    + \" % regions differed in volume between FS6 and FS5\\n\"\n",
    "    + str(len(set_76_surf) / 148)\n",
    "    + \" % regions differed in surface between FS7 and FS6\\n\"\n",
    "    + str(len(set_75_surf) / 148)\n",
    "    + \" % regions differed in surface between FS7 and FS5\\n\"\n",
    "    + str(len(set_65_surf) / 148)\n",
    "    + \" % regions differed in surface between FS6 and FS5\\n\"\n",
    "    + str(len(set_76_ct) / 148)\n",
    "    + \" % regions differed in thickness between FS7 and FS6\\n\"\n",
    "    + str(len(set_75_ct) / 148)\n",
    "    + \" % regions differed in thickness between FS7 and FS5\\n\"\n",
    "    + str(len(set_65_ct) / 148)\n",
    "    + \" % regions differed in thickness between FS6 and FS5\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "18f6e697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Sørensen–Dice coefficients for software variability are:\n",
      " Volume 76 vs 75 = 0.696969696969697\n",
      " Volume 76 vs 65 = 0.6744186046511628\n",
      " Volume 75 vs 65 = 0.8472222222222222\n",
      " Surface 76 vs 75 = 0.7545454545454545\n",
      " Surface 76 vs 65 = 0.7397260273972602\n",
      " Surface 75 vs 65 = 0.7813953488372093\n",
      " Thickness 76 vs 75 = 0.7298578199052133\n",
      " Thickness 76 vs 65 = 0.8607594936708861\n",
      " Thickness 75 vs 65 = 0.8245614035087719\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"The Sørensen–Dice coefficients for software variability are:\\n Volume 76 vs 75 = \"\n",
    "    + str(dice_76_75_vol)\n",
    "    + \"\\n Volume 76 vs 65 = \"\n",
    "    + str(dice_76_65_vol)\n",
    "    + \"\\n Volume 75 vs 65 = \"\n",
    "    + str(dice_75_65_vol)\n",
    "    + \"\\n Surface 76 vs 75 = \"\n",
    "    + str(dice_76_75_surf)\n",
    "    + \"\\n Surface 76 vs 65 = \"\n",
    "    + str(dice_76_65_surf)\n",
    "    + \"\\n Surface 75 vs 65 = \"\n",
    "    + str(dice_75_65_surf)\n",
    "    + \"\\n Thickness 76 vs 75 = \"\n",
    "    + str(dice_76_75_ct)\n",
    "    + \"\\n Thickness 76 vs 65 = \"\n",
    "    + str(dice_76_65_ct)\n",
    "    + \"\\n Thickness 75 vs 65 = \"\n",
    "    + str(dice_75_65_ct)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a905eb90",
   "metadata": {},
   "source": [
    "## Whole-brain Sørensen–Dice coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75354cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "for sub in subj;\n",
    "do\n",
    "    mri_seg_overlap data/FS7/$sub/mri/aparc.a2009s+aseg.mgz data/FS6/$sub/mri/aparc.a2009s+aseg.mgz -o stats/dice/dice_76_$sub.aparc2009.json\n",
    "    mri_seg_overlap data/FS7/$sub/mri/aparc+aseg.mgz data/FS6/$sub/mri/aparc+aseg.mgz -o stats/dice/dice_76_$sub.aparc.json\n",
    "    mri_seg_overlap data/FS7/$sub/mri/aseg.mgz data/FS6/$sub/mri/aseg.mgz -o stats/dice/dice_76_$sub.aseg.json\n",
    "done\n",
    "\n",
    "for sub in subj;\n",
    "do\n",
    "    mri_seg_overlap data/FS7/$sub/mri/aparc.a2009s+aseg.mgz data/FS5/$sub/mri/aparc.a2009s+aseg.mgz -o stats/dice/dice_75_$sub.aparc2009.json\n",
    "    mri_seg_overlap data/FS7/$sub/mri/aparc+aseg.mgz data/FS5/$sub/mri/aparc+aseg.mgz -o stats/dice/dice_75_$sub.aparc.json\n",
    "    mri_seg_overlap data/FS7/$sub/mri/aseg.mgz data/FS5/$sub/mri/aseg.mgz -o stats/dice/dice_75_$sub.aseg.json\n",
    "done\n",
    "\n",
    "for sub in subj;\n",
    "do\n",
    "    mri_seg_overlap data/FS6/$sub/mri/aparc.a2009s+aseg.mgz data/FS5/$sub/mri/aparc.a2009s+aseg.mgz -o stats/dice/dice_65_$sub.aparc2009.json\n",
    "    mri_seg_overlap data/FS6/$sub/mri/aparc+aseg.mgz data/FS5/$sub/mri/aparc+aseg.mgz -o stats/dice/dice_65_$sub.aparc.json\n",
    "    mri_seg_overlap data/FS6/$sub/mri/aseg.mgz data/FS5/$sub/mri/aseg.mgz -o stats/dice/dice_65_$sub.aseg.json\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f598119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for subj in aseg_table[\"PATNO_id\"]:\n",
    "    for pair in [\"76\", \"75\", \"65\"]:\n",
    "        for file in [\"aseg\", \"aparc\", \"aparc2009\"]:\n",
    "            with open(\n",
    "                \"stats/dice/dice_{pair}_{subj}.{file}.json\".format(\n",
    "                    pair=pair, subj=subj, file=file\n",
    "                ),\n",
    "                \"r\",\n",
    "            ) as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "                for key in data[\"measures\"][\"dice\"][\"labels\"]:\n",
    "\n",
    "                    name = data[\"names\"][\"{key}\".format(key=key)]\n",
    "                    dice = data[\"measures\"][\"dice\"][\"labels\"][\"{key}\".format(key=key)]\n",
    "                    aseg_table.loc[\n",
    "                        aseg_table[\"PATNO_id\"] == subj,\n",
    "                        \"dice_FS{pair}_\".format(pair=pair) + name,\n",
    "                    ] = dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6914c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_table = aseg_table.filter(like=\"dice_\")\n",
    "mean = dice_table.mean()\n",
    "sd = dice_table.std()\n",
    "\n",
    "dice_results = {}\n",
    "dice_results[\"mean\"] = mean\n",
    "dice_results[\"sd\"] = sd\n",
    "dice_results = pd.DataFrame.from_dict(dice_results, orient=\"index\")\n",
    "dice_results = dice_results.transpose()\n",
    "# dice_results.to_csv(\"dice_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89a028c",
   "metadata": {},
   "source": [
    "# stats - software variability separately in HC and PD cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "08900842",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_pd = aseg_table.loc[aseg_table[\"dx_group\"].isin([\"PD-MCI\", \"PD-non-MCI\"])]\n",
    "selection_hc = aseg_table[aseg_table[\"dx_group\"] == \"HC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0d161831",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_paired_76_hc = {}\n",
    "t_paired_75_hc = {}\n",
    "t_paired_65_hc = {}\n",
    "t_paired_76_pd = {}\n",
    "t_paired_75_pd = {}\n",
    "t_paired_65_pd = {}\n",
    "\n",
    "# PD\n",
    "for roi in ROIs:\n",
    "    (\n",
    "        t_paired_76_pd[\"t_{roi}\".format(roi=roi)],\n",
    "        t_paired_76_pd[\"p_{roi}\".format(roi=roi)],\n",
    "    ) = stats.ttest_rel(\n",
    "        selection_pd[\"{roi}_FS7\".format(roi=roi)],\n",
    "        selection_pd[\"{roi}_FS6\".format(roi=roi)],\n",
    "        nan_policy=\"omit\",\n",
    "    )\n",
    "    (\n",
    "        t_paired_75_pd[\"t_{roi}\".format(roi=roi)],\n",
    "        t_paired_75_pd[\"p_{roi}\".format(roi=roi)],\n",
    "    ) = stats.ttest_rel(\n",
    "        selection_pd[\"{roi}_FS7\".format(roi=roi)],\n",
    "        selection_pd[\"{roi}_FS5\".format(roi=roi)],\n",
    "        nan_policy=\"omit\",\n",
    "    )\n",
    "    (\n",
    "        t_paired_65_pd[\"t_{roi}\".format(roi=roi)],\n",
    "        t_paired_65_pd[\"p_{roi}\".format(roi=roi)],\n",
    "    ) = stats.ttest_rel(\n",
    "        selection_pd[\"{roi}_FS6\".format(roi=roi)],\n",
    "        selection_pd[\"{roi}_FS5\".format(roi=roi)],\n",
    "        nan_policy=\"omit\",\n",
    "    )\n",
    "\n",
    "for i in [\"vol\", \"surf\", \"ct\"]:\n",
    "    for roi in ROIs_bil:\n",
    "        for hemi in [\"lh\", \"rh\"]:\n",
    "            (\n",
    "                t_paired_76_pd[\"t_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                t_paired_76_pd[\"p_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "            ) = stats.ttest_rel(\n",
    "                selection_pd[\"{roi}_{hemi}_{i}_FS7\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                selection_pd[\"{roi}_{hemi}_{i}_FS6\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "            (\n",
    "                t_paired_75_pd[\"t_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                t_paired_75_pd[\"p_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "            ) = stats.ttest_rel(\n",
    "                selection_pd[\"{roi}_{hemi}_{i}_FS7\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                selection_pd[\"{roi}_{hemi}_{i}_FS5\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "            (\n",
    "                t_paired_65_pd[\"t_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                t_paired_65_pd[\"p_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "            ) = stats.ttest_rel(\n",
    "                selection_pd[\"{roi}_{hemi}_{i}_FS6\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                selection_pd[\"{roi}_{hemi}_{i}_FS5\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "\n",
    "# HC\n",
    "for roi in ROIs:\n",
    "    (\n",
    "        t_paired_76_hc[\"t_{roi}\".format(roi=roi)],\n",
    "        t_paired_76_hc[\"p_{roi}\".format(roi=roi)],\n",
    "    ) = stats.ttest_rel(\n",
    "        selection_hc[\"{roi}_FS7\".format(roi=roi)],\n",
    "        selection_hc[\"{roi}_FS6\".format(roi=roi)],\n",
    "        nan_policy=\"omit\",\n",
    "    )\n",
    "    (\n",
    "        t_paired_75_hc[\"t_{roi}\".format(roi=roi)],\n",
    "        t_paired_75_hc[\"p_{roi}\".format(roi=roi)],\n",
    "    ) = stats.ttest_rel(\n",
    "        selection_hc[\"{roi}_FS7\".format(roi=roi)],\n",
    "        selection_hc[\"{roi}_FS5\".format(roi=roi)],\n",
    "        nan_policy=\"omit\",\n",
    "    )\n",
    "    (\n",
    "        t_paired_65_hc[\"t_{roi}\".format(roi=roi)],\n",
    "        t_paired_65_hc[\"p_{roi}\".format(roi=roi)],\n",
    "    ) = stats.ttest_rel(\n",
    "        selection_hc[\"{roi}_FS6\".format(roi=roi)],\n",
    "        selection_hc[\"{roi}_FS5\".format(roi=roi)],\n",
    "        nan_policy=\"omit\",\n",
    "    )\n",
    "\n",
    "for i in [\"vol\", \"surf\", \"ct\"]:\n",
    "    for roi in ROIs_bil:\n",
    "        for hemi in [\"lh\", \"rh\"]:\n",
    "            (\n",
    "                t_paired_76_hc[\"t_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                t_paired_76_hc[\"p_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "            ) = stats.ttest_rel(\n",
    "                selection_hc[\"{roi}_{hemi}_{i}_FS7\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                selection_hc[\"{roi}_{hemi}_{i}_FS6\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "            (\n",
    "                t_paired_75_hc[\"t_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                t_paired_75_hc[\"p_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "            ) = stats.ttest_rel(\n",
    "                selection_hc[\"{roi}_{hemi}_{i}_FS7\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                selection_hc[\"{roi}_{hemi}_{i}_FS5\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "            (\n",
    "                t_paired_65_hc[\"t_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                t_paired_65_hc[\"p_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "            ) = stats.ttest_rel(\n",
    "                selection_hc[\"{roi}_{hemi}_{i}_FS6\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                selection_hc[\"{roi}_{hemi}_{i}_FS5\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "\n",
    "# temp = pd.DataFrame.from_dict(t_paired_76_pd, orient = 'index')\n",
    "# temp.to_csv(\"results_ttest_paired_76_pd.csv\")\n",
    "# temp = pd.DataFrame.from_dict(t_paired_75_pd, orient = 'index')\n",
    "# temp.to_csv(\"results_ttest_paired_75_pd.csv\")\n",
    "# temp = pd.DataFrame.from_dict(t_paired_65_pd, orient = 'index')\n",
    "# temp.to_csv(\"results_ttest_paired_65_pd.csv\")\n",
    "\n",
    "# temp = pd.DataFrame.from_dict(t_paired_76_hc, orient = 'index')\n",
    "# temp.to_csv(\"results_ttest_paired_76_hc.csv\")\n",
    "# temp = pd.DataFrame.from_dict(t_paired_75_hc, orient = 'index')\n",
    "# temp.to_csv(\"results_ttest_paired_75_hc.csv\")\n",
    "# temp = pd.DataFrame.from_dict(t_paired_65_hc, orient = 'index')\n",
    "# temp.to_csv(\"results_ttest_paired_65_hc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362aa191",
   "metadata": {},
   "source": [
    "# Clinical analyses\n",
    "## subcortical volume analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6c0d7166",
   "metadata": {},
   "outputs": [],
   "source": [
    "aseg_table2 = stage_two\n",
    "\n",
    "aseg_table2[\"PATNO_base\"] = \"sub-\" + aseg_table2[\"PATNO\"].astype(str) + \"_base\"\n",
    "aseg_table2[\"first_id\"] = (\n",
    "    aseg_table2[\"first_visit\"] + \".long.\" + aseg_table2[\"PATNO_base\"]\n",
    ")\n",
    "aseg_table2[\"second_id\"] = (\n",
    "    aseg_table2[\"second_visit\"] + \".long.\" + aseg_table2[\"PATNO_base\"]\n",
    ")\n",
    "\n",
    "# select only PD-non-MCI patients and HC\n",
    "aseg_table2 = stage_two.loc[stage_two[\"dx_group\"].isin([\"HC\", \"PD-non-MCI\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8ed9209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract subcortical volumes\n",
    "\n",
    "ROIs = [\n",
    "    \"Left-Lateral-Ventricle\",\n",
    "    \"Left-Inf-Lat-Vent\",\n",
    "    \"Left-Cerebellum-White-Matter\",\n",
    "    \"Left-Cerebellum-Cortex\",\n",
    "    \"Left-Thalamus\",\n",
    "    \"Left-Caudate\",\n",
    "    \"Left-Putamen\",\n",
    "    \"Left-Pallidum\",\n",
    "    \"3rd-Ventricle\",\n",
    "    \"4th-Ventricle\",\n",
    "    \"Brain-Stem\",\n",
    "    \"Left-Hippocampus\",\n",
    "    \"Left-Amygdala\",\n",
    "    \"CSF\",\n",
    "    \"Left-Accumbens-area\",\n",
    "    \"Left-VentralDC\",\n",
    "    \"Left-vessel\",\n",
    "    \"Left-choroid-plexus\",\n",
    "    \"Right-Lateral-Ventricle\",\n",
    "    \"Right-Inf-Lat-Vent\",\n",
    "    \"Right-Cerebellum-White-Matter\",\n",
    "    \"Right-Cerebellum-Cortex\",\n",
    "    \"Right-Thalamus\",\n",
    "    \"Right-Caudate\",\n",
    "    \"Right-Putamen\",\n",
    "    \"Right-Pallidum\",\n",
    "    \"Right-Hippocampus\",\n",
    "    \"Right-Amygdala\",\n",
    "    \"Right-Accumbens-area\",\n",
    "    \"Right-VentralDC\",\n",
    "    \"Right-vessel\",\n",
    "    \"Right-choroid-plexus\",\n",
    "    \"5th-Ventricle\",\n",
    "    \"Optic-Chiasm\",\n",
    "    \"CC_Posterior\",\n",
    "    \"CC_Mid_Posterior\",\n",
    "    \"CC_Central\",\n",
    "    \"CC_Mid_Anterior\",\n",
    "    \"CC_Anterior\",\n",
    "]\n",
    "\n",
    "\n",
    "# extract first visit\n",
    "for subj in aseg_table2[\"first_id\"]:\n",
    "    for version in [\"FS5\", \"FS6\", \"FS7\"]:\n",
    "        # extract TIV\n",
    "        file = \"stats/{version}/{subj}/stats/aseg.stats\".format(\n",
    "            subj=subj, version=version\n",
    "        )\n",
    "        with open(file, \"r\") as fp:\n",
    "            # read all lines in a list\n",
    "            lines = fp.readlines()\n",
    "            for line in lines:\n",
    "                # check if string present on a current line\n",
    "                if line.find(\"Estimated Total Intracranial Volume\") != -1:\n",
    "                    aseg_table2.loc[\n",
    "                        aseg_table2[\"first_id\"] == subj,\n",
    "                        \"TIV_{version}_first\".format(version=version),\n",
    "                    ] = float(line.split(\",\")[3])\n",
    "\n",
    "                    # aseg_table[\"TIV{ses}\".format(ses = session)] = float(out)\n",
    "\n",
    "        # extract ROIs volume\n",
    "        for roi in ROIs:\n",
    "\n",
    "            file = \"stats/{version}/{subj}/stats/aseg.stats\".format(\n",
    "                subj=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        aseg_table2.loc[\n",
    "                            aseg_table2[\"first_id\"] == subj,\n",
    "                            roi + \"_\" + version + \"_first\",\n",
    "                        ] = float(line.split()[3])\n",
    "\n",
    "# extract second visit\n",
    "for subj in aseg_table2[\"second_id\"]:\n",
    "    for version in [\"FS5\", \"FS6\", \"FS7\"]:\n",
    "        # extract TIV\n",
    "        file = \"stats/{version}/{subj}/stats/aseg.stats\".format(\n",
    "            subj=subj, version=version\n",
    "        )\n",
    "        with open(file, \"r\") as fp:\n",
    "            # read all lines in a list\n",
    "            lines = fp.readlines()\n",
    "            for line in lines:\n",
    "                # check if string present on a current line\n",
    "                if line.find(\"Estimated Total Intracranial Volume\") != -1:\n",
    "                    aseg_table2.loc[\n",
    "                        aseg_table2[\"second_id\"] == subj,\n",
    "                        \"TIV_{version}_second\".format(version=version),\n",
    "                    ] = float(line.split(\",\")[3])\n",
    "\n",
    "                    # aseg_table[\"TIV{ses}\".format(ses = session)] = float(out)\n",
    "\n",
    "        # extract ROIs volume\n",
    "        for roi in ROIs:\n",
    "\n",
    "            file = \"stats/{version}/{subj}/stats/aseg.stats\".format(\n",
    "                subj=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        aseg_table2.loc[\n",
    "                            aseg_table2[\"second_id\"] == subj,\n",
    "                            roi + \"_\" + version + \"_second\",\n",
    "                        ] = float(line.split()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5ab89c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this calculates the change in subcortical volume\n",
    "\n",
    "for roi_bil in ROIs:\n",
    "    for version in [\"FS5\", \"FS6\", \"FS7\"]:\n",
    "        #         # calculate change in subcortical volume\n",
    "        #         aseg_table2[roi_bil + version + \"_change\"] = (\n",
    "        #             aseg_table2[roi_bil + version + \"_second\"] - aseg_table2[roi_bil + version + \"_first\"]\n",
    "        #         )\n",
    "\n",
    "        # calculate percentage of change\n",
    "        aseg_table2[roi_bil + \"_\" + version + \"_change_pct\"] = (\n",
    "            (\n",
    "                aseg_table2[roi_bil + \"_\" + version + \"_second\"]\n",
    "                - aseg_table2[roi_bil + \"_\" + version + \"_first\"]\n",
    "            )\n",
    "            / aseg_table2[roi_bil + \"_\" + version + \"_first\"]\n",
    "        ) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e2d6f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROIs = [\n",
    "    \"Left-Lateral-Ventricle\",\n",
    "    \"Left-Inf-Lat-Vent\",\n",
    "    \"Left-Cerebellum-White-Matter\",\n",
    "    \"Left-Cerebellum-Cortex\",\n",
    "    \"Left-Thalamus\",\n",
    "    \"Left-Caudate\",\n",
    "    \"Left-Putamen\",\n",
    "    \"Left-Pallidum\",\n",
    "    \"3rd-Ventricle\",\n",
    "    \"4th-Ventricle\",\n",
    "    \"Brain-Stem\",\n",
    "    \"Left-Hippocampus\",\n",
    "    \"Left-Amygdala\",\n",
    "    \"CSF\",\n",
    "    \"Left-Accumbens-area\",\n",
    "    \"Left-VentralDC\",\n",
    "    \"Left-vessel\",\n",
    "    \"Left-choroid-plexus\",\n",
    "    \"Right-Lateral-Ventricle\",\n",
    "    \"Right-Inf-Lat-Vent\",\n",
    "    \"Right-Cerebellum-White-Matter\",\n",
    "    \"Right-Cerebellum-Cortex\",\n",
    "    \"Right-Thalamus\",\n",
    "    \"Right-Caudate\",\n",
    "    \"Right-Putamen\",\n",
    "    \"Right-Pallidum\",\n",
    "    \"Right-Hippocampus\",\n",
    "    \"Right-Amygdala\",\n",
    "    \"Right-Accumbens-area\",\n",
    "    \"Right-VentralDC\",\n",
    "    \"Right-choroid-plexus\",\n",
    "    \"Optic-Chiasm\",\n",
    "    \"CC_Posterior\",\n",
    "    \"CC_Mid_Posterior\",\n",
    "    \"CC_Central\",\n",
    "    \"CC_Mid_Anterior\",\n",
    "    \"CC_Anterior\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c7b14",
   "metadata": {},
   "source": [
    "## stats - clinical analysis (subcortical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9843a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial correlation\n",
    "\n",
    "from pingouin import partial_corr\n",
    "\n",
    "ROI_PDnonMCI = aseg_table2.loc[aseg_table2[\"dx_group\"] == \"PD-non-MCI\"]\n",
    "corr_cov = {}\n",
    "\n",
    "# baseline\n",
    "for roi_bil in ROIs:\n",
    "    for version in [\"FS5\", \"FS6\", \"FS7\"]:\n",
    "\n",
    "        corr_temp = partial_corr(\n",
    "            data=ROI_PDnonMCI,\n",
    "            x=\"{roi}_{ver}_first\".format(roi=roi_bil, ver=version),\n",
    "            y=\"NP3TOT\",\n",
    "            covar=[\"AGE_AT_VISIT\", \"SEX\"],\n",
    "            method=\"pearson\",\n",
    "        )\n",
    "        corr_cov[\"corr_n_\" + version + \"_\" + roi_bil + \"_UPDRS_base\"] = corr_temp[\"n\"][\n",
    "            \"pearson\"\n",
    "        ]\n",
    "        corr_cov[\"corr_r_\" + version + \"_\" + roi_bil + \"_UPDRS_base\"] = corr_temp[\"r\"][\n",
    "            \"pearson\"\n",
    "        ]\n",
    "        corr_cov[\"corr_ci_\" + version + \"_\" + roi_bil + \"_UPDRS_base\"] = corr_temp[\n",
    "            \"CI95%\"\n",
    "        ][\"pearson\"]\n",
    "        corr_cov[\"corr_p_\" + version + \"_\" + roi_bil + \"_UPDRS_base\"] = corr_temp[\n",
    "            \"p-val\"\n",
    "        ][\"pearson\"]\n",
    "\n",
    "# longitudinal\n",
    "for roi_bil in ROIs:\n",
    "    for version in [\"FS5\", \"FS6\", \"FS7\"]:\n",
    "        corr_temp = partial_corr(\n",
    "            data=ROI_PDnonMCI,\n",
    "            x=\"{roi}_{ver}_change_pct\".format(roi=roi_bil, ver=version),\n",
    "            y=\"NP3TOT_change\",\n",
    "            covar=[\"AGE_AT_VISIT\", \"SEX\", \"durationT2_T1_y\"],\n",
    "            method=\"pearson\",\n",
    "        )\n",
    "        corr_cov[\"corr_n_\" + version + \"_\" + roi_bil + \"_UPDRS_long\"] = corr_temp[\"n\"][\n",
    "            \"pearson\"\n",
    "        ]\n",
    "        corr_cov[\"corr_r_\" + version + \"_\" + roi_bil + \"_UPDRS_long\"] = corr_temp[\"r\"][\n",
    "            \"pearson\"\n",
    "        ]\n",
    "        corr_cov[\"corr_ci_\" + version + \"_\" + roi_bil + \"_UPDRS_long\"] = corr_temp[\n",
    "            \"CI95%\"\n",
    "        ][\"pearson\"]\n",
    "        corr_cov[\"corr_p_\" + version + \"_\" + roi_bil + \"_UPDRS_long\"] = corr_temp[\n",
    "            \"p-val\"\n",
    "        ][\"pearson\"]\n",
    "\n",
    "df_corr_cov = pd.DataFrame.from_dict(corr_cov, orient=\"index\")\n",
    "# df_corr_cov.to_csv(\"results_corr_subcortical_cov.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "52d6071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## group analysis with covariates\n",
    "\n",
    "from pingouin import ancova as pg_ancova\n",
    "\n",
    "ROI_PDnonMCI = aseg_table2.loc[aseg_table2[\"dx_group\"] == \"PD-non-MCI\"]\n",
    "ROI_HC = aseg_table2.loc[aseg_table2[\"dx_group\"] == \"HC\"]\n",
    "HC_PDMCI = pd.concat([ROI_HC, ROI_PDnonMCI], ignore_index=True)\n",
    "\n",
    "ancova = {}\n",
    "\n",
    "# baseline\n",
    "for roi in ROIs:\n",
    "    for ver in [\"FS5\", \"FS6\", \"FS7\"]:\n",
    "        temp = pg_ancova(\n",
    "            data=HC_PDMCI,\n",
    "            dv=\"{roi}_{ver}_first\".format(roi=roi, ver=ver),\n",
    "            between=\"dx_group\",\n",
    "            covar=[\"AGE_AT_VISIT\", \"SEX\"],\n",
    "        )\n",
    "        ancova[\"ancova_F_\" + ver + \"_\" + roi + \"_base\"] = temp[\"F\"][0]\n",
    "        ancova[\"ancova_p_\" + ver + \"_\" + roi + \"_base\"] = temp[\"p-unc\"][0]\n",
    "\n",
    "# longitudinal\n",
    "for roi in ROIs:\n",
    "    for ver in [\"FS5\", \"FS6\", \"FS7\"]:\n",
    "\n",
    "        temp = pg_ancova(\n",
    "            data=HC_PDMCI,\n",
    "            dv=\"{roi}_{ver}_change_pct\".format(roi=roi, ver=ver),\n",
    "            between=\"dx_group\",\n",
    "            covar=[\"AGE_AT_VISIT\", \"SEX\", \"durationT2_T1_y\"],\n",
    "        )\n",
    "        ancova[\"ancova_F_\" + ver + \"_\" + roi + \"_long\"] = temp[\"F\"][0]\n",
    "        ancova[\"ancova_p_\" + ver + \"_\" + roi + \"_long\"] = temp[\"p-unc\"][0]\n",
    "\n",
    "df_ancova = pd.DataFrame.from_dict(ancova, orient=\"index\")\n",
    "# df_ancova.to_csv(\"results_ancova_subcortical_cov.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85dc1c",
   "metadata": {},
   "source": [
    "## Clinical results (subcortical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f648f83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">  Partial correlation between the UPDRS score and subcortical volumes at baseline  </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Subcortical segmentations </span>┃<span style=\"font-weight: bold\"> FS 5   </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\"> FS 6   </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\"> FS 7   </span>┃<span style=\"font-weight: bold\">        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━┩\n",
       "│                           │ r      │ p      │ r      │ p      │ r      │ p      │\n",
       "│ Left-Thalamus             │ -0.013 │ 12.36  │ -0.026 │ 10.838 │ -0.016 │ 12.017 │\n",
       "│ Left-Caudate              │ -0.206 │ 0.312  │ -0.178 │ 0.685  │ -0.182 │ 0.611  │\n",
       "│ Left-Putamen              │ -0.188 │ 0.52   │ -0.202 │ 0.352  │ -0.221 │ 0.194  │\n",
       "│ Left-Pallidum             │ -0.182 │ 0.622  │ -0.085 │ 4.928  │ -0.15  │ 1.357  │\n",
       "│ Left-Hippocampus          │ -0.124 │ 2.426  │ -0.11  │ 3.144  │ -0.12  │ 2.589  │\n",
       "│ Left-Amygdala             │ -0.099 │ 3.846  │ -0.155 │ 1.206  │ -0.176 │ 0.722  │\n",
       "│ Left-Accumbens-area       │ 0.127  │ 2.27   │ 0.085  │ 4.921  │ 0.086  │ 4.853  │\n",
       "│ Right-Thalamus            │ -0.013 │ 12.416 │ -0.033 │ 10.04  │ -0.058 │ 7.311  │\n",
       "│ Right-Caudate             │ -0.11  │ 3.15   │ -0.107 │ 3.322  │ -0.118 │ 2.687  │\n",
       "│ Right-Putamen             │ -0.222 │ 0.192  │ -0.269 │ 0.037  │ -0.263 │ 0.047  │\n",
       "│ Right-Pallidum            │ -0.015 │ 12.149 │ 0.041  │ 9.142  │ -0.007 │ 13.181 │\n",
       "│ Right-Hippocampus         │ -0.223 │ 0.183  │ -0.163 │ 1.014  │ -0.189 │ 0.515  │\n",
       "│ Right-Amygdala            │ -0.159 │ 1.111  │ -0.156 │ 1.201  │ -0.237 │ 0.115  │\n",
       "│ Right-Accumbens-area      │ 0.001  │ 13.847 │ 0.025  │ 11.028 │ -0.034 │ 9.929  │\n",
       "└───────────────────────────┴────────┴────────┴────────┴────────┴────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m  Partial correlation between the UPDRS score and subcortical volumes at baseline  \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mSubcortical segmentations\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mFS 5  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mFS 6  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mFS 7  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━┩\n",
       "│                           │ r      │ p      │ r      │ p      │ r      │ p      │\n",
       "│ Left-Thalamus             │ -0.013 │ 12.36  │ -0.026 │ 10.838 │ -0.016 │ 12.017 │\n",
       "│ Left-Caudate              │ -0.206 │ 0.312  │ -0.178 │ 0.685  │ -0.182 │ 0.611  │\n",
       "│ Left-Putamen              │ -0.188 │ 0.52   │ -0.202 │ 0.352  │ -0.221 │ 0.194  │\n",
       "│ Left-Pallidum             │ -0.182 │ 0.622  │ -0.085 │ 4.928  │ -0.15  │ 1.357  │\n",
       "│ Left-Hippocampus          │ -0.124 │ 2.426  │ -0.11  │ 3.144  │ -0.12  │ 2.589  │\n",
       "│ Left-Amygdala             │ -0.099 │ 3.846  │ -0.155 │ 1.206  │ -0.176 │ 0.722  │\n",
       "│ Left-Accumbens-area       │ 0.127  │ 2.27   │ 0.085  │ 4.921  │ 0.086  │ 4.853  │\n",
       "│ Right-Thalamus            │ -0.013 │ 12.416 │ -0.033 │ 10.04  │ -0.058 │ 7.311  │\n",
       "│ Right-Caudate             │ -0.11  │ 3.15   │ -0.107 │ 3.322  │ -0.118 │ 2.687  │\n",
       "│ Right-Putamen             │ -0.222 │ 0.192  │ -0.269 │ 0.037  │ -0.263 │ 0.047  │\n",
       "│ Right-Pallidum            │ -0.015 │ 12.149 │ 0.041  │ 9.142  │ -0.007 │ 13.181 │\n",
       "│ Right-Hippocampus         │ -0.223 │ 0.183  │ -0.163 │ 1.014  │ -0.189 │ 0.515  │\n",
       "│ Right-Amygdala            │ -0.159 │ 1.111  │ -0.156 │ 1.201  │ -0.237 │ 0.115  │\n",
       "│ Right-Accumbens-area      │ 0.001  │ 13.847 │ 0.025  │ 11.028 │ -0.034 │ 9.929  │\n",
       "└───────────────────────────┴────────┴────────┴────────┴────────┴────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## partial correlation\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "table = Table(\n",
    "    title=\"Partial correlation between the UPDRS score and subcortical volumes at baseline\"\n",
    ")\n",
    "\n",
    "table.add_column(\"Subcortical segmentations\", justify=\"Left\")\n",
    "table.add_column(\"FS 5\")\n",
    "table.add_column(\"\")\n",
    "table.add_column(\"FS 6\")\n",
    "table.add_column(\"\")\n",
    "table.add_column(\"FS 7\")\n",
    "table.add_column(\"\")\n",
    "\n",
    "table.add_row(\"\", \"r\", \"p\", \"r\", \"p\", \"r\", \"p\")\n",
    "\n",
    "rois_sub = [\n",
    "    \"Left-Thalamus\",\n",
    "    \"Left-Caudate\",\n",
    "    \"Left-Putamen\",\n",
    "    \"Left-Pallidum\",\n",
    "    \"Left-Hippocampus\",\n",
    "    \"Left-Amygdala\",\n",
    "    \"Left-Accumbens-area\",\n",
    "    \"Right-Thalamus\",\n",
    "    \"Right-Caudate\",\n",
    "    \"Right-Putamen\",\n",
    "    \"Right-Pallidum\",\n",
    "    \"Right-Hippocampus\",\n",
    "    \"Right-Amygdala\",\n",
    "    \"Right-Accumbens-area\",\n",
    "]\n",
    "\n",
    "for rois in rois_sub:\n",
    "\n",
    "    table.add_row(\n",
    "        rois,\n",
    "        str(\n",
    "            (corr_cov[\"corr_r_FS5_{rois}_UPDRS_base\".format(rois=rois)]).round(\n",
    "                decimals=3\n",
    "            )\n",
    "        ),\n",
    "        str(\n",
    "            (corr_cov[\"corr_p_FS5_{rois}_UPDRS_base\".format(rois=rois)] * 14).round(\n",
    "                decimals=3\n",
    "            )\n",
    "        ),\n",
    "        str(\n",
    "            (corr_cov[\"corr_r_FS6_{rois}_UPDRS_base\".format(rois=rois)]).round(\n",
    "                decimals=3\n",
    "            )\n",
    "        ),\n",
    "        str(\n",
    "            (corr_cov[\"corr_p_FS6_{rois}_UPDRS_base\".format(rois=rois)] * 14).round(\n",
    "                decimals=3\n",
    "            )\n",
    "        ),\n",
    "        str(\n",
    "            (corr_cov[\"corr_r_FS7_{rois}_UPDRS_base\".format(rois=rois)]).round(\n",
    "                decimals=3\n",
    "            )\n",
    "        ),\n",
    "        str(\n",
    "            (corr_cov[\"corr_p_FS7_{rois}_UPDRS_base\".format(rois=rois)] * 14).round(\n",
    "                decimals=3\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "console = Console()\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9ac1b42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">  Longitudinal partial correlation between the change in UPDRS score and rate of   </span>\n",
       "<span style=\"font-style: italic\">                           change in subcortical volumes                           </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Subcortical segmentations </span>┃<span style=\"font-weight: bold\"> FS 5   </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\"> FS 6   </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\"> FS 7   </span>┃<span style=\"font-weight: bold\">        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━┩\n",
       "│                           │ r      │ p      │ r      │ p      │ r      │ p      │\n",
       "│ Left-Thalamus             │ 0.14   │ 1.737  │ 0.037  │ 9.654  │ -0.012 │ 12.556 │\n",
       "│ Left-Caudate              │ 0.096  │ 4.124  │ -0.016 │ 11.999 │ -0.002 │ 13.744 │\n",
       "│ Left-Putamen              │ -0.007 │ 13.159 │ 0.1    │ 3.812  │ -0.011 │ 12.63  │\n",
       "│ Left-Pallidum             │ 0.022  │ 11.384 │ 0.145  │ 1.551  │ 0.039  │ 9.401  │\n",
       "│ Left-Hippocampus          │ 0.067  │ 6.522  │ 0.066  │ 6.567  │ 0.063  │ 6.829  │\n",
       "│ Left-Amygdala             │ 0.103  │ 3.65   │ -0.076 │ 5.715  │ 0.011  │ 12.64  │\n",
       "│ Left-Accumbens-area       │ -0.101 │ 3.734  │ 0.076  │ 5.662  │ 0.091  │ 4.485  │\n",
       "│ Right-Thalamus            │ -0.009 │ 12.956 │ -0.016 │ 12.042 │ -0.016 │ 12.01  │\n",
       "│ Right-Caudate             │ -0.122 │ 2.523  │ -0.221 │ 0.204  │ -0.229 │ 0.155  │\n",
       "│ Right-Putamen             │ 0.062  │ 6.985  │ 0.208  │ 0.305  │ 0.141  │ 1.714  │\n",
       "│ Right-Pallidum            │ -0.039 │ 9.358  │ -0.089 │ 4.609  │ 0.057  │ 7.462  │\n",
       "│ Right-Hippocampus         │ 0.12   │ 2.637  │ 0.005  │ 13.396 │ -0.01  │ 12.759 │\n",
       "│ Right-Amygdala            │ -0.002 │ 13.745 │ -0.031 │ 10.341 │ -0.141 │ 1.71   │\n",
       "│ Right-Accumbens-area      │ -0.132 │ 2.077  │ -0.025 │ 10.977 │ -0.018 │ 11.829 │\n",
       "└───────────────────────────┴────────┴────────┴────────┴────────┴────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m  Longitudinal partial correlation between the change in UPDRS score and rate of   \u001b[0m\n",
       "\u001b[3m                           change in subcortical volumes                           \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mSubcortical segmentations\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mFS 5  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mFS 6  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mFS 7  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━┩\n",
       "│                           │ r      │ p      │ r      │ p      │ r      │ p      │\n",
       "│ Left-Thalamus             │ 0.14   │ 1.737  │ 0.037  │ 9.654  │ -0.012 │ 12.556 │\n",
       "│ Left-Caudate              │ 0.096  │ 4.124  │ -0.016 │ 11.999 │ -0.002 │ 13.744 │\n",
       "│ Left-Putamen              │ -0.007 │ 13.159 │ 0.1    │ 3.812  │ -0.011 │ 12.63  │\n",
       "│ Left-Pallidum             │ 0.022  │ 11.384 │ 0.145  │ 1.551  │ 0.039  │ 9.401  │\n",
       "│ Left-Hippocampus          │ 0.067  │ 6.522  │ 0.066  │ 6.567  │ 0.063  │ 6.829  │\n",
       "│ Left-Amygdala             │ 0.103  │ 3.65   │ -0.076 │ 5.715  │ 0.011  │ 12.64  │\n",
       "│ Left-Accumbens-area       │ -0.101 │ 3.734  │ 0.076  │ 5.662  │ 0.091  │ 4.485  │\n",
       "│ Right-Thalamus            │ -0.009 │ 12.956 │ -0.016 │ 12.042 │ -0.016 │ 12.01  │\n",
       "│ Right-Caudate             │ -0.122 │ 2.523  │ -0.221 │ 0.204  │ -0.229 │ 0.155  │\n",
       "│ Right-Putamen             │ 0.062  │ 6.985  │ 0.208  │ 0.305  │ 0.141  │ 1.714  │\n",
       "│ Right-Pallidum            │ -0.039 │ 9.358  │ -0.089 │ 4.609  │ 0.057  │ 7.462  │\n",
       "│ Right-Hippocampus         │ 0.12   │ 2.637  │ 0.005  │ 13.396 │ -0.01  │ 12.759 │\n",
       "│ Right-Amygdala            │ -0.002 │ 13.745 │ -0.031 │ 10.341 │ -0.141 │ 1.71   │\n",
       "│ Right-Accumbens-area      │ -0.132 │ 2.077  │ -0.025 │ 10.977 │ -0.018 │ 11.829 │\n",
       "└───────────────────────────┴────────┴────────┴────────┴────────┴────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "table = Table(\n",
    "    title=\"Longitudinal partial correlation between the change in UPDRS score and rate of change in subcortical volumes\"\n",
    ")\n",
    "\n",
    "table.add_column(\"Subcortical segmentations\", justify=\"Left\")\n",
    "table.add_column(\"FS 5\")\n",
    "table.add_column(\"\")\n",
    "table.add_column(\"FS 6\")\n",
    "table.add_column(\"\")\n",
    "table.add_column(\"FS 7\")\n",
    "table.add_column(\"\")\n",
    "\n",
    "table.add_row(\"\", \"r\", \"p\", \"r\", \"p\", \"r\", \"p\")\n",
    "\n",
    "rois_sub = [\n",
    "    \"Left-Thalamus\",\n",
    "    \"Left-Caudate\",\n",
    "    \"Left-Putamen\",\n",
    "    \"Left-Pallidum\",\n",
    "    \"Left-Hippocampus\",\n",
    "    \"Left-Amygdala\",\n",
    "    \"Left-Accumbens-area\",\n",
    "    \"Right-Thalamus\",\n",
    "    \"Right-Caudate\",\n",
    "    \"Right-Putamen\",\n",
    "    \"Right-Pallidum\",\n",
    "    \"Right-Hippocampus\",\n",
    "    \"Right-Amygdala\",\n",
    "    \"Right-Accumbens-area\",\n",
    "]\n",
    "\n",
    "for rois in rois_sub:\n",
    "\n",
    "    table.add_row(\n",
    "        rois,\n",
    "        str(\n",
    "            (corr_cov[\"corr_r_FS5_{rois}_UPDRS_long\".format(rois=rois)]).round(\n",
    "                decimals=3\n",
    "            )\n",
    "        ),\n",
    "        str(\n",
    "            (corr_cov[\"corr_p_FS5_{rois}_UPDRS_long\".format(rois=rois)] * 14).round(\n",
    "                decimals=3\n",
    "            )\n",
    "        ),\n",
    "        str(\n",
    "            (corr_cov[\"corr_r_FS6_{rois}_UPDRS_long\".format(rois=rois)]).round(\n",
    "                decimals=3\n",
    "            )\n",
    "        ),\n",
    "        str(\n",
    "            (corr_cov[\"corr_p_FS6_{rois}_UPDRS_long\".format(rois=rois)] * 14).round(\n",
    "                decimals=3\n",
    "            )\n",
    "        ),\n",
    "        str(\n",
    "            (corr_cov[\"corr_r_FS7_{rois}_UPDRS_long\".format(rois=rois)]).round(\n",
    "                decimals=3\n",
    "            )\n",
    "        ),\n",
    "        str(\n",
    "            (corr_cov[\"corr_p_FS7_{rois}_UPDRS_long\".format(rois=rois)] * 14).round(\n",
    "                decimals=3\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "console = Console()\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c0ba1132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">         Group differences (HC vs PD) in subcortical volumes at baseline          </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Subcortical segmentations </span>┃<span style=\"font-weight: bold\"> FS 5   </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\"> FS 6   </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\"> FS 7   </span>┃<span style=\"font-weight: bold\">       </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│                           │ F      │ p      │ F      │ p      │ F      │ p     │\n",
       "│ Left-Thalamus             │ 15.696 │ 0.001  │ 15.582 │ 0.001  │ 15.627 │ 0.001 │\n",
       "│ Left-Caudate              │ 0.026  │ 12.193 │ 0.0    │ 13.881 │ 0.001  │ 13.72 │\n",
       "│ Left-Putamen              │ 1.463  │ 3.189  │ 2.527  │ 1.586  │ 1.707  │ 2.698 │\n",
       "│ Left-Pallidum             │ 3.095  │ 1.118  │ 4.103  │ 0.616  │ 8.764  │ 0.048 │\n",
       "│ Left-Hippocampus          │ 12.511 │ 0.007  │ 10.627 │ 0.018  │ 8.892  │ 0.044 │\n",
       "│ Left-Amygdala             │ 2.215  │ 1.933  │ 3.076  │ 1.131  │ 3.863  │ 0.708 │\n",
       "│ Left-Accumbens-area       │ 9.325  │ 0.035  │ 4.565  │ 0.472  │ 5.951  │ 0.217 │\n",
       "│ Right-Thalamus            │ 13.594 │ 0.004  │ 13.801 │ 0.004  │ 15.178 │ 0.002 │\n",
       "│ Right-Caudate             │ 0.063  │ 11.224 │ 0.449  │ 7.048  │ 0.57   │ 6.314 │\n",
       "│ Right-Putamen             │ 1.161  │ 3.953  │ 0.821  │ 5.123  │ 1.503  │ 3.1   │\n",
       "│ Right-Pallidum            │ 5.205  │ 0.328  │ 10.142 │ 0.023  │ 21.056 │ 0.0   │\n",
       "│ Right-Hippocampus         │ 15.21  │ 0.002  │ 17.531 │ 0.001  │ 17.345 │ 0.001 │\n",
       "│ Right-Amygdala            │ 3.281  │ 1.0    │ 9.173  │ 0.038  │ 11.376 │ 0.012 │\n",
       "│ Right-Accumbens-area      │ 3.688  │ 0.785  │ 7.267  │ 0.106  │ 10.78  │ 0.017 │\n",
       "└───────────────────────────┴────────┴────────┴────────┴────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m         Group differences (HC vs PD) in subcortical volumes at baseline          \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mSubcortical segmentations\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mFS 5  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mFS 6  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mFS 7  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│                           │ F      │ p      │ F      │ p      │ F      │ p     │\n",
       "│ Left-Thalamus             │ 15.696 │ 0.001  │ 15.582 │ 0.001  │ 15.627 │ 0.001 │\n",
       "│ Left-Caudate              │ 0.026  │ 12.193 │ 0.0    │ 13.881 │ 0.001  │ 13.72 │\n",
       "│ Left-Putamen              │ 1.463  │ 3.189  │ 2.527  │ 1.586  │ 1.707  │ 2.698 │\n",
       "│ Left-Pallidum             │ 3.095  │ 1.118  │ 4.103  │ 0.616  │ 8.764  │ 0.048 │\n",
       "│ Left-Hippocampus          │ 12.511 │ 0.007  │ 10.627 │ 0.018  │ 8.892  │ 0.044 │\n",
       "│ Left-Amygdala             │ 2.215  │ 1.933  │ 3.076  │ 1.131  │ 3.863  │ 0.708 │\n",
       "│ Left-Accumbens-area       │ 9.325  │ 0.035  │ 4.565  │ 0.472  │ 5.951  │ 0.217 │\n",
       "│ Right-Thalamus            │ 13.594 │ 0.004  │ 13.801 │ 0.004  │ 15.178 │ 0.002 │\n",
       "│ Right-Caudate             │ 0.063  │ 11.224 │ 0.449  │ 7.048  │ 0.57   │ 6.314 │\n",
       "│ Right-Putamen             │ 1.161  │ 3.953  │ 0.821  │ 5.123  │ 1.503  │ 3.1   │\n",
       "│ Right-Pallidum            │ 5.205  │ 0.328  │ 10.142 │ 0.023  │ 21.056 │ 0.0   │\n",
       "│ Right-Hippocampus         │ 15.21  │ 0.002  │ 17.531 │ 0.001  │ 17.345 │ 0.001 │\n",
       "│ Right-Amygdala            │ 3.281  │ 1.0    │ 9.173  │ 0.038  │ 11.376 │ 0.012 │\n",
       "│ Right-Accumbens-area      │ 3.688  │ 0.785  │ 7.267  │ 0.106  │ 10.78  │ 0.017 │\n",
       "└───────────────────────────┴────────┴────────┴────────┴────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## ancova\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "table = Table(title=\"Group differences (HC vs PD) in subcortical volumes at baseline\")\n",
    "\n",
    "table.add_column(\"Subcortical segmentations\", justify=\"Left\")\n",
    "table.add_column(\"FS 5\")\n",
    "table.add_column(\"\")\n",
    "table.add_column(\"FS 6\")\n",
    "table.add_column(\"\")\n",
    "table.add_column(\"FS 7\")\n",
    "table.add_column(\"\")\n",
    "\n",
    "table.add_row(\"\", \"F\", \"p\", \"F\", \"p\", \"F\", \"p\")\n",
    "\n",
    "rois_sub = [\n",
    "    \"Left-Thalamus\",\n",
    "    \"Left-Caudate\",\n",
    "    \"Left-Putamen\",\n",
    "    \"Left-Pallidum\",\n",
    "    \"Left-Hippocampus\",\n",
    "    \"Left-Amygdala\",\n",
    "    \"Left-Accumbens-area\",\n",
    "    \"Right-Thalamus\",\n",
    "    \"Right-Caudate\",\n",
    "    \"Right-Putamen\",\n",
    "    \"Right-Pallidum\",\n",
    "    \"Right-Hippocampus\",\n",
    "    \"Right-Amygdala\",\n",
    "    \"Right-Accumbens-area\",\n",
    "]\n",
    "\n",
    "for rois in rois_sub:\n",
    "\n",
    "    table.add_row(\n",
    "        rois,\n",
    "        str((ancova[\"ancova_F_FS5_{rois}_base\".format(rois=rois)]).round(decimals=3)),\n",
    "        str(\n",
    "            (ancova[\"ancova_p_FS5_{rois}_base\".format(rois=rois)] * 14).round(\n",
    "                decimals=3\n",
    "            )\n",
    "        ),\n",
    "        str((ancova[\"ancova_F_FS6_{rois}_base\".format(rois=rois)]).round(decimals=3)),\n",
    "        str(\n",
    "            (ancova[\"ancova_p_FS6_{rois}_base\".format(rois=rois)] * 14).round(\n",
    "                decimals=3\n",
    "            )\n",
    "        ),\n",
    "        str((ancova[\"ancova_F_FS7_{rois}_base\".format(rois=rois)]).round(decimals=3)),\n",
    "        str(\n",
    "            (ancova[\"ancova_p_FS7_{rois}_base\".format(rois=rois)] * 14).round(\n",
    "                decimals=3\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "console = Console()\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "538b80f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\"> Longtudinal group differences (HC vs PD) in the rate of change in subcortical  </span>\n",
       "<span style=\"font-style: italic\">                                    volumes                                     </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Subcortical segmentations </span>┃<span style=\"font-weight: bold\"> FS 5   </span>┃<span style=\"font-weight: bold\">        </span>┃<span style=\"font-weight: bold\"> FS 6  </span>┃<span style=\"font-weight: bold\">       </span>┃<span style=\"font-weight: bold\"> FS 7  </span>┃<span style=\"font-weight: bold\">        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━━┩\n",
       "│                           │ F      │ p      │ F     │ p     │ F     │ p      │\n",
       "│ Left-Thalamus             │ 0.792  │ 5.241  │ 0.257 │ 8.581 │ 0.276 │ 8.401  │\n",
       "│ Left-Caudate              │ 5.461  │ 0.284  │ 3.084 │ 1.126 │ 1.879 │ 2.405  │\n",
       "│ Left-Putamen              │ 0.529  │ 6.548  │ 2.095 │ 2.089 │ 0.546 │ 6.45   │\n",
       "│ Left-Pallidum             │ 0.085  │ 10.787 │ 6.372 │ 0.172 │ 2.997 │ 1.187  │\n",
       "│ Left-Hippocampus          │ 0.222  │ 8.937  │ 0.221 │ 8.941 │ 0.093 │ 10.65  │\n",
       "│ Left-Amygdala             │ 0.07   │ 11.089 │ 1.621 │ 2.86  │ 0.107 │ 10.409 │\n",
       "│ Left-Accumbens-area       │ 0.363  │ 7.667  │ 1.811 │ 2.517 │ 0.504 │ 6.697  │\n",
       "│ Right-Thalamus            │ 0.616  │ 6.067  │ 0.207 │ 9.09  │ 0.017 │ 12.57  │\n",
       "│ Right-Caudate             │ 12.644 │ 0.006  │ 4.884 │ 0.394 │ 1.236 │ 3.745  │\n",
       "│ Right-Putamen             │ 2.143  │ 2.025  │ 0.152 │ 9.76  │ 1.272 │ 3.649  │\n",
       "│ Right-Pallidum            │ 0.178  │ 9.423  │ 1.569 │ 2.964 │ 0.132 │ 10.03  │\n",
       "│ Right-Hippocampus         │ 3.33   │ 0.971  │ 1.575 │ 2.951 │ 0.018 │ 12.512 │\n",
       "│ Right-Amygdala            │ 0.289  │ 8.283  │ 1.014 │ 4.412 │ 0.502 │ 6.711  │\n",
       "│ Right-Accumbens-area      │ 1.379  │ 3.381  │ 2.096 │ 2.086 │ 4.185 │ 0.587  │\n",
       "└───────────────────────────┴────────┴────────┴───────┴───────┴───────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m Longtudinal group differences (HC vs PD) in the rate of change in subcortical  \u001b[0m\n",
       "\u001b[3m                                    volumes                                     \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mSubcortical segmentations\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mFS 5  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mFS 6 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mFS 7 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━╇━━━━━━━━┩\n",
       "│                           │ F      │ p      │ F     │ p     │ F     │ p      │\n",
       "│ Left-Thalamus             │ 0.792  │ 5.241  │ 0.257 │ 8.581 │ 0.276 │ 8.401  │\n",
       "│ Left-Caudate              │ 5.461  │ 0.284  │ 3.084 │ 1.126 │ 1.879 │ 2.405  │\n",
       "│ Left-Putamen              │ 0.529  │ 6.548  │ 2.095 │ 2.089 │ 0.546 │ 6.45   │\n",
       "│ Left-Pallidum             │ 0.085  │ 10.787 │ 6.372 │ 0.172 │ 2.997 │ 1.187  │\n",
       "│ Left-Hippocampus          │ 0.222  │ 8.937  │ 0.221 │ 8.941 │ 0.093 │ 10.65  │\n",
       "│ Left-Amygdala             │ 0.07   │ 11.089 │ 1.621 │ 2.86  │ 0.107 │ 10.409 │\n",
       "│ Left-Accumbens-area       │ 0.363  │ 7.667  │ 1.811 │ 2.517 │ 0.504 │ 6.697  │\n",
       "│ Right-Thalamus            │ 0.616  │ 6.067  │ 0.207 │ 9.09  │ 0.017 │ 12.57  │\n",
       "│ Right-Caudate             │ 12.644 │ 0.006  │ 4.884 │ 0.394 │ 1.236 │ 3.745  │\n",
       "│ Right-Putamen             │ 2.143  │ 2.025  │ 0.152 │ 9.76  │ 1.272 │ 3.649  │\n",
       "│ Right-Pallidum            │ 0.178  │ 9.423  │ 1.569 │ 2.964 │ 0.132 │ 10.03  │\n",
       "│ Right-Hippocampus         │ 3.33   │ 0.971  │ 1.575 │ 2.951 │ 0.018 │ 12.512 │\n",
       "│ Right-Amygdala            │ 0.289  │ 8.283  │ 1.014 │ 4.412 │ 0.502 │ 6.711  │\n",
       "│ Right-Accumbens-area      │ 1.379  │ 3.381  │ 2.096 │ 2.086 │ 4.185 │ 0.587  │\n",
       "└───────────────────────────┴────────┴────────┴───────┴───────┴───────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "\n",
    "table = Table(\n",
    "    title=\"Longtudinal group differences (HC vs PD) in the rate of change in subcortical volumes\"\n",
    ")\n",
    "\n",
    "table.add_column(\"Subcortical segmentations\", justify=\"Left\")\n",
    "table.add_column(\"FS 5\")\n",
    "table.add_column(\"\")\n",
    "table.add_column(\"FS 6\")\n",
    "table.add_column(\"\")\n",
    "table.add_column(\"FS 7\")\n",
    "table.add_column(\"\")\n",
    "\n",
    "table.add_row(\"\", \"F\", \"p\", \"F\", \"p\", \"F\", \"p\")\n",
    "\n",
    "rois_sub = [\n",
    "    \"Left-Thalamus\",\n",
    "    \"Left-Caudate\",\n",
    "    \"Left-Putamen\",\n",
    "    \"Left-Pallidum\",\n",
    "    \"Left-Hippocampus\",\n",
    "    \"Left-Amygdala\",\n",
    "    \"Left-Accumbens-area\",\n",
    "    \"Right-Thalamus\",\n",
    "    \"Right-Caudate\",\n",
    "    \"Right-Putamen\",\n",
    "    \"Right-Pallidum\",\n",
    "    \"Right-Hippocampus\",\n",
    "    \"Right-Amygdala\",\n",
    "    \"Right-Accumbens-area\",\n",
    "]\n",
    "\n",
    "for rois in rois_sub:\n",
    "\n",
    "    table.add_row(\n",
    "        rois,\n",
    "        str((ancova[\"ancova_F_FS5_{rois}_long\".format(rois=rois)]).round(decimals=3)),\n",
    "        str(\n",
    "            (ancova[\"ancova_p_FS5_{rois}_long\".format(rois=rois)] * 14).round(\n",
    "                decimals=3\n",
    "            )\n",
    "        ),\n",
    "        str((ancova[\"ancova_F_FS6_{rois}_long\".format(rois=rois)]).round(decimals=3)),\n",
    "        str(\n",
    "            (ancova[\"ancova_p_FS6_{rois}_long\".format(rois=rois)] * 14).round(\n",
    "                decimals=3\n",
    "            )\n",
    "        ),\n",
    "        str((ancova[\"ancova_F_FS7_{rois}_long\".format(rois=rois)]).round(decimals=3)),\n",
    "        str(\n",
    "            (ancova[\"ancova_p_FS7_{rois}_long\".format(rois=rois)] * 14).round(\n",
    "                decimals=3\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "console = Console()\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f299b895",
   "metadata": {},
   "source": [
    "# Data visualisation\n",
    "\n",
    "## Computational analyses\n",
    "Dice coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "116a099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_table = aseg_table.filter(like=\"dice_\")\n",
    "mean = dice_table.mean()\n",
    "sd = dice_table.std()\n",
    "\n",
    "dice_results = {}\n",
    "dice_results[\"mean\"] = mean\n",
    "dice_results[\"sd\"] = sd\n",
    "dice_results = pd.DataFrame.from_dict(dice_results, orient=\"index\")\n",
    "dice_results = dice_results.transpose()\n",
    "# dice_results.to_csv(\"dice_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "66397efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_table_76_subR = dice_table.filter(like=\"dice_FS76_Right\")\n",
    "dice_table_76_subL = dice_table.filter(like=\"dice_FS76_Left\")\n",
    "dice_table_76_ctx_lh = dice_table.filter(like=\"dice_FS76_ctx_lh\")\n",
    "dice_table_76_ctx_rh = dice_table.filter(like=\"dice_FS76_ctx_rh\")\n",
    "\n",
    "dice_table_75_subR = dice_table.filter(like=\"dice_FS75_Right\")\n",
    "dice_table_75_subL = dice_table.filter(like=\"dice_FS75_Left\")\n",
    "dice_table_75_ctx_lh = dice_table.filter(like=\"dice_FS75_ctx_lh\")\n",
    "dice_table_75_ctx_rh = dice_table.filter(like=\"dice_FS75_ctx_rh\")\n",
    "\n",
    "dice_table_65_subR = dice_table.filter(like=\"dice_FS65_Right\")\n",
    "dice_table_65_subL = dice_table.filter(like=\"dice_FS65_Left\")\n",
    "dice_table_65_ctx_rh = dice_table.filter(like=\"dice_FS65_ctx_rh\")\n",
    "dice_table_65_ctx_lh = dice_table.filter(like=\"dice_FS65_ctx_lh\")\n",
    "\n",
    "dice_table_65_subR.columns = dice_table_65_subR.columns.str.replace(\n",
    "    \"^dice_FS65_Right-\", \"\"\n",
    ")\n",
    "dice_table_65_subL.columns = dice_table_65_subL.columns.str.replace(\n",
    "    \"^dice_FS65_Left-\", \"\"\n",
    ")\n",
    "dice_table_65_ctx_rh.columns = dice_table_65_ctx_rh.columns.str.replace(\n",
    "    \"^dice_FS65_ctx_rh_\", \"\"\n",
    ")\n",
    "dice_table_65_ctx_lh.columns = dice_table_65_ctx_lh.columns.str.replace(\n",
    "    \"^dice_FS65_ctx_lh_\", \"\"\n",
    ")\n",
    "\n",
    "dice_table_75_subR.columns = dice_table_75_subR.columns.str.replace(\n",
    "    \"^dice_FS75_Right-\", \"\"\n",
    ")\n",
    "dice_table_75_subL.columns = dice_table_75_subL.columns.str.replace(\n",
    "    \"^dice_FS75_Left-\", \"\"\n",
    ")\n",
    "dice_table_75_ctx_rh.columns = dice_table_75_ctx_rh.columns.str.replace(\n",
    "    \"^dice_FS75_ctx_rh_\", \"\"\n",
    ")\n",
    "dice_table_75_ctx_lh.columns = dice_table_75_ctx_lh.columns.str.replace(\n",
    "    \"^dice_FS75_ctx_lh_\", \"\"\n",
    ")\n",
    "\n",
    "dice_table_76_subR.columns = dice_table_76_subR.columns.str.replace(\n",
    "    \"^dice_FS76_Right-\", \"\"\n",
    ")\n",
    "dice_table_76_subL.columns = dice_table_76_subL.columns.str.replace(\n",
    "    \"^dice_FS76_Left-\", \"\"\n",
    ")\n",
    "dice_table_76_ctx_rh.columns = dice_table_76_ctx_rh.columns.str.replace(\n",
    "    \"^dice_FS76_ctx_rh_\", \"\"\n",
    ")\n",
    "dice_table_76_ctx_lh.columns = dice_table_76_ctx_lh.columns.str.replace(\n",
    "    \"^dice_FS76_ctx_lh_\", \"\"\n",
    ")\n",
    "\n",
    "dice_table_76_rh = pd.concat([dice_table_76_subR, dice_table_76_ctx_rh], axis=1)\n",
    "dice_table_76_lh = pd.concat([dice_table_76_subL, dice_table_76_ctx_lh], axis=1)\n",
    "dice_table_76_rh[\"hemi\"] = \"rh\"\n",
    "dice_table_76_lh[\"hemi\"] = \"lh\"\n",
    "dice_table_76_rh[\"group\"] = \"FS 7 vs 6\"\n",
    "dice_table_76_lh[\"group\"] = \"FS 7 vs 6\"\n",
    "\n",
    "dice_table_75_rh = pd.concat([dice_table_75_subR, dice_table_75_ctx_rh], axis=1)\n",
    "dice_table_75_lh = pd.concat([dice_table_75_subL, dice_table_75_ctx_lh], axis=1)\n",
    "dice_table_75_rh[\"hemi\"] = \"rh\"\n",
    "dice_table_75_lh[\"hemi\"] = \"lh\"\n",
    "dice_table_75_rh[\"group\"] = \"FS 7 vs 5\"\n",
    "dice_table_75_lh[\"group\"] = \"FS 7 vs 5\"\n",
    "\n",
    "dice_table_65_rh = pd.concat([dice_table_65_subR, dice_table_65_ctx_rh], axis=1)\n",
    "dice_table_65_lh = pd.concat([dice_table_65_subL, dice_table_65_ctx_lh], axis=1)\n",
    "dice_table_65_rh[\"hemi\"] = \"rh\"\n",
    "dice_table_65_lh[\"hemi\"] = \"lh\"\n",
    "dice_table_65_rh[\"group\"] = \"FS 6 vs 5\"\n",
    "dice_table_65_lh[\"group\"] = \"FS 6 vs 5\"\n",
    "\n",
    "dice_table_all = pd.concat(\n",
    "    [\n",
    "        dice_table_76_rh,\n",
    "        dice_table_76_lh,\n",
    "        dice_table_75_rh,\n",
    "        dice_table_75_lh,\n",
    "        dice_table_65_rh,\n",
    "        dice_table_65_lh,\n",
    "    ]\n",
    ")\n",
    "\n",
    "dice_table_lh = pd.concat([dice_table_76_lh, dice_table_75_lh, dice_table_65_lh])\n",
    "dice_table_rh = pd.concat([dice_table_76_rh, dice_table_75_rh, dice_table_65_rh])\n",
    "\n",
    "# dice_table_all.to_csv('dice_table_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37de6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "y_dice = [\n",
    "    \"Cerebral-White-Matter\",\n",
    "    \"Cerebral-Cortex\",\n",
    "    \"Lateral-Ventricle\",\n",
    "    \"Inf-Lat-Vent\",\n",
    "    \"Cerebellum-White-Matter\",\n",
    "    \"Cerebellum-Cortex\",\n",
    "    \"Thalamus\",\n",
    "    \"Caudate\",\n",
    "    \"Putamen\",\n",
    "    \"Pallidum\",\n",
    "    \"Hippocampus\",\n",
    "    \"Amygdala\",\n",
    "    \"Accumbens-area\",\n",
    "    \"VentralDC\",\n",
    "    \"vessel\",\n",
    "    \"choroid-plexus\",\n",
    "    \"G_and_S_frontomargin\",\n",
    "    \"G_and_S_occipital_inf\",\n",
    "    \"G_and_S_paracentral\",\n",
    "    \"G_and_S_subcentral\",\n",
    "    \"G_and_S_transv_frontopol\",\n",
    "    \"G_and_S_cingul-Ant\",\n",
    "    \"G_and_S_cingul-Mid-Ant\",\n",
    "    \"G_and_S_cingul-Mid-Post\",\n",
    "    \"G_cingul-Post-dorsal\",\n",
    "    \"G_cingul-Post-ventral\",\n",
    "    \"G_cuneus\",\n",
    "    \"G_front_inf-Opercular\",\n",
    "    \"G_front_inf-Orbital\",\n",
    "    \"G_front_inf-Triangul\",\n",
    "    \"G_front_middle\",\n",
    "    \"G_front_sup\",\n",
    "    \"G_Ins_lg_and_S_cent_ins\",\n",
    "    \"G_insular_short\",\n",
    "    \"G_occipital_middle\",\n",
    "    \"G_occipital_sup\",\n",
    "    \"G_oc-temp_lat-fusifor\",\n",
    "    \"G_oc-temp_med-Lingual\",\n",
    "    \"G_oc-temp_med-Parahip\",\n",
    "    \"G_orbital\",\n",
    "    \"G_pariet_inf-Angular\",\n",
    "    \"G_pariet_inf-Supramar\",\n",
    "    \"G_parietal_sup\",\n",
    "    \"G_postcentral\",\n",
    "    \"G_precentral\",\n",
    "    \"G_precuneus\",\n",
    "    \"G_rectus\",\n",
    "    \"G_subcallosal\",\n",
    "    \"G_temp_sup-G_T_transv\",\n",
    "    \"G_temp_sup-Lateral\",\n",
    "    \"G_temp_sup-Plan_polar\",\n",
    "    \"G_temp_sup-Plan_tempo\",\n",
    "    \"G_temporal_inf\",\n",
    "    \"G_temporal_middle\",\n",
    "    \"Lat_Fis-ant-Horizont\",\n",
    "    \"Lat_Fis-ant-Vertical\",\n",
    "    \"Lat_Fis-post\",\n",
    "    \"Pole_occipital\",\n",
    "    \"Pole_temporal\",\n",
    "    \"S_calcarine\",\n",
    "    \"S_central\",\n",
    "    \"S_cingul-Marginalis\",\n",
    "    \"S_circular_insula_ant\",\n",
    "    \"S_circular_insula_inf\",\n",
    "    \"S_circular_insula_sup\",\n",
    "    \"S_collat_transv_ant\",\n",
    "    \"S_collat_transv_post\",\n",
    "    \"S_front_inf\",\n",
    "    \"S_front_middle\",\n",
    "    \"S_front_sup\",\n",
    "    \"S_interm_prim-Jensen\",\n",
    "    \"S_intrapariet_and_P_trans\",\n",
    "    \"S_oc_middle_and_Lunatus\",\n",
    "    \"S_oc_sup_and_transversal\",\n",
    "    \"S_occipital_ant\",\n",
    "    \"S_oc-temp_lat\",\n",
    "    \"S_oc-temp_med_and_Lingual\",\n",
    "    \"S_orbital_lateral\",\n",
    "    \"S_orbital_med-olfact\",\n",
    "    \"S_orbital-H_Shaped\",\n",
    "    \"S_parieto_occipital\",\n",
    "    \"S_pericallosal\",\n",
    "    \"S_postcentral\",\n",
    "    \"S_precentral-inf-part\",\n",
    "    \"S_precentral-sup-part\",\n",
    "    \"S_suborbital\",\n",
    "    \"S_subparietal\",\n",
    "    \"S_temporal_inf\",\n",
    "    \"S_temporal_sup\",\n",
    "    \"S_temporal_transverse\",\n",
    "]\n",
    "\n",
    "\n",
    "fig = px.box(dice_table_all, y=y_dice, color=\"group\", facet_row=\"hemi\")\n",
    "\n",
    "\n",
    "fig.update_xaxes(gridwidth=1, griddash=\"dot\")\n",
    "fig.update_yaxes(title=\"Sørensen–Dice coefficients\")\n",
    "fig.update_layout(legend_title_text=\"Legend\")\n",
    "# fig.write_image(\"plot_dice.png\", width=2800, height=1080)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f9906e",
   "metadata": {},
   "source": [
    "<img src=\"images/plot_dice.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f73aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "x = dice_table_lh.copy()\n",
    "x = x.drop(columns=[\"hemi\", \"undetermined\"])\n",
    "\n",
    "fig = px.box(\n",
    "    data_frame=x,\n",
    "    color=\"group\",\n",
    "    orientation=\"h\",\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title=\"Regions (left hemisphere)\", gridwidth=1, griddash=\"dot\")\n",
    "fig.update_xaxes(title=\"Sørensen–Dice coefficients\")\n",
    "fig.update_layout(legend_title_text=\"\", font_size=20)\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.05,\n",
    "        xanchor=\"left\",\n",
    "        x=0,\n",
    "        font_size=20,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")\n",
    "# fig.write_image(\"plot_dice_lh.png\", width=1080, height=2700)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c8dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "x = dice_table_rh.copy()\n",
    "x = x.drop(columns=[\"hemi\"])\n",
    "\n",
    "fig = px.box(\n",
    "    data_frame=x,\n",
    "    color=\"group\",\n",
    "    orientation=\"h\",\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title=\"Regions (right hemisphere)\", gridwidth=1, griddash=\"dot\")\n",
    "fig.update_xaxes(title=\"Sørensen–Dice coefficients\")\n",
    "fig.update_layout(legend_title_text=\"\", font_size=20)\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.05,\n",
    "        xanchor=\"left\",\n",
    "        x=0,\n",
    "        font_size=20,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")\n",
    "# fig.write_image(\"plot_dice_rh.png\", width=1080, height=2700)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4c41cf",
   "metadata": {},
   "source": [
    "### subcortical volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d0d938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_table_5_a = aseg_table[\n",
    "    [\n",
    "        \"Left-Lateral-Ventricle_FS5\",\n",
    "        \"Left-Inf-Lat-Vent_FS5\",\n",
    "        \"Left-Cerebellum-White-Matter_FS5\",\n",
    "        \"Left-Cerebellum-Cortex_FS5\",\n",
    "        \"Left-Thalamus_FS5\",\n",
    "        \"Left-Caudate_FS5\",\n",
    "        \"Left-Putamen_FS5\",\n",
    "        \"Left-Pallidum_FS5\",\n",
    "        \"3rd-Ventricle_FS5\",\n",
    "        \"4th-Ventricle_FS5\",\n",
    "        \"Brain-Stem_FS5\",\n",
    "        \"Left-Hippocampus_FS5\",\n",
    "        \"Left-Amygdala_FS5\",\n",
    "        \"CSF_FS5\",\n",
    "        \"Left-Accumbens-area_FS5\",\n",
    "        \"Left-VentralDC_FS5\",\n",
    "        \"Left-vessel_FS5\",\n",
    "        \"Left-choroid-plexus_FS5\",\n",
    "        \"Right-Lateral-Ventricle_FS5\",\n",
    "        \"Right-Inf-Lat-Vent_FS5\",\n",
    "        \"Right-Cerebellum-White-Matter_FS5\",\n",
    "        \"Right-Cerebellum-Cortex_FS5\",\n",
    "        \"Right-Thalamus_FS5\",\n",
    "        \"Right-Caudate_FS5\",\n",
    "        \"Right-Putamen_FS5\",\n",
    "        \"Right-Pallidum_FS5\",\n",
    "        \"Right-Hippocampus_FS5\",\n",
    "        \"Right-Amygdala_FS5\",\n",
    "        \"Right-Accumbens-area_FS5\",\n",
    "        \"Right-VentralDC_FS5\",\n",
    "        \"Right-vessel_FS5\",\n",
    "        \"Right-choroid-plexus_FS5\",\n",
    "        \"5th-Ventricle_FS5\",\n",
    "        \"Optic-Chiasm_FS5\",\n",
    "        \"CC_Posterior_FS5\",\n",
    "        \"CC_Mid_Posterior_FS5\",\n",
    "        \"CC_Central_FS5\",\n",
    "        \"CC_Mid_Anterior_FS5\",\n",
    "        \"CC_Anterior_FS5\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "sub_table_6_a = aseg_table[\n",
    "    [\n",
    "        \"Left-Lateral-Ventricle_FS6\",\n",
    "        \"Left-Inf-Lat-Vent_FS6\",\n",
    "        \"Left-Cerebellum-White-Matter_FS6\",\n",
    "        \"Left-Cerebellum-Cortex_FS6\",\n",
    "        \"Left-Thalamus_FS6\",\n",
    "        \"Left-Caudate_FS6\",\n",
    "        \"Left-Putamen_FS6\",\n",
    "        \"Left-Pallidum_FS6\",\n",
    "        \"3rd-Ventricle_FS6\",\n",
    "        \"4th-Ventricle_FS6\",\n",
    "        \"Brain-Stem_FS6\",\n",
    "        \"Left-Hippocampus_FS6\",\n",
    "        \"Left-Amygdala_FS6\",\n",
    "        \"CSF_FS6\",\n",
    "        \"Left-Accumbens-area_FS6\",\n",
    "        \"Left-VentralDC_FS6\",\n",
    "        \"Left-vessel_FS6\",\n",
    "        \"Left-choroid-plexus_FS6\",\n",
    "        \"Right-Lateral-Ventricle_FS6\",\n",
    "        \"Right-Inf-Lat-Vent_FS6\",\n",
    "        \"Right-Cerebellum-White-Matter_FS6\",\n",
    "        \"Right-Cerebellum-Cortex_FS6\",\n",
    "        \"Right-Thalamus_FS6\",\n",
    "        \"Right-Caudate_FS6\",\n",
    "        \"Right-Putamen_FS6\",\n",
    "        \"Right-Pallidum_FS6\",\n",
    "        \"Right-Hippocampus_FS6\",\n",
    "        \"Right-Amygdala_FS6\",\n",
    "        \"Right-Accumbens-area_FS6\",\n",
    "        \"Right-VentralDC_FS6\",\n",
    "        \"Right-vessel_FS6\",\n",
    "        \"Right-choroid-plexus_FS6\",\n",
    "        \"5th-Ventricle_FS6\",\n",
    "        \"Optic-Chiasm_FS6\",\n",
    "        \"CC_Posterior_FS6\",\n",
    "        \"CC_Mid_Posterior_FS6\",\n",
    "        \"CC_Central_FS6\",\n",
    "        \"CC_Mid_Anterior_FS6\",\n",
    "        \"CC_Anterior_FS6\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "sub_table_7_a = aseg_table[\n",
    "    [\n",
    "        \"Left-Lateral-Ventricle_FS7\",\n",
    "        \"Left-Inf-Lat-Vent_FS7\",\n",
    "        \"Left-Cerebellum-White-Matter_FS7\",\n",
    "        \"Left-Cerebellum-Cortex_FS7\",\n",
    "        \"Left-Thalamus_FS7\",\n",
    "        \"Left-Caudate_FS7\",\n",
    "        \"Left-Putamen_FS7\",\n",
    "        \"Left-Pallidum_FS7\",\n",
    "        \"3rd-Ventricle_FS7\",\n",
    "        \"4th-Ventricle_FS7\",\n",
    "        \"Brain-Stem_FS7\",\n",
    "        \"Left-Hippocampus_FS7\",\n",
    "        \"Left-Amygdala_FS7\",\n",
    "        \"CSF_FS7\",\n",
    "        \"Left-Accumbens-area_FS7\",\n",
    "        \"Left-VentralDC_FS7\",\n",
    "        \"Left-vessel_FS7\",\n",
    "        \"Left-choroid-plexus_FS7\",\n",
    "        \"Right-Lateral-Ventricle_FS7\",\n",
    "        \"Right-Inf-Lat-Vent_FS7\",\n",
    "        \"Right-Cerebellum-White-Matter_FS7\",\n",
    "        \"Right-Cerebellum-Cortex_FS7\",\n",
    "        \"Right-Thalamus_FS7\",\n",
    "        \"Right-Caudate_FS7\",\n",
    "        \"Right-Putamen_FS7\",\n",
    "        \"Right-Pallidum_FS7\",\n",
    "        \"Right-Hippocampus_FS7\",\n",
    "        \"Right-Amygdala_FS7\",\n",
    "        \"Right-Accumbens-area_FS7\",\n",
    "        \"Right-VentralDC_FS7\",\n",
    "        \"Right-vessel_FS7\",\n",
    "        \"Right-choroid-plexus_FS7\",\n",
    "        \"5th-Ventricle_FS7\",\n",
    "        \"Optic-Chiasm_FS7\",\n",
    "        \"CC_Posterior_FS7\",\n",
    "        \"CC_Mid_Posterior_FS7\",\n",
    "        \"CC_Central_FS7\",\n",
    "        \"CC_Mid_Anterior_FS7\",\n",
    "        \"CC_Anterior_FS7\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4158f436",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_table_coh = aseg_table.filter(like=\"dx_group\")\n",
    "\n",
    "sub_table_5 = pd.concat([sub_table_5_a, sub_table_coh], axis=1)\n",
    "sub_table_6 = pd.concat([sub_table_6_a, sub_table_coh], axis=1)\n",
    "sub_table_7 = pd.concat([sub_table_7_a, sub_table_coh], axis=1)\n",
    "\n",
    "sub_table_5[\"version\"] = \"FS5\"\n",
    "sub_table_6[\"version\"] = \"FS6\"\n",
    "sub_table_7[\"version\"] = \"FS7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "35b34ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_table_5.columns = sub_table_5.columns.str.replace(\"_FS5\", \"\")\n",
    "sub_table_6.columns = sub_table_6.columns.str.replace(\"_FS6\", \"\")\n",
    "sub_table_7.columns = sub_table_7.columns.str.replace(\"_FS7\", \"\")\n",
    "\n",
    "sub_all = pd.concat([sub_table_5, sub_table_6, sub_table_7])\n",
    "\n",
    "# sub_all.to_csv('sub_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c4c5c6",
   "metadata": {},
   "source": [
    "### volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e4065a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_table_5_a = aseg_table.filter(like=\"_vol_FS5\")\n",
    "vol_table_6_a = aseg_table.filter(like=\"_vol_FS6\")\n",
    "vol_table_7_a = aseg_table.filter(like=\"_vol_FS7\")\n",
    "\n",
    "vol_table_coh = aseg_table.filter(like=\"dx_group\")\n",
    "\n",
    "vol_table_5 = pd.concat([vol_table_5_a, vol_table_coh], axis=1)\n",
    "vol_table_6 = pd.concat([vol_table_6_a, vol_table_coh], axis=1)\n",
    "vol_table_7 = pd.concat([vol_table_7_a, vol_table_coh], axis=1)\n",
    "\n",
    "vol_table_5_lh = vol_table_5.filter(like=\"lh_vol_FS5\")\n",
    "vol_table_5_rh = vol_table_5.filter(like=\"rh_vol_FS5\")\n",
    "vol_table_6_lh = vol_table_6.filter(like=\"lh_vol_FS6\")\n",
    "vol_table_6_rh = vol_table_6.filter(like=\"rh_vol_FS6\")\n",
    "vol_table_7_lh = vol_table_7.filter(like=\"lh_vol_FS7\")\n",
    "vol_table_7_rh = vol_table_7.filter(like=\"rh_vol_FS7\")\n",
    "\n",
    "vol_table_5_coh = vol_table_5.filter(like=\"dx_group\")\n",
    "vol_table_6_coh = vol_table_6.filter(like=\"dx_group\")\n",
    "vol_table_7_coh = vol_table_7.filter(like=\"dx_group\")\n",
    "\n",
    "vol_table_5_lh = pd.concat([vol_table_5_lh, vol_table_5_coh], axis=1)\n",
    "vol_table_6_lh = pd.concat([vol_table_6_lh, vol_table_6_coh], axis=1)\n",
    "vol_table_7_lh = pd.concat([vol_table_7_lh, vol_table_7_coh], axis=1)\n",
    "vol_table_5_rh = pd.concat([vol_table_5_rh, vol_table_5_coh], axis=1)\n",
    "vol_table_6_rh = pd.concat([vol_table_6_rh, vol_table_6_coh], axis=1)\n",
    "vol_table_7_rh = pd.concat([vol_table_7_rh, vol_table_7_coh], axis=1)\n",
    "\n",
    "vol_table_5_lh[\"hemi\"] = \"lh\"\n",
    "vol_table_5_rh[\"hemi\"] = \"rh\"\n",
    "vol_table_6_lh[\"hemi\"] = \"lh\"\n",
    "vol_table_6_rh[\"hemi\"] = \"rh\"\n",
    "vol_table_7_lh[\"hemi\"] = \"lh\"\n",
    "vol_table_7_rh[\"hemi\"] = \"rh\"\n",
    "\n",
    "vol_table_5_lh[\"version\"] = \"FS5\"\n",
    "vol_table_5_rh[\"version\"] = \"FS5\"\n",
    "vol_table_6_lh[\"version\"] = \"FS6\"\n",
    "vol_table_6_rh[\"version\"] = \"FS6\"\n",
    "vol_table_7_lh[\"version\"] = \"FS7\"\n",
    "vol_table_7_rh[\"version\"] = \"FS7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5d0d5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "vol_table_5_lh.columns = vol_table_5_lh.columns.str.replace(\"_lh_vol_FS5\", \"\")\n",
    "vol_table_5_rh.columns = vol_table_5_rh.columns.str.replace(\"_rh_vol_FS5\", \"\")\n",
    "vol_table_6_lh.columns = vol_table_6_lh.columns.str.replace(\"_lh_vol_FS6\", \"\")\n",
    "vol_table_6_rh.columns = vol_table_6_rh.columns.str.replace(\"_rh_vol_FS6\", \"\")\n",
    "vol_table_7_lh.columns = vol_table_7_lh.columns.str.replace(\"_lh_vol_FS7\", \"\")\n",
    "vol_table_7_rh.columns = vol_table_7_rh.columns.str.replace(\"_rh_vol_FS7\", \"\")\n",
    "\n",
    "vol_all = pd.concat(\n",
    "    [\n",
    "        vol_table_5_lh,\n",
    "        vol_table_5_rh,\n",
    "        vol_table_6_lh,\n",
    "        vol_table_6_rh,\n",
    "        vol_table_7_lh,\n",
    "        vol_table_7_rh,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# vol_all.to_csv('vol_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8bc84b",
   "metadata": {},
   "source": [
    "### cortical thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "66134877",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_table_5_a = aseg_table.filter(like=\"_ct_FS5\")\n",
    "ct_table_6_a = aseg_table.filter(like=\"_ct_FS6\")\n",
    "ct_table_7_a = aseg_table.filter(like=\"_ct_FS7\")\n",
    "\n",
    "ct_table_coh = aseg_table.filter(like=\"dx_group\")\n",
    "\n",
    "ct_table_5 = pd.concat([ct_table_5_a, ct_table_coh], axis=1)\n",
    "ct_table_6 = pd.concat([ct_table_6_a, ct_table_coh], axis=1)\n",
    "ct_table_7 = pd.concat([ct_table_7_a, ct_table_coh], axis=1)\n",
    "\n",
    "ct_table_5_lh = ct_table_5.filter(like=\"lh_ct_FS5\")\n",
    "ct_table_5_rh = ct_table_5.filter(like=\"rh_ct_FS5\")\n",
    "ct_table_6_lh = ct_table_6.filter(like=\"lh_ct_FS6\")\n",
    "ct_table_6_rh = ct_table_6.filter(like=\"rh_ct_FS6\")\n",
    "ct_table_7_lh = ct_table_7.filter(like=\"lh_ct_FS7\")\n",
    "ct_table_7_rh = ct_table_7.filter(like=\"rh_ct_FS7\")\n",
    "\n",
    "ct_table_5_coh = ct_table_5.filter(like=\"dx_group\")\n",
    "ct_table_6_coh = ct_table_6.filter(like=\"dx_group\")\n",
    "ct_table_7_coh = ct_table_7.filter(like=\"dx_group\")\n",
    "\n",
    "ct_table_5_lh = pd.concat([ct_table_5_lh, ct_table_5_coh], axis=1)\n",
    "ct_table_6_lh = pd.concat([ct_table_6_lh, ct_table_6_coh], axis=1)\n",
    "ct_table_7_lh = pd.concat([ct_table_7_lh, ct_table_7_coh], axis=1)\n",
    "ct_table_5_rh = pd.concat([ct_table_5_rh, ct_table_5_coh], axis=1)\n",
    "ct_table_6_rh = pd.concat([ct_table_6_rh, ct_table_6_coh], axis=1)\n",
    "ct_table_7_rh = pd.concat([ct_table_7_rh, ct_table_7_coh], axis=1)\n",
    "\n",
    "ct_table_5_lh[\"hemi\"] = \"lh\"\n",
    "ct_table_5_rh[\"hemi\"] = \"rh\"\n",
    "ct_table_6_lh[\"hemi\"] = \"lh\"\n",
    "ct_table_6_rh[\"hemi\"] = \"rh\"\n",
    "ct_table_7_lh[\"hemi\"] = \"lh\"\n",
    "ct_table_7_rh[\"hemi\"] = \"rh\"\n",
    "\n",
    "ct_table_5_lh[\"version\"] = \"FS5\"\n",
    "ct_table_5_rh[\"version\"] = \"FS5\"\n",
    "ct_table_6_lh[\"version\"] = \"FS6\"\n",
    "ct_table_6_rh[\"version\"] = \"FS6\"\n",
    "ct_table_7_lh[\"version\"] = \"FS7\"\n",
    "ct_table_7_rh[\"version\"] = \"FS7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6b8f4ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "ct_table_5_lh.columns = ct_table_5_lh.columns.str.replace(\"_lh_ct_FS5\", \"\")\n",
    "ct_table_5_rh.columns = ct_table_5_rh.columns.str.replace(\"_rh_ct_FS5\", \"\")\n",
    "ct_table_6_lh.columns = ct_table_6_lh.columns.str.replace(\"_lh_ct_FS6\", \"\")\n",
    "ct_table_6_rh.columns = ct_table_6_rh.columns.str.replace(\"_rh_ct_FS6\", \"\")\n",
    "ct_table_7_lh.columns = ct_table_7_lh.columns.str.replace(\"_lh_ct_FS7\", \"\")\n",
    "ct_table_7_rh.columns = ct_table_7_rh.columns.str.replace(\"_rh_ct_FS7\", \"\")\n",
    "\n",
    "ct_all = pd.concat(\n",
    "    [\n",
    "        ct_table_5_lh,\n",
    "        ct_table_5_rh,\n",
    "        ct_table_6_lh,\n",
    "        ct_table_6_rh,\n",
    "        ct_table_7_lh,\n",
    "        ct_table_7_rh,\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "ct_table_rh = pd.concat([ct_table_5_rh, ct_table_6_rh, ct_table_7_rh])\n",
    "ct_table_lh = pd.concat([ct_table_5_lh, ct_table_6_lh, ct_table_7_lh])\n",
    "\n",
    "\n",
    "# ct_all.to_csv('ct_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552ac4dd",
   "metadata": {},
   "source": [
    "### surface area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "97b8f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_table_5_a = aseg_table.filter(like=\"_surf_FS5\")\n",
    "surf_table_6_a = aseg_table.filter(like=\"_surf_FS6\")\n",
    "surf_table_7_a = aseg_table.filter(like=\"_surf_FS7\")\n",
    "\n",
    "surf_table_coh = aseg_table.filter(like=\"dx_group\")\n",
    "\n",
    "surf_table_5 = pd.concat([surf_table_5_a, surf_table_coh], axis=1)\n",
    "surf_table_6 = pd.concat([surf_table_6_a, surf_table_coh], axis=1)\n",
    "surf_table_7 = pd.concat([surf_table_7_a, surf_table_coh], axis=1)\n",
    "\n",
    "surf_table_5_lh = surf_table_5.filter(like=\"lh_surf_FS5\")\n",
    "surf_table_5_rh = surf_table_5.filter(like=\"rh_surf_FS5\")\n",
    "surf_table_6_lh = surf_table_6.filter(like=\"lh_surf_FS6\")\n",
    "surf_table_6_rh = surf_table_6.filter(like=\"rh_surf_FS6\")\n",
    "surf_table_7_lh = surf_table_7.filter(like=\"lh_surf_FS7\")\n",
    "surf_table_7_rh = surf_table_7.filter(like=\"rh_surf_FS7\")\n",
    "\n",
    "surf_table_5_coh = surf_table_5.filter(like=\"dx_group\")\n",
    "surf_table_6_coh = surf_table_6.filter(like=\"dx_group\")\n",
    "surf_table_7_coh = surf_table_7.filter(like=\"dx_group\")\n",
    "\n",
    "surf_table_5_lh = pd.concat([surf_table_5_lh, surf_table_5_coh], axis=1)\n",
    "surf_table_6_lh = pd.concat([surf_table_6_lh, surf_table_6_coh], axis=1)\n",
    "surf_table_7_lh = pd.concat([surf_table_7_lh, surf_table_7_coh], axis=1)\n",
    "surf_table_5_rh = pd.concat([surf_table_5_rh, surf_table_5_coh], axis=1)\n",
    "surf_table_6_rh = pd.concat([surf_table_6_rh, surf_table_6_coh], axis=1)\n",
    "surf_table_7_rh = pd.concat([surf_table_7_rh, surf_table_7_coh], axis=1)\n",
    "\n",
    "surf_table_5_lh[\"hemi\"] = \"lh\"\n",
    "surf_table_5_rh[\"hemi\"] = \"rh\"\n",
    "surf_table_6_lh[\"hemi\"] = \"lh\"\n",
    "surf_table_6_rh[\"hemi\"] = \"rh\"\n",
    "surf_table_7_lh[\"hemi\"] = \"lh\"\n",
    "surf_table_7_rh[\"hemi\"] = \"rh\"\n",
    "\n",
    "surf_table_5_lh[\"version\"] = \"FS5\"\n",
    "surf_table_5_rh[\"version\"] = \"FS5\"\n",
    "surf_table_6_lh[\"version\"] = \"FS6\"\n",
    "surf_table_6_rh[\"version\"] = \"FS6\"\n",
    "surf_table_7_lh[\"version\"] = \"FS7\"\n",
    "surf_table_7_rh[\"version\"] = \"FS7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1bbff4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "surf_table_5_lh.columns = surf_table_5_lh.columns.str.replace(\"_lh_surf_FS5\", \"\")\n",
    "surf_table_5_rh.columns = surf_table_5_rh.columns.str.replace(\"_rh_surf_FS5\", \"\")\n",
    "surf_table_6_lh.columns = surf_table_6_lh.columns.str.replace(\"_lh_surf_FS6\", \"\")\n",
    "surf_table_6_rh.columns = surf_table_6_rh.columns.str.replace(\"_rh_surf_FS6\", \"\")\n",
    "surf_table_7_lh.columns = surf_table_7_lh.columns.str.replace(\"_lh_surf_FS7\", \"\")\n",
    "surf_table_7_rh.columns = surf_table_7_rh.columns.str.replace(\"_rh_surf_FS7\", \"\")\n",
    "\n",
    "surf_all = pd.concat(\n",
    "    [\n",
    "        surf_table_5_lh,\n",
    "        surf_table_5_rh,\n",
    "        surf_table_6_lh,\n",
    "        surf_table_6_rh,\n",
    "        surf_table_7_lh,\n",
    "        surf_table_7_rh,\n",
    "    ]\n",
    ")\n",
    "\n",
    "surf_table_rh = pd.concat([surf_table_5_rh, surf_table_6_rh, surf_table_7_rh])\n",
    "surf_table_lh = pd.concat([surf_table_5_lh, surf_table_6_lh, surf_table_7_lh])\n",
    "\n",
    "# surf_all.to_csv('surf_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a651ae76",
   "metadata": {},
   "source": [
    "## Plots - structural estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c1498966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import kaleido\n",
    "\n",
    "y_sub = [\n",
    "    \"Left-Lateral-Ventricle\",\n",
    "    \"Right-Lateral-Ventricle\",\n",
    "    \"Left-Inf-Lat-Vent\",\n",
    "    \"Right-Inf-Lat-Vent\",\n",
    "    \"Left-Cerebellum-White-Matter\",\n",
    "    \"Right-Cerebellum-White-Matter\",\n",
    "    \"Left-Cerebellum-Cortex\",\n",
    "    \"Right-Cerebellum-Cortex\",\n",
    "    \"Left-Thalamus\",\n",
    "    \"Right-Thalamus\",\n",
    "    \"Left-Caudate\",\n",
    "    \"Right-Caudate\",\n",
    "    \"Left-Putamen\",\n",
    "    \"Right-Putamen\",\n",
    "    \"Left-Pallidum\",\n",
    "    \"Right-Pallidum\",\n",
    "    \"Left-Hippocampus\",\n",
    "    \"Right-Hippocampus\",\n",
    "    \"Left-Amygdala\",\n",
    "    \"Right-Amygdala\",\n",
    "    \"Left-Accumbens-area\",\n",
    "    \"Right-Accumbens-area\",\n",
    "    \"Left-VentralDC\",\n",
    "    \"Right-VentralDC\",\n",
    "    \"Left-vessel\",\n",
    "    \"Right-vessel\",\n",
    "    \"Left-choroid-plexus\",\n",
    "    \"Right-choroid-plexus\",\n",
    "    \"3rd-Ventricle\",\n",
    "    \"4th-Ventricle\",\n",
    "    \"5th-Ventricle\",\n",
    "    \"CSF\",\n",
    "    \"Brain-Stem\",\n",
    "    \"Optic-Chiasm\",\n",
    "    \"CC_Posterior\",\n",
    "    \"CC_Mid_Posterior\",\n",
    "    \"CC_Central\",\n",
    "    \"CC_Mid_Anterior\",\n",
    "    \"CC_Anterior\",\n",
    "]\n",
    "\n",
    "y_cort = [\n",
    "    \"G_and_S_frontomargin\",\n",
    "    \"G_and_S_occipital_inf\",\n",
    "    \"G_and_S_paracentral\",\n",
    "    \"G_and_S_subcentral\",\n",
    "    \"G_and_S_transv_frontopol\",\n",
    "    \"G_and_S_cingul-Ant\",\n",
    "    \"G_and_S_cingul-Mid-Ant\",\n",
    "    \"G_and_S_cingul-Mid-Post\",\n",
    "    \"G_cingul-Post-dorsal\",\n",
    "    \"G_cingul-Post-ventral\",\n",
    "    \"G_cuneus\",\n",
    "    \"G_front_inf-Opercular\",\n",
    "    \"G_front_inf-Orbital\",\n",
    "    \"G_front_inf-Triangul\",\n",
    "    \"G_front_middle\",\n",
    "    \"G_front_sup\",\n",
    "    \"G_Ins_lg_and_S_cent_ins\",\n",
    "    \"G_insular_short\",\n",
    "    \"G_occipital_middle\",\n",
    "    \"G_occipital_sup\",\n",
    "    \"G_oc-temp_lat-fusifor\",\n",
    "    \"G_oc-temp_med-Lingual\",\n",
    "    \"G_oc-temp_med-Parahip\",\n",
    "    \"G_orbital\",\n",
    "    \"G_pariet_inf-Angular\",\n",
    "    \"G_pariet_inf-Supramar\",\n",
    "    \"G_parietal_sup\",\n",
    "    \"G_postcentral\",\n",
    "    \"G_precentral\",\n",
    "    \"G_precuneus\",\n",
    "    \"G_rectus\",\n",
    "    \"G_subcallosal\",\n",
    "    \"G_temp_sup-G_T_transv\",\n",
    "    \"G_temp_sup-Lateral\",\n",
    "    \"G_temp_sup-Plan_polar\",\n",
    "    \"G_temp_sup-Plan_tempo\",\n",
    "    \"G_temporal_inf\",\n",
    "    \"G_temporal_middle\",\n",
    "    \"Lat_Fis-ant-Horizont\",\n",
    "    \"Lat_Fis-ant-Vertical\",\n",
    "    \"Lat_Fis-post\",\n",
    "    \"Pole_occipital\",\n",
    "    \"Pole_temporal\",\n",
    "    \"S_calcarine\",\n",
    "    \"S_central\",\n",
    "    \"S_cingul-Marginalis\",\n",
    "    \"S_circular_insula_ant\",\n",
    "    \"S_circular_insula_inf\",\n",
    "    \"S_circular_insula_sup\",\n",
    "    \"S_collat_transv_ant\",\n",
    "    \"S_collat_transv_post\",\n",
    "    \"S_front_inf\",\n",
    "    \"S_front_middle\",\n",
    "    \"S_front_sup\",\n",
    "    \"S_interm_prim-Jensen\",\n",
    "    \"S_intrapariet_and_P_trans\",\n",
    "    \"S_oc_middle_and_Lunatus\",\n",
    "    \"S_oc_sup_and_transversal\",\n",
    "    \"S_occipital_ant\",\n",
    "    \"S_oc-temp_lat\",\n",
    "    \"S_oc-temp_med_and_Lingual\",\n",
    "    \"S_orbital_lateral\",\n",
    "    \"S_orbital_med-olfact\",\n",
    "    \"S_orbital-H_Shaped\",\n",
    "    \"S_parieto_occipital\",\n",
    "    \"S_pericallosal\",\n",
    "    \"S_postcentral\",\n",
    "    \"S_precentral-inf-part\",\n",
    "    \"S_precentral-sup-part\",\n",
    "    \"S_suborbital\",\n",
    "    \"S_subparietal\",\n",
    "    \"S_temporal_inf\",\n",
    "    \"S_temporal_sup\",\n",
    "    \"S_temporal_transverse\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04241bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(\n",
    "    sub_all,\n",
    "    y=y_sub,\n",
    "    color=\"version\",\n",
    ")\n",
    "\n",
    "fig.update_xaxes(gridwidth=1, griddash=\"dot\")\n",
    "fig.update_yaxes(title=\"Volume<br> (mm<sup>3</sup>)\")\n",
    "# fig.write_image(\"plot_sub.png\", width=1920, height=1080)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2740483b",
   "metadata": {},
   "source": [
    "<img src=\"images/plot_est_sub.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea8f9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(\n",
    "    vol_all,\n",
    "    y=y_cort,\n",
    "    color=\"version\",\n",
    "    facet_row=\"hemi\",\n",
    ")\n",
    "\n",
    "fig.update_xaxes(gridwidth=1, griddash=\"dot\")\n",
    "fig.update_yaxes(title=\"Volume<br> (mm<sup>3</sup>)\")\n",
    "# fig.write_image(\"plot_vol.png\", width=1920, height=1080)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8bcbf9",
   "metadata": {},
   "source": [
    "<img src=\"images/plot_est_vol.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9403ad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(\n",
    "    surf_all,\n",
    "    y=y_cort,\n",
    "    color=\"version\",\n",
    "    facet_row=\"hemi\",\n",
    ")\n",
    "\n",
    "fig.update_xaxes(gridwidth=1, griddash=\"dot\")\n",
    "fig.update_yaxes(title=\"Surface area<br> (mm<sup>2</sup>)\")\n",
    "# fig.write_image(\"plot_surf.png\", width=1920, height=1080)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec356f4",
   "metadata": {},
   "source": [
    "<img src=\"images/plot_est_surf.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decfa35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(\n",
    "    ct_all,\n",
    "    y=y_cort,\n",
    "    color=\"version\",\n",
    "    facet_row=\"hemi\",\n",
    ")\n",
    "\n",
    "fig.update_xaxes(gridwidth=1, griddash=\"dot\")\n",
    "fig.update_yaxes(title=\"Thickness<br> (mm)\")\n",
    "# fig.write_image(\"plot_ct.png\", width=1920, height=1080)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee4ec03",
   "metadata": {},
   "source": [
    "<img src=\"images/plot_est_ct.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4289a6aa",
   "metadata": {},
   "source": [
    "# Plots - between-version and between-subject variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f2d0bc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sd across subjects\n",
    "\n",
    "sub5_between = sub_all.loc[(sub_all[\"version\"] == \"FS5\")]\n",
    "sub5_between = sub5_between.std()\n",
    "sub5_between[\"version\"] = \"FS5\"\n",
    "\n",
    "\n",
    "sub6_between = sub_all.loc[(sub_all[\"version\"] == \"FS6\")]\n",
    "sub6_between = sub6_between.std()\n",
    "sub6_between[\"version\"] = \"FS6\"\n",
    "\n",
    "\n",
    "sub7_between = sub_all.loc[(sub_all[\"version\"] == \"FS7\")]\n",
    "sub7_between = sub7_between.std()\n",
    "sub7_between[\"version\"] = \"FS7\"\n",
    "\n",
    "\n",
    "sub5_between = pd.DataFrame(data=sub5_between).T\n",
    "sub6_between = pd.DataFrame(data=sub6_between).T\n",
    "sub7_between = pd.DataFrame(data=sub7_between).T\n",
    "\n",
    "sub_between = pd.concat([sub5_between, sub6_between, sub7_between])\n",
    "\n",
    "sub_between = sub_between[\n",
    "    [\n",
    "        \"Left-Lateral-Ventricle\",\n",
    "        \"Right-Lateral-Ventricle\",\n",
    "        \"Left-Inf-Lat-Vent\",\n",
    "        \"Right-Inf-Lat-Vent\",\n",
    "        \"Left-Cerebellum-White-Matter\",\n",
    "        \"Right-Cerebellum-White-Matter\",\n",
    "        \"Left-Cerebellum-Cortex\",\n",
    "        \"Right-Cerebellum-Cortex\",\n",
    "        \"Left-Thalamus\",\n",
    "        \"Right-Thalamus\",\n",
    "        \"Left-Caudate\",\n",
    "        \"Right-Caudate\",\n",
    "        \"Left-Putamen\",\n",
    "        \"Right-Putamen\",\n",
    "        \"Left-Pallidum\",\n",
    "        \"Right-Pallidum\",\n",
    "        \"Left-Hippocampus\",\n",
    "        \"Right-Hippocampus\",\n",
    "        \"Left-Amygdala\",\n",
    "        \"Right-Amygdala\",\n",
    "        \"Left-Accumbens-area\",\n",
    "        \"Right-Accumbens-area\",\n",
    "        \"Left-VentralDC\",\n",
    "        \"Right-VentralDC\",\n",
    "        \"Left-vessel\",\n",
    "        \"Right-vessel\",\n",
    "        \"Left-choroid-plexus\",\n",
    "        \"Right-choroid-plexus\",\n",
    "        \"3rd-Ventricle\",\n",
    "        \"4th-Ventricle\",\n",
    "        \"5th-Ventricle\",\n",
    "        \"CSF\",\n",
    "        \"Brain-Stem\",\n",
    "        \"Optic-Chiasm\",\n",
    "        \"CC_Posterior\",\n",
    "        \"CC_Mid_Posterior\",\n",
    "        \"CC_Central\",\n",
    "        \"CC_Mid_Anterior\",\n",
    "        \"CC_Anterior\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e5b483cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sd across subjects cort\n",
    "\n",
    "# vol\n",
    "vol5lh_between = vol_all.loc[(vol_all[\"version\"] == \"FS5\") & (vol_all[\"hemi\"] == \"lh\")]\n",
    "vol5lh_between = vol5lh_between.std()\n",
    "vol5lh_between[\"version\"] = \"FS5\"\n",
    "vol5lh_between[\"hemi\"] = \"lh\"\n",
    "\n",
    "vol5rh_between = vol_all.loc[(vol_all[\"version\"] == \"FS5\") & (vol_all[\"hemi\"] == \"rh\")]\n",
    "vol5rh_between = vol5rh_between.std()\n",
    "vol5rh_between[\"version\"] = \"FS5\"\n",
    "vol5rh_between[\"hemi\"] = \"rh\"\n",
    "\n",
    "vol6lh_between = vol_all.loc[(vol_all[\"version\"] == \"FS6\") & (vol_all[\"hemi\"] == \"lh\")]\n",
    "vol6lh_between = vol6lh_between.std()\n",
    "vol6lh_between[\"version\"] = \"FS6\"\n",
    "vol6lh_between[\"hemi\"] = \"lh\"\n",
    "\n",
    "vol6rh_between = vol_all.loc[(vol_all[\"version\"] == \"FS6\") & (vol_all[\"hemi\"] == \"rh\")]\n",
    "vol6rh_between = vol6rh_between.std()\n",
    "vol6rh_between[\"version\"] = \"FS6\"\n",
    "vol6rh_between[\"hemi\"] = \"rh\"\n",
    "\n",
    "vol7lh_between = vol_all.loc[(vol_all[\"version\"] == \"FS7\") & (vol_all[\"hemi\"] == \"lh\")]\n",
    "vol7lh_between = vol7lh_between.std()\n",
    "vol7lh_between[\"version\"] = \"FS7\"\n",
    "vol7lh_between[\"hemi\"] = \"lh\"\n",
    "\n",
    "vol7rh_between = vol_all.loc[(vol_all[\"version\"] == \"FS7\") & (vol_all[\"hemi\"] == \"rh\")]\n",
    "vol7rh_between = vol7rh_between.std()\n",
    "vol7rh_between[\"version\"] = \"FS7\"\n",
    "vol7rh_between[\"hemi\"] = \"rh\"\n",
    "\n",
    "\n",
    "vol5lh_between = pd.DataFrame(data=vol5lh_between).T\n",
    "vol5rh_between = pd.DataFrame(data=vol5rh_between).T\n",
    "vol6lh_between = pd.DataFrame(data=vol6lh_between).T\n",
    "vol6rh_between = pd.DataFrame(data=vol6rh_between).T\n",
    "vol7lh_between = pd.DataFrame(data=vol7lh_between).T\n",
    "vol7rh_between = pd.DataFrame(data=vol7rh_between).T\n",
    "\n",
    "vol_between = pd.concat(\n",
    "    [\n",
    "        vol5lh_between,\n",
    "        vol5rh_between,\n",
    "        vol6lh_between,\n",
    "        vol6rh_between,\n",
    "        vol7lh_between,\n",
    "        vol7rh_between,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# surf\n",
    "surf5lh_between = surf_all.loc[\n",
    "    (surf_all[\"version\"] == \"FS5\") & (surf_all[\"hemi\"] == \"lh\")\n",
    "]\n",
    "surf5lh_between = surf5lh_between.std()\n",
    "surf5lh_between[\"version\"] = \"FS5\"\n",
    "surf5lh_between[\"hemi\"] = \"lh\"\n",
    "\n",
    "surf5rh_between = surf_all.loc[\n",
    "    (surf_all[\"version\"] == \"FS5\") & (surf_all[\"hemi\"] == \"rh\")\n",
    "]\n",
    "surf5rh_between = surf5rh_between.std()\n",
    "surf5rh_between[\"version\"] = \"FS5\"\n",
    "surf5rh_between[\"hemi\"] = \"rh\"\n",
    "\n",
    "surf6lh_between = surf_all.loc[\n",
    "    (surf_all[\"version\"] == \"FS6\") & (surf_all[\"hemi\"] == \"lh\")\n",
    "]\n",
    "surf6lh_between = surf6lh_between.std()\n",
    "surf6lh_between[\"version\"] = \"FS6\"\n",
    "surf6lh_between[\"hemi\"] = \"lh\"\n",
    "\n",
    "surf6rh_between = surf_all.loc[\n",
    "    (surf_all[\"version\"] == \"FS6\") & (surf_all[\"hemi\"] == \"rh\")\n",
    "]\n",
    "surf6rh_between = surf6rh_between.std()\n",
    "surf6rh_between[\"version\"] = \"FS6\"\n",
    "surf6rh_between[\"hemi\"] = \"rh\"\n",
    "\n",
    "surf7lh_between = surf_all.loc[\n",
    "    (surf_all[\"version\"] == \"FS7\") & (surf_all[\"hemi\"] == \"lh\")\n",
    "]\n",
    "surf7lh_between = surf7lh_between.std()\n",
    "surf7lh_between[\"version\"] = \"FS7\"\n",
    "surf7lh_between[\"hemi\"] = \"lh\"\n",
    "\n",
    "surf7rh_between = surf_all.loc[\n",
    "    (surf_all[\"version\"] == \"FS7\") & (surf_all[\"hemi\"] == \"rh\")\n",
    "]\n",
    "surf7rh_between = surf7rh_between.std()\n",
    "surf7rh_between[\"version\"] = \"FS7\"\n",
    "surf7rh_between[\"hemi\"] = \"rh\"\n",
    "\n",
    "\n",
    "surf5lh_between = pd.DataFrame(data=surf5lh_between).T\n",
    "surf5rh_between = pd.DataFrame(data=surf5rh_between).T\n",
    "surf6lh_between = pd.DataFrame(data=surf6lh_between).T\n",
    "surf6rh_between = pd.DataFrame(data=surf6rh_between).T\n",
    "surf7lh_between = pd.DataFrame(data=surf7lh_between).T\n",
    "surf7rh_between = pd.DataFrame(data=surf7rh_between).T\n",
    "\n",
    "surf_between = pd.concat(\n",
    "    [\n",
    "        surf5lh_between,\n",
    "        surf5rh_between,\n",
    "        surf6lh_between,\n",
    "        surf6rh_between,\n",
    "        surf7lh_between,\n",
    "        surf7rh_between,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ct\n",
    "ct5lh_between = ct_all.loc[(ct_all[\"version\"] == \"FS5\") & (ct_all[\"hemi\"] == \"lh\")]\n",
    "ct5lh_between = ct5lh_between.std()\n",
    "ct5lh_between[\"version\"] = \"FS5\"\n",
    "ct5lh_between[\"hemi\"] = \"lh\"\n",
    "\n",
    "ct5rh_between = ct_all.loc[(ct_all[\"version\"] == \"FS5\") & (ct_all[\"hemi\"] == \"rh\")]\n",
    "ct5rh_between = ct5rh_between.std()\n",
    "ct5rh_between[\"version\"] = \"FS5\"\n",
    "ct5rh_between[\"hemi\"] = \"rh\"\n",
    "\n",
    "ct6lh_between = ct_all.loc[(ct_all[\"version\"] == \"FS6\") & (ct_all[\"hemi\"] == \"lh\")]\n",
    "ct6lh_between = ct6lh_between.std()\n",
    "ct6lh_between[\"version\"] = \"FS6\"\n",
    "ct6lh_between[\"hemi\"] = \"lh\"\n",
    "\n",
    "ct6rh_between = ct_all.loc[(ct_all[\"version\"] == \"FS6\") & (ct_all[\"hemi\"] == \"rh\")]\n",
    "ct6rh_between = ct6rh_between.std()\n",
    "ct6rh_between[\"version\"] = \"FS6\"\n",
    "ct6rh_between[\"hemi\"] = \"rh\"\n",
    "\n",
    "ct7lh_between = ct_all.loc[(ct_all[\"version\"] == \"FS7\") & (ct_all[\"hemi\"] == \"lh\")]\n",
    "ct7lh_between = ct7lh_between.std()\n",
    "ct7lh_between[\"version\"] = \"FS7\"\n",
    "ct7lh_between[\"hemi\"] = \"lh\"\n",
    "\n",
    "ct7rh_between = ct_all.loc[(ct_all[\"version\"] == \"FS7\") & (ct_all[\"hemi\"] == \"rh\")]\n",
    "ct7rh_between = ct7rh_between.std()\n",
    "ct7rh_between[\"version\"] = \"FS7\"\n",
    "ct7rh_between[\"hemi\"] = \"rh\"\n",
    "\n",
    "\n",
    "ct5lh_between = pd.DataFrame(data=ct5lh_between).T\n",
    "ct5rh_between = pd.DataFrame(data=ct5rh_between).T\n",
    "ct6lh_between = pd.DataFrame(data=ct6lh_between).T\n",
    "ct6rh_between = pd.DataFrame(data=ct6rh_between).T\n",
    "ct7lh_between = pd.DataFrame(data=ct7lh_between).T\n",
    "ct7rh_between = pd.DataFrame(data=ct7rh_between).T\n",
    "\n",
    "ct_between = pd.concat(\n",
    "    [\n",
    "        ct5lh_between,\n",
    "        ct5rh_between,\n",
    "        ct6lh_between,\n",
    "        ct6rh_between,\n",
    "        ct7lh_between,\n",
    "        ct7rh_between,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "21039609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference between versions\n",
    "\n",
    "sub_diff_table_76_a = aseg_table.filter(like=\"FS7_6_diff_\")\n",
    "sub_diff_table_75_a = aseg_table.filter(like=\"FS7_5_diff_\")\n",
    "sub_diff_table_65_a = aseg_table.filter(like=\"FS6_5_diff_\")\n",
    "\n",
    "sub_diff_table_coh = aseg_table.filter(like=\"dx_group\")\n",
    "\n",
    "sub_diff_table_75 = pd.concat([sub_diff_table_75_a, sub_diff_table_coh], axis=1)\n",
    "sub_diff_table_76 = pd.concat([sub_diff_table_76_a, sub_diff_table_coh], axis=1)\n",
    "sub_diff_table_65 = pd.concat([sub_diff_table_65_a, sub_diff_table_coh], axis=1)\n",
    "\n",
    "sub_diff_table_76[\"version\"] = \"FS76\"\n",
    "sub_diff_table_75[\"version\"] = \"FS75\"\n",
    "sub_diff_table_65[\"version\"] = \"FS65\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1076a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_diff_table_76.columns = sub_diff_table_76.columns.str.replace(\"FS7_6_diff_\", \"\")\n",
    "sub_diff_table_75.columns = sub_diff_table_75.columns.str.replace(\"FS7_5_diff_\", \"\")\n",
    "sub_diff_table_65.columns = sub_diff_table_65.columns.str.replace(\"FS6_5_diff_\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6f4c552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_diff_table_76 = sub_diff_table_76[\n",
    "    [\n",
    "        \"Left-Lateral-Ventricle\",\n",
    "        \"Left-Inf-Lat-Vent\",\n",
    "        \"Left-Cerebellum-White-Matter\",\n",
    "        \"Left-Cerebellum-Cortex\",\n",
    "        \"Left-Thalamus\",\n",
    "        \"Left-Caudate\",\n",
    "        \"Left-Putamen\",\n",
    "        \"Left-Pallidum\",\n",
    "        \"3rd-Ventricle\",\n",
    "        \"4th-Ventricle\",\n",
    "        \"Brain-Stem\",\n",
    "        \"Left-Hippocampus\",\n",
    "        \"Left-Amygdala\",\n",
    "        \"CSF\",\n",
    "        \"Left-Accumbens-area\",\n",
    "        \"Left-VentralDC\",\n",
    "        \"Left-vessel\",\n",
    "        \"Left-choroid-plexus\",\n",
    "        \"Right-Lateral-Ventricle\",\n",
    "        \"Right-Inf-Lat-Vent\",\n",
    "        \"Right-Cerebellum-White-Matter\",\n",
    "        \"Right-Cerebellum-Cortex\",\n",
    "        \"Right-Thalamus\",\n",
    "        \"Right-Caudate\",\n",
    "        \"Right-Putamen\",\n",
    "        \"Right-Pallidum\",\n",
    "        \"Right-Hippocampus\",\n",
    "        \"Right-Amygdala\",\n",
    "        \"Right-Accumbens-area\",\n",
    "        \"Right-VentralDC\",\n",
    "        \"Right-vessel\",\n",
    "        \"Right-choroid-plexus\",\n",
    "        \"5th-Ventricle\",\n",
    "        \"Optic-Chiasm\",\n",
    "        \"CC_Posterior\",\n",
    "        \"CC_Mid_Posterior\",\n",
    "        \"CC_Central\",\n",
    "        \"CC_Mid_Anterior\",\n",
    "        \"CC_Anterior\",\n",
    "        \"version\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "sub_diff_table_75 = sub_diff_table_75[\n",
    "    [\n",
    "        \"Left-Lateral-Ventricle\",\n",
    "        \"Left-Inf-Lat-Vent\",\n",
    "        \"Left-Cerebellum-White-Matter\",\n",
    "        \"Left-Cerebellum-Cortex\",\n",
    "        \"Left-Thalamus\",\n",
    "        \"Left-Caudate\",\n",
    "        \"Left-Putamen\",\n",
    "        \"Left-Pallidum\",\n",
    "        \"3rd-Ventricle\",\n",
    "        \"4th-Ventricle\",\n",
    "        \"Brain-Stem\",\n",
    "        \"Left-Hippocampus\",\n",
    "        \"Left-Amygdala\",\n",
    "        \"CSF\",\n",
    "        \"Left-Accumbens-area\",\n",
    "        \"Left-VentralDC\",\n",
    "        \"Left-vessel\",\n",
    "        \"Left-choroid-plexus\",\n",
    "        \"Right-Lateral-Ventricle\",\n",
    "        \"Right-Inf-Lat-Vent\",\n",
    "        \"Right-Cerebellum-White-Matter\",\n",
    "        \"Right-Cerebellum-Cortex\",\n",
    "        \"Right-Thalamus\",\n",
    "        \"Right-Caudate\",\n",
    "        \"Right-Putamen\",\n",
    "        \"Right-Pallidum\",\n",
    "        \"Right-Hippocampus\",\n",
    "        \"Right-Amygdala\",\n",
    "        \"Right-Accumbens-area\",\n",
    "        \"Right-VentralDC\",\n",
    "        \"Right-vessel\",\n",
    "        \"Right-choroid-plexus\",\n",
    "        \"5th-Ventricle\",\n",
    "        \"Optic-Chiasm\",\n",
    "        \"CC_Posterior\",\n",
    "        \"CC_Mid_Posterior\",\n",
    "        \"CC_Central\",\n",
    "        \"CC_Mid_Anterior\",\n",
    "        \"CC_Anterior\",\n",
    "        \"version\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "sub_diff_table_65 = sub_diff_table_65[\n",
    "    [\n",
    "        \"Left-Lateral-Ventricle\",\n",
    "        \"Left-Inf-Lat-Vent\",\n",
    "        \"Left-Cerebellum-White-Matter\",\n",
    "        \"Left-Cerebellum-Cortex\",\n",
    "        \"Left-Thalamus\",\n",
    "        \"Left-Caudate\",\n",
    "        \"Left-Putamen\",\n",
    "        \"Left-Pallidum\",\n",
    "        \"3rd-Ventricle\",\n",
    "        \"4th-Ventricle\",\n",
    "        \"Brain-Stem\",\n",
    "        \"Left-Hippocampus\",\n",
    "        \"Left-Amygdala\",\n",
    "        \"CSF\",\n",
    "        \"Left-Accumbens-area\",\n",
    "        \"Left-VentralDC\",\n",
    "        \"Left-vessel\",\n",
    "        \"Left-choroid-plexus\",\n",
    "        \"Right-Lateral-Ventricle\",\n",
    "        \"Right-Inf-Lat-Vent\",\n",
    "        \"Right-Cerebellum-White-Matter\",\n",
    "        \"Right-Cerebellum-Cortex\",\n",
    "        \"Right-Thalamus\",\n",
    "        \"Right-Caudate\",\n",
    "        \"Right-Putamen\",\n",
    "        \"Right-Pallidum\",\n",
    "        \"Right-Hippocampus\",\n",
    "        \"Right-Amygdala\",\n",
    "        \"Right-Accumbens-area\",\n",
    "        \"Right-VentralDC\",\n",
    "        \"Right-vessel\",\n",
    "        \"Right-choroid-plexus\",\n",
    "        \"5th-Ventricle\",\n",
    "        \"Optic-Chiasm\",\n",
    "        \"CC_Posterior\",\n",
    "        \"CC_Mid_Posterior\",\n",
    "        \"CC_Central\",\n",
    "        \"CC_Mid_Anterior\",\n",
    "        \"CC_Anterior\",\n",
    "        \"version\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "sub_diff_all = pd.concat([sub_diff_table_76, sub_diff_table_75, sub_diff_table_65])\n",
    "\n",
    "\n",
    "# sub_diff_all.to_csv('sub_diff_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "df99eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df with difference\n",
    "\n",
    "diff_table_76_a = aseg_table.filter(like=\"FS7_6_diff_\")\n",
    "diff_table_75_a = aseg_table.filter(like=\"FS7_5_diff_\")\n",
    "diff_table_65_a = aseg_table.filter(like=\"FS6_5_diff_\")\n",
    "\n",
    "# create df with volume difference\n",
    "\n",
    "diff_table_vol_76_rh = diff_table_76_a.filter(regex=(\"FS7_6_diff_rh.+?vol\"), axis=1)\n",
    "diff_table_vol_75_rh = diff_table_75_a.filter(regex=(\"FS7_5_diff_rh.+?vol\"), axis=1)\n",
    "diff_table_vol_65_rh = diff_table_65_a.filter(regex=(\"FS6_5_diff_rh.+?vol\"), axis=1)\n",
    "diff_table_vol_76_rh[\"version\"] = \"FS76\"\n",
    "diff_table_vol_75_rh[\"version\"] = \"FS75\"\n",
    "diff_table_vol_65_rh[\"version\"] = \"FS65\"\n",
    "diff_table_vol_76_rh[\"hemi\"] = \"rh\"\n",
    "diff_table_vol_75_rh[\"hemi\"] = \"rh\"\n",
    "diff_table_vol_65_rh[\"hemi\"] = \"rh\"\n",
    "\n",
    "diff_table_vol_76_lh = sub_diff_table_76_a.filter(regex=(\"FS7_6_diff_lh.+?vol\"), axis=1)\n",
    "diff_table_vol_75_lh = sub_diff_table_75_a.filter(regex=(\"FS7_5_diff_lh.+?vol\"), axis=1)\n",
    "diff_table_vol_65_lh = sub_diff_table_65_a.filter(regex=(\"FS6_5_diff_lh.+?vol\"), axis=1)\n",
    "diff_table_vol_76_lh[\"version\"] = \"FS76\"\n",
    "diff_table_vol_75_lh[\"version\"] = \"FS75\"\n",
    "diff_table_vol_65_lh[\"version\"] = \"FS65\"\n",
    "diff_table_vol_76_lh[\"hemi\"] = \"lh\"\n",
    "diff_table_vol_75_lh[\"hemi\"] = \"lh\"\n",
    "diff_table_vol_65_lh[\"hemi\"] = \"lh\"\n",
    "\n",
    "diff_table_vol_76_rh.columns = diff_table_vol_76_rh.columns.str.replace(\n",
    "    \"FS7_6_diff_rh_\", \"\"\n",
    ")\n",
    "diff_table_vol_76_rh.columns = diff_table_vol_76_rh.columns.str.replace(\"_vol\", \"\")\n",
    "diff_table_vol_75_rh.columns = diff_table_vol_75_rh.columns.str.replace(\n",
    "    \"FS7_5_diff_rh_\", \"\"\n",
    ")\n",
    "diff_table_vol_75_rh.columns = diff_table_vol_75_rh.columns.str.replace(\"_vol\", \"\")\n",
    "diff_table_vol_65_rh.columns = diff_table_vol_65_rh.columns.str.replace(\n",
    "    \"FS6_5_diff_rh_\", \"\"\n",
    ")\n",
    "diff_table_vol_65_rh.columns = diff_table_vol_65_rh.columns.str.replace(\"_vol\", \"\")\n",
    "diff_table_vol_76_lh.columns = diff_table_vol_76_lh.columns.str.replace(\n",
    "    \"FS7_6_diff_lh_\", \"\"\n",
    ")\n",
    "diff_table_vol_76_lh.columns = diff_table_vol_76_lh.columns.str.replace(\"_vol\", \"\")\n",
    "diff_table_vol_75_lh.columns = diff_table_vol_75_lh.columns.str.replace(\n",
    "    \"FS7_5_diff_lh_\", \"\"\n",
    ")\n",
    "diff_table_vol_75_lh.columns = diff_table_vol_75_lh.columns.str.replace(\"_vol\", \"\")\n",
    "diff_table_vol_65_lh.columns = diff_table_vol_65_lh.columns.str.replace(\n",
    "    \"FS6_5_diff_lh_\", \"\"\n",
    ")\n",
    "diff_table_vol_65_lh.columns = diff_table_vol_65_lh.columns.str.replace(\"_vol\", \"\")\n",
    "\n",
    "diff_table_vol_all = pd.concat(\n",
    "    [\n",
    "        diff_table_vol_76_rh,\n",
    "        diff_table_vol_75_rh,\n",
    "        diff_table_vol_65_rh,\n",
    "        diff_table_vol_76_lh,\n",
    "        diff_table_vol_75_lh,\n",
    "        diff_table_vol_65_lh,\n",
    "    ]\n",
    ")\n",
    "\n",
    "diff_table_vol_rh = pd.concat(\n",
    "    [diff_table_vol_76_rh, diff_table_vol_75_rh, diff_table_vol_65_rh]\n",
    ")\n",
    "diff_table_vol_lh = pd.concat(\n",
    "    [diff_table_vol_76_lh, diff_table_vol_75_lh, diff_table_vol_65_lh]\n",
    ")\n",
    "\n",
    "# create df with surface area difference\n",
    "\n",
    "diff_table_surf_76_rh = diff_table_76_a.filter(regex=(\"FS7_6_diff_rh.+?surf\"), axis=1)\n",
    "diff_table_surf_75_rh = diff_table_75_a.filter(regex=(\"FS7_5_diff_rh.+?surf\"), axis=1)\n",
    "diff_table_surf_65_rh = diff_table_65_a.filter(regex=(\"FS6_5_diff_rh.+?surf\"), axis=1)\n",
    "diff_table_surf_76_rh[\"version\"] = \"FS76\"\n",
    "diff_table_surf_75_rh[\"version\"] = \"FS75\"\n",
    "diff_table_surf_65_rh[\"version\"] = \"FS65\"\n",
    "diff_table_surf_76_rh[\"hemi\"] = \"rh\"\n",
    "diff_table_surf_75_rh[\"hemi\"] = \"rh\"\n",
    "diff_table_surf_65_rh[\"hemi\"] = \"rh\"\n",
    "\n",
    "diff_table_surf_76_lh = sub_diff_table_76_a.filter(\n",
    "    regex=(\"FS7_6_diff_lh.+?surf\"), axis=1\n",
    ")\n",
    "diff_table_surf_75_lh = sub_diff_table_75_a.filter(\n",
    "    regex=(\"FS7_5_diff_lh.+?surf\"), axis=1\n",
    ")\n",
    "diff_table_surf_65_lh = sub_diff_table_65_a.filter(\n",
    "    regex=(\"FS6_5_diff_lh.+?surf\"), axis=1\n",
    ")\n",
    "diff_table_surf_76_lh[\"version\"] = \"FS76\"\n",
    "diff_table_surf_75_lh[\"version\"] = \"FS75\"\n",
    "diff_table_surf_65_lh[\"version\"] = \"FS65\"\n",
    "diff_table_surf_76_lh[\"hemi\"] = \"lh\"\n",
    "diff_table_surf_75_lh[\"hemi\"] = \"lh\"\n",
    "diff_table_surf_65_lh[\"hemi\"] = \"lh\"\n",
    "\n",
    "diff_table_surf_76_rh.columns = diff_table_surf_76_rh.columns.str.replace(\n",
    "    \"FS7_6_diff_rh_\", \"\"\n",
    ")\n",
    "diff_table_surf_76_rh.columns = diff_table_surf_76_rh.columns.str.replace(\"_surf\", \"\")\n",
    "diff_table_surf_75_rh.columns = diff_table_surf_75_rh.columns.str.replace(\n",
    "    \"FS7_5_diff_rh_\", \"\"\n",
    ")\n",
    "diff_table_surf_75_rh.columns = diff_table_surf_75_rh.columns.str.replace(\"_surf\", \"\")\n",
    "diff_table_surf_65_rh.columns = diff_table_surf_65_rh.columns.str.replace(\n",
    "    \"FS6_5_diff_rh_\", \"\"\n",
    ")\n",
    "diff_table_surf_65_rh.columns = diff_table_surf_65_rh.columns.str.replace(\"_surf\", \"\")\n",
    "diff_table_surf_76_lh.columns = diff_table_surf_76_lh.columns.str.replace(\n",
    "    \"FS7_6_diff_lh_\", \"\"\n",
    ")\n",
    "diff_table_surf_76_lh.columns = diff_table_surf_76_lh.columns.str.replace(\"_surf\", \"\")\n",
    "diff_table_surf_75_lh.columns = diff_table_surf_75_lh.columns.str.replace(\n",
    "    \"FS7_5_diff_lh_\", \"\"\n",
    ")\n",
    "diff_table_surf_75_lh.columns = diff_table_surf_75_lh.columns.str.replace(\"_surf\", \"\")\n",
    "diff_table_surf_65_lh.columns = diff_table_surf_65_lh.columns.str.replace(\n",
    "    \"FS6_5_diff_lh_\", \"\"\n",
    ")\n",
    "diff_table_surf_65_lh.columns = diff_table_surf_65_lh.columns.str.replace(\"_surf\", \"\")\n",
    "\n",
    "diff_table_surf_all = pd.concat(\n",
    "    [\n",
    "        diff_table_surf_76_rh,\n",
    "        diff_table_surf_75_rh,\n",
    "        diff_table_surf_65_rh,\n",
    "        diff_table_surf_76_lh,\n",
    "        diff_table_surf_75_lh,\n",
    "        diff_table_surf_65_lh,\n",
    "    ]\n",
    ")\n",
    "\n",
    "diff_table_surf_rh = pd.concat(\n",
    "    [diff_table_surf_76_rh, diff_table_surf_75_rh, diff_table_surf_65_rh]\n",
    ")\n",
    "\n",
    "diff_table_surf_lh = pd.concat(\n",
    "    [diff_table_surf_76_lh, diff_table_surf_75_lh, diff_table_surf_65_lh]\n",
    ")\n",
    "\n",
    "# create df with cortical thickness difference\n",
    "\n",
    "diff_table_ct_76_rh = diff_table_76_a.filter(regex=(\"FS7_6_diff_rh.+?_ct\"), axis=1)\n",
    "diff_table_ct_75_rh = diff_table_75_a.filter(regex=(\"FS7_5_diff_rh.+?_ct\"), axis=1)\n",
    "diff_table_ct_65_rh = diff_table_65_a.filter(regex=(\"FS6_5_diff_rh.+?_ct\"), axis=1)\n",
    "diff_table_ct_76_rh[\"version\"] = \"FS76\"\n",
    "diff_table_ct_75_rh[\"version\"] = \"FS75\"\n",
    "diff_table_ct_65_rh[\"version\"] = \"FS65\"\n",
    "diff_table_ct_76_rh[\"hemi\"] = \"rh\"\n",
    "diff_table_ct_75_rh[\"hemi\"] = \"rh\"\n",
    "diff_table_ct_65_rh[\"hemi\"] = \"rh\"\n",
    "\n",
    "diff_table_ct_76_lh = sub_diff_table_76_a.filter(regex=(\"FS7_6_diff_lh.+?_ct\"), axis=1)\n",
    "diff_table_ct_75_lh = sub_diff_table_75_a.filter(regex=(\"FS7_5_diff_lh.+?_ct\"), axis=1)\n",
    "diff_table_ct_65_lh = sub_diff_table_65_a.filter(regex=(\"FS6_5_diff_lh.+?_ct\"), axis=1)\n",
    "diff_table_ct_76_lh[\"version\"] = \"FS76\"\n",
    "diff_table_ct_75_lh[\"version\"] = \"FS75\"\n",
    "diff_table_ct_65_lh[\"version\"] = \"FS65\"\n",
    "diff_table_ct_76_lh[\"hemi\"] = \"lh\"\n",
    "diff_table_ct_75_lh[\"hemi\"] = \"lh\"\n",
    "diff_table_ct_65_lh[\"hemi\"] = \"lh\"\n",
    "\n",
    "diff_table_ct_76_rh.columns = diff_table_ct_76_rh.columns.str.replace(\n",
    "    \"FS7_6_diff_rh_\", \"\"\n",
    ")\n",
    "diff_table_ct_76_rh.columns = diff_table_ct_76_rh.columns.str.replace(\"_ct\", \"\")\n",
    "diff_table_ct_75_rh.columns = diff_table_ct_75_rh.columns.str.replace(\n",
    "    \"FS7_5_diff_rh_\", \"\"\n",
    ")\n",
    "diff_table_ct_75_rh.columns = diff_table_ct_75_rh.columns.str.replace(\"_ct\", \"\")\n",
    "diff_table_ct_65_rh.columns = diff_table_ct_65_rh.columns.str.replace(\n",
    "    \"FS6_5_diff_rh_\", \"\"\n",
    ")\n",
    "diff_table_ct_65_rh.columns = diff_table_ct_65_rh.columns.str.replace(\"_ct\", \"\")\n",
    "diff_table_ct_76_lh.columns = diff_table_ct_76_lh.columns.str.replace(\n",
    "    \"FS7_6_diff_lh_\", \"\"\n",
    ")\n",
    "diff_table_ct_76_lh.columns = diff_table_ct_76_lh.columns.str.replace(\"_ct\", \"\")\n",
    "diff_table_ct_75_lh.columns = diff_table_ct_75_lh.columns.str.replace(\n",
    "    \"FS7_5_diff_lh_\", \"\"\n",
    ")\n",
    "diff_table_ct_75_lh.columns = diff_table_ct_75_lh.columns.str.replace(\"_ct\", \"\")\n",
    "diff_table_ct_65_lh.columns = diff_table_ct_65_lh.columns.str.replace(\n",
    "    \"FS6_5_diff_lh_\", \"\"\n",
    ")\n",
    "diff_table_ct_65_lh.columns = diff_table_ct_65_lh.columns.str.replace(\"_ct\", \"\")\n",
    "\n",
    "diff_table_ct_all = pd.concat(\n",
    "    [\n",
    "        diff_table_ct_76_rh,\n",
    "        diff_table_ct_75_rh,\n",
    "        diff_table_ct_65_rh,\n",
    "        diff_table_ct_76_lh,\n",
    "        diff_table_ct_75_lh,\n",
    "        diff_table_ct_65_lh,\n",
    "    ]\n",
    ")\n",
    "\n",
    "diff_table_ct_rh = pd.concat(\n",
    "    [diff_table_ct_76_rh, diff_table_ct_75_rh, diff_table_ct_65_rh]\n",
    ")\n",
    "\n",
    "diff_table_ct_lh = pd.concat(\n",
    "    [diff_table_ct_76_lh, diff_table_ct_75_lh, diff_table_ct_65_lh]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3887fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subcortical plot\n",
    "\n",
    "\n",
    "x = sub_diff_all\n",
    "x[\"version\"].replace(\"FS76\", \"FS 7 vs 6\", inplace=True)\n",
    "x[\"version\"].replace(\"FS75\", \"FS 7 vs 5\", inplace=True)\n",
    "x[\"version\"].replace(\"FS65\", \"FS 6 vs 5\", inplace=True)\n",
    "\n",
    "fig = px.box(\n",
    "    x,\n",
    "    y=y_sub,\n",
    "    color=\"version\",\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_sub,\n",
    "        y=sub_between.iloc[0],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"x\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 5\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_sub,\n",
    "        y=sub_between.iloc[1],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"triangle-up\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 6\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_sub,\n",
    "        y=sub_between.iloc[2],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"circle\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 7\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_xaxes(title=\"\", gridwidth=1, griddash=\"dot\")\n",
    "fig.update_yaxes(title=\"Volume (mm<sup>3</sup>)\")\n",
    "fig.update_yaxes(range=[-1000, 14000])\n",
    "fig.update_layout(legend_title_text=\"Legend\", font_size=12)\n",
    "# fig.write_image(\"plot_sub_both_short_large.png\", width=1920, height=1080)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462566f9",
   "metadata": {},
   "source": [
    "<img src=\"images/plot_sub.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ed43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sub_diff_all.copy()\n",
    "x[\"version\"].replace(\"FS76\", \"FS 7 vs 6\", inplace=True)\n",
    "x[\"version\"].replace(\"FS75\", \"FS 7 vs 5\", inplace=True)\n",
    "x[\"version\"].replace(\"FS65\", \"FS 6 vs 5\", inplace=True)\n",
    "\n",
    "x = x[\n",
    "    [\n",
    "        \"CC_Anterior\",\n",
    "        \"CC_Mid_Anterior\",\n",
    "        \"CC_Central\",\n",
    "        \"CC_Mid_Posterior\",\n",
    "        \"CC_Posterior\",\n",
    "        \"Optic-Chiasm\",\n",
    "        \"Brain-Stem\",\n",
    "        \"CSF\",\n",
    "        \"5th-Ventricle\",\n",
    "        \"4th-Ventricle\",\n",
    "        \"3rd-Ventricle\",\n",
    "        \"Right-choroid-plexus\",\n",
    "        \"Left-choroid-plexus\",\n",
    "        \"Right-vessel\",\n",
    "        \"Left-vessel\",\n",
    "        \"Right-VentralDC\",\n",
    "        \"Left-VentralDC\",\n",
    "        \"Right-Accumbens-area\",\n",
    "        \"Left-Accumbens-area\",\n",
    "        \"Right-Amygdala\",\n",
    "        \"Left-Amygdala\",\n",
    "        \"Right-Hippocampus\",\n",
    "        \"Left-Hippocampus\",\n",
    "        \"Right-Pallidum\",\n",
    "        \"Left-Pallidum\",\n",
    "        \"Right-Putamen\",\n",
    "        \"Left-Putamen\",\n",
    "        \"Right-Caudate\",\n",
    "        \"Left-Caudate\",\n",
    "        \"Right-Thalamus\",\n",
    "        \"Left-Thalamus\",\n",
    "        \"Right-Cerebellum-Cortex\",\n",
    "        \"Left-Cerebellum-Cortex\",\n",
    "        \"Right-Cerebellum-White-Matter\",\n",
    "        \"Left-Cerebellum-White-Matter\",\n",
    "        \"Right-Inf-Lat-Vent\",\n",
    "        \"Left-Inf-Lat-Vent\",\n",
    "        \"Right-Lateral-Ventricle\",\n",
    "        \"Left-Lateral-Ventricle\",\n",
    "        \"version\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "fig = px.box(\n",
    "    data_frame=x,\n",
    "    color=\"version\",\n",
    "    orientation=\"h\",\n",
    ")\n",
    "\n",
    "for data in fig.data:\n",
    "    data.legendgroup = \"group1\"\n",
    "    data.legendgrouptitle = {\"text\": \"Between-version\"}\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_sub,\n",
    "        x=sub_between.iloc[0],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"x\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 5\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_sub,\n",
    "        x=sub_between.iloc[1],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"triangle-up\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        name=\"FS 6\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_sub,\n",
    "        x=sub_between.iloc[2],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"circle\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        name=\"FS 7\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_yaxes(title=\"Subcortical regions\", gridwidth=1, griddash=\"dot\")\n",
    "fig.update_xaxes(title=\"Volume (mm<sup>3</sup>)\")\n",
    "fig.update_xaxes(range=[-1000, 14000])\n",
    "fig.update_layout(legend_title_text=\"\", font_size=20)\n",
    "\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.05,\n",
    "        xanchor=\"left\",\n",
    "        x=0,\n",
    "        font_size=20,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    legend2=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.03,\n",
    "        xanchor=\"left\",\n",
    "        x=0,\n",
    "        font_size=20,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# fig.write_image(\"plot_sub_both_short_large.png\", width=1080, height=1920)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158b341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot volume\n",
    "\n",
    "x = diff_table_vol_all\n",
    "x[\"version\"].replace(\"FS76\", \"FS 7 vs 6\", inplace=True)\n",
    "x[\"version\"].replace(\"FS75\", \"FS 7 vs 5\", inplace=True)\n",
    "x[\"version\"].replace(\"FS65\", \"FS 6 vs 5\", inplace=True)\n",
    "\n",
    "fig = px.box(\n",
    "    x,\n",
    "    y=y_cort,\n",
    "    color=\"version\",\n",
    "    facet_row=\"hemi\",\n",
    ")\n",
    "\n",
    "for data in fig.data:\n",
    "    data.legendgroup = \"group1\"\n",
    "    data.legendgrouptitle = {\"text\": \"Between-version\"}\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_cort,\n",
    "        y=vol_between.iloc[0],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"x\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 5\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_cort,\n",
    "        y=vol_between.iloc[1],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"x\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 5\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    ),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_cort,\n",
    "        y=vol_between.iloc[2],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"triangle-up\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 6\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_cort,\n",
    "        y=vol_between.iloc[3],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"triangle-up\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 6\",\n",
    "    ),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_cort,\n",
    "        y=vol_between.iloc[4],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"circle\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 7\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_cort,\n",
    "        y=vol_between.iloc[5],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"circle\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 7\",\n",
    "    ),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_xaxes(title=\"Regions\", gridwidth=1, griddash=\"dot\")\n",
    "fig.update_yaxes(title=\"Volume<br> (mm<sup>3</sup>)\")\n",
    "fig.update_layout(legend_title_text=\"Legend\")\n",
    "\n",
    "# fig.write_image(\"plot_vol_both.png\", width=1920, height=1080)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0b4ee8",
   "metadata": {},
   "source": [
    "<img src=\"images/plot_vol_bil.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed5412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot volume rh\n",
    "\n",
    "x = diff_table_vol_rh\n",
    "x[\"version\"].replace(\"FS76\", \"FS 7 vs 6\", inplace=True)\n",
    "x[\"version\"].replace(\"FS75\", \"FS 7 vs 5\", inplace=True)\n",
    "x[\"version\"].replace(\"FS65\", \"FS 6 vs 5\", inplace=True)\n",
    "x = x.drop(columns=[\"hemi\"])\n",
    "\n",
    "fig = px.box(\n",
    "    data_frame=x,\n",
    "    color=\"version\",\n",
    "    orientation=\"h\",\n",
    ")\n",
    "\n",
    "for data in fig.data:\n",
    "    data.legendgroup = \"group1\"\n",
    "    data.legendgrouptitle = {\"text\": \"Between-version\"}\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_cort,\n",
    "        x=vol_between.iloc[1],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"x\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 5\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_cort,\n",
    "        x=vol_between.iloc[3],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"triangle-up\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 6\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_cort,\n",
    "        x=vol_between.iloc[5],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"circle\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 7\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_yaxes(title=\"Regions (right hemisphere)\", gridwidth=1, griddash=\"dot\")\n",
    "fig.update_xaxes(title=\"Volume<br> (mm<sup>3</sup>)\")\n",
    "fig.update_layout(legend_title_text=\"\", font_size=20)\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.05,\n",
    "        xanchor=\"left\",\n",
    "        x=0,\n",
    "        font_size=20,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    legend2=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.03,\n",
    "        xanchor=\"left\",\n",
    "        x=0,\n",
    "        font_size=20,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# fig.write_image(\"plot_vol_rh_large.png\", width=1080, height=2400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7018d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot volume lh\n",
    "\n",
    "x = diff_table_vol_lh\n",
    "x[\"version\"].replace(\"FS76\", \"FS 7 vs 6\", inplace=True)\n",
    "x[\"version\"].replace(\"FS75\", \"FS 7 vs 5\", inplace=True)\n",
    "x[\"version\"].replace(\"FS65\", \"FS 6 vs 5\", inplace=True)\n",
    "x = x.drop(columns=[\"hemi\"])\n",
    "\n",
    "fig = px.box(\n",
    "    data_frame=x,\n",
    "    color=\"version\",\n",
    "    orientation=\"h\",\n",
    ")\n",
    "\n",
    "for data in fig.data:\n",
    "    data.legendgroup = \"group1\"\n",
    "    data.legendgrouptitle = {\"text\": \"Between-version\"}\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_cort,\n",
    "        x=vol_between.iloc[0],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"x\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 5\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_cort,\n",
    "        x=vol_between.iloc[2],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"triangle-up\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 6\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_cort,\n",
    "        x=vol_between.iloc[4],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"circle\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 7\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_yaxes(title=\"Regions (left hemisphere)\", gridwidth=1, griddash=\"dot\")\n",
    "fig.update_xaxes(title=\"Volume<br> (mm<sup>3</sup>)\")\n",
    "fig.update_layout(legend_title_text=\"\", font_size=20)\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.05,\n",
    "        xanchor=\"left\",\n",
    "        x=0,\n",
    "        font_size=20,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    legend2=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.03,\n",
    "        xanchor=\"left\",\n",
    "        x=0,\n",
    "        font_size=20,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")\n",
    "# fig.write_image(\"plot_vol_lh_large.png\", width=1080, height=2400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6317c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot surface area\n",
    "\n",
    "x = diff_table_surf_all\n",
    "x[\"version\"].replace(\"FS76\", \"FS 7 vs 6\", inplace=True)\n",
    "x[\"version\"].replace(\"FS75\", \"FS 7 vs 5\", inplace=True)\n",
    "x[\"version\"].replace(\"FS65\", \"FS 6 vs 5\", inplace=True)\n",
    "\n",
    "\n",
    "fig = px.box(\n",
    "    x,\n",
    "    y=y_cort,\n",
    "    color=\"version\",\n",
    "    facet_row=\"hemi\",\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_cort,\n",
    "        y=surf_between.iloc[0],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"x\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 5\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_cort,\n",
    "        y=surf_between.iloc[1],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"x\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 5\",\n",
    "    ),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_cort,\n",
    "        y=surf_between.iloc[2],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"triangle-up\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 6\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_cort,\n",
    "        y=surf_between.iloc[3],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"triangle-up\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 6\",\n",
    "    ),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_cort,\n",
    "        y=surf_between.iloc[4],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"circle\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 7\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_cort,\n",
    "        y=surf_between.iloc[5],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"circle\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 7\",\n",
    "    ),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_xaxes(title=\"Regions\", gridwidth=1, griddash=\"dot\")\n",
    "fig.update_yaxes(title=\"Surface area<br> (mm<sup>2</sup>)\")\n",
    "fig.update_layout(legend_title_text=\"Legend\")\n",
    "# fig.write_image(\"plot_surf_both.png\", width=1920, height=1080)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ad0d1d",
   "metadata": {},
   "source": [
    "<img src=\"images/plot_surf_bil.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18212347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot surface area rh\n",
    "\n",
    "x = diff_table_surf_rh\n",
    "x[\"version\"].replace(\"FS76\", \"FS 7 vs 6\", inplace=True)\n",
    "x[\"version\"].replace(\"FS75\", \"FS 7 vs 5\", inplace=True)\n",
    "x[\"version\"].replace(\"FS65\", \"FS 6 vs 5\", inplace=True)\n",
    "x = x.drop(columns=[\"hemi\"])\n",
    "\n",
    "fig = px.box(\n",
    "    data_frame=x,\n",
    "    color=\"version\",\n",
    "    orientation=\"h\",\n",
    ")\n",
    "\n",
    "for data in fig.data:\n",
    "    data.legendgroup = \"group1\"\n",
    "    data.legendgrouptitle = {\"text\": \"Between-version\"}\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_cort,\n",
    "        x=surf_between.iloc[1],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"x\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 5\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_cort,\n",
    "        x=surf_between.iloc[3],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"x\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 6\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_cort,\n",
    "        x=surf_between.iloc[5],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"triangle-up\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 7\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_yaxes(title=\"Regions (right hemisphere)\", gridwidth=1, griddash=\"dot\")\n",
    "fig.update_xaxes(title=\"Surface area<br> (mm<sup>2</sup>)\")\n",
    "fig.update_layout(legend_title_text=\"\", font_size=20)\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.05,\n",
    "        xanchor=\"left\",\n",
    "        x=0,\n",
    "        font_size=20,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    legend2=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.03,\n",
    "        xanchor=\"left\",\n",
    "        x=0,\n",
    "        font_size=20,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")\n",
    "# fig.write_image(\"plot_surf_rh_large.png\", width=1080, height=2400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab84072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot surface area lh\n",
    "\n",
    "x = diff_table_surf_lh\n",
    "x[\"version\"].replace(\"FS76\", \"FS 7 vs 6\", inplace=True)\n",
    "x[\"version\"].replace(\"FS75\", \"FS 7 vs 5\", inplace=True)\n",
    "x[\"version\"].replace(\"FS65\", \"FS 6 vs 5\", inplace=True)\n",
    "x = x.drop(columns=[\"hemi\"])\n",
    "\n",
    "fig = px.box(\n",
    "    data_frame=x,\n",
    "    color=\"version\",\n",
    "    orientation=\"h\",\n",
    ")\n",
    "\n",
    "for data in fig.data:\n",
    "    data.legendgroup = \"group1\"\n",
    "    data.legendgrouptitle = {\"text\": \"Between-version\"}\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_cort,\n",
    "        x=surf_between.iloc[0],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"x\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 5\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_cort,\n",
    "        x=surf_between.iloc[2],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"x\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 6\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_cort,\n",
    "        x=surf_between.iloc[4],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"triangle-up\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 7\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_yaxes(title=\"Regions (left hemisphere)\", gridwidth=1, griddash=\"dot\")\n",
    "fig.update_xaxes(title=\"Surface area<br> (mm<sup>2</sup>)\")\n",
    "fig.update_layout(legend_title_text=\"\", font_size=20)\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.05,\n",
    "        xanchor=\"left\",\n",
    "        x=0,\n",
    "        font_size=20,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    legend2=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.03,\n",
    "        xanchor=\"left\",\n",
    "        x=0,\n",
    "        font_size=20,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")\n",
    "# fig.write_image(\"plot_surf_lh_large.png\", width=1080, height=2400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6333e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cortical thickness\n",
    "\n",
    "\n",
    "x = diff_table_ct_all\n",
    "x[\"version\"].replace(\"FS76\", \"FS 7 vs 6\", inplace=True)\n",
    "x[\"version\"].replace(\"FS75\", \"FS 7 vs 5\", inplace=True)\n",
    "x[\"version\"].replace(\"FS65\", \"FS 6 vs 5\", inplace=True)\n",
    "\n",
    "\n",
    "fig = px.box(\n",
    "    x,\n",
    "    y=y_cort,\n",
    "    color=\"version\",\n",
    "    facet_row=\"hemi\",\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_cort,\n",
    "        y=ct_between.iloc[0],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"x\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 5\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_cort,\n",
    "        y=ct_between.iloc[1],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"x\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 5\",\n",
    "    ),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_cort,\n",
    "        y=ct_between.iloc[2],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"triangle-up\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 6\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_cort,\n",
    "        y=ct_between.iloc[3],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"triangle-up\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 6\",\n",
    "    ),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_cort,\n",
    "        y=ct_between.iloc[4],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"circle\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 7\",\n",
    "    ),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=y_cort,\n",
    "        y=ct_between.iloc[5],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"circle\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 7\",\n",
    "    ),\n",
    "    row=2,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_xaxes(title=\"Regions\", gridwidth=1, griddash=\"dot\")\n",
    "fig.update_yaxes(title=\"Thickness<br> (mm)\")\n",
    "fig.update_layout(legend_title_text=\"Legend\")\n",
    "# fig.write_image(\"plot_ct_both.png\", width=1920, height=1080)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943d5b4b",
   "metadata": {},
   "source": [
    "<img src=\"images/plot_ct_bil.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb8811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cortical thickness rh\n",
    "\n",
    "\n",
    "x = diff_table_ct_rh\n",
    "x[\"version\"].replace(\"FS76\", \"FS 7 vs 6\", inplace=True)\n",
    "x[\"version\"].replace(\"FS75\", \"FS 7 vs 5\", inplace=True)\n",
    "x[\"version\"].replace(\"FS65\", \"FS 6 vs 5\", inplace=True)\n",
    "x = x.drop(columns=[\"hemi\"])\n",
    "\n",
    "fig = px.box(\n",
    "    data_frame=x,\n",
    "    color=\"version\",\n",
    "    orientation=\"h\",\n",
    ")\n",
    "\n",
    "for data in fig.data:\n",
    "    data.legendgroup = \"group1\"\n",
    "    data.legendgrouptitle = {\"text\": \"Between-version\"}\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_cort,\n",
    "        x=ct_between.iloc[1],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"x\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 5\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_cort,\n",
    "        x=ct_between.iloc[3],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"x\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 6\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_cort,\n",
    "        x=ct_between.iloc[5],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"triangle-up\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 7\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_yaxes(title=\"Regions (right hemisphere)\", gridwidth=1, griddash=\"dot\")\n",
    "fig.update_xaxes(title=\"Thickness<br> (mm)\")\n",
    "fig.update_layout(legend_title_text=\"\", font_size=20)\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.05,\n",
    "        xanchor=\"left\",\n",
    "        x=0,\n",
    "        font_size=20,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    legend2=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.03,\n",
    "        xanchor=\"left\",\n",
    "        x=0,\n",
    "        font_size=20,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")\n",
    "# fig.write_image(\"plot_ct_rh_large.png\", width=1080, height=2400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94455944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cortical thickness lh\n",
    "\n",
    "\n",
    "x = diff_table_ct_lh\n",
    "x[\"version\"].replace(\"FS76\", \"FS 7 vs 6\", inplace=True)\n",
    "x[\"version\"].replace(\"FS75\", \"FS 7 vs 5\", inplace=True)\n",
    "x[\"version\"].replace(\"FS65\", \"FS 6 vs 5\", inplace=True)\n",
    "x = x.drop(columns=[\"hemi\"])\n",
    "\n",
    "fig = px.box(\n",
    "    data_frame=x,\n",
    "    color=\"version\",\n",
    "    orientation=\"h\",\n",
    ")\n",
    "\n",
    "for data in fig.data:\n",
    "    data.legendgroup = \"group1\"\n",
    "    data.legendgrouptitle = {\"text\": \"Between-version\"}\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_cort,\n",
    "        x=ct_between.iloc[0],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"x\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 5\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_cort,\n",
    "        x=ct_between.iloc[2],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"x\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 6\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=y_cort,\n",
    "        x=ct_between.iloc[4],\n",
    "        mode=\"markers\",\n",
    "        marker_symbol=\"triangle-up\",\n",
    "        marker_size=10,\n",
    "        marker_color=\"black\",\n",
    "        name=\"FS 7\",\n",
    "        legendgroup=\"group2\",\n",
    "        legendgrouptitle_text=\"Between-subject\",\n",
    "        legend=\"legend2\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_yaxes(title=\"Regions (left hemisphere)\", gridwidth=1, griddash=\"dot\")\n",
    "fig.update_xaxes(title=\"Thickness<br> (mm)\")\n",
    "fig.update_layout(legend_title_text=\"\", font_size=20)\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.05,\n",
    "        xanchor=\"left\",\n",
    "        x=0,\n",
    "        font_size=20,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    legend2=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=1.03,\n",
    "        xanchor=\"left\",\n",
    "        x=0,\n",
    "        font_size=20,\n",
    "        traceorder=\"normal\",\n",
    "    )\n",
    ")\n",
    "# fig.write_image(\"plot_ct_lh_large.png\", width=1080, height=2400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4ecd8e",
   "metadata": {},
   "source": [
    "# Results - clinical whole-brain\n",
    "\n",
    "## FS 5 - whole-brain results\n",
    "\n",
    "## Group analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2c6a8e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group differences\n",
    "\n",
    "result_group = open(\"result_group_FS5.txt\", \"w\")\n",
    "\n",
    "# print(\"Group analysis\\n\")\n",
    "for pair in [\"HC_PDnonMCI\"]:\n",
    "    # print(\"** Significant group differences between {pair} **\\n\".format(pair=pair))\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        for time in [\"base\", \"long\"]:\n",
    "            # print(\"Hemisphere {hemi}\\n\".format(hemi=hemi))\n",
    "            file = open(\n",
    "                \"stats/results/FS5/results_group_{time}_{pair}_{hemi}/con_group_{pair}_{time}/cache.th13.abs.sig.cluster.summary\".format(\n",
    "                    time=time, hemi=hemi, pair=pair\n",
    "                ),\n",
    "                \"r\",\n",
    "            )\n",
    "            always_print = False\n",
    "            lines = file.readlines()\n",
    "            result_group.write(time + \"\\n\")\n",
    "            result_group.write(pair + \"_\" + hemi + \"\\n\")\n",
    "            for line in lines:\n",
    "                if always_print or \"ClusterNo\" in line:\n",
    "                    # print(line)\n",
    "                    result_group.write(line)\n",
    "                    always_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4d858513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClusterNo</th>\n",
       "      <th>Max</th>\n",
       "      <th>VtxMax</th>\n",
       "      <th>Size(mm^2)</th>\n",
       "      <th>MNIX</th>\n",
       "      <th>MNIY</th>\n",
       "      <th>MNIZ</th>\n",
       "      <th>CWP</th>\n",
       "      <th>CWPLow</th>\n",
       "      <th>CWPHi</th>\n",
       "      <th>NVtxs</th>\n",
       "      <th>WghtVtx</th>\n",
       "      <th>Annot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HC_PDnonMCI_lh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.450</td>\n",
       "      <td>80915</td>\n",
       "      <td>901.98</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-17.8</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.04938</td>\n",
       "      <td>0.04547</td>\n",
       "      <td>0.05327</td>\n",
       "      <td>1947</td>\n",
       "      <td>postcentral</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>long</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HC_PDnonMCI_lh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.815</td>\n",
       "      <td>97664</td>\n",
       "      <td>682.70</td>\n",
       "      <td>-41.3</td>\n",
       "      <td>-33.6</td>\n",
       "      <td>-21.9</td>\n",
       "      <td>0.00659</td>\n",
       "      <td>0.00519</td>\n",
       "      <td>0.00798</td>\n",
       "      <td>1214</td>\n",
       "      <td>fusiform</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>-3.009</td>\n",
       "      <td>142353</td>\n",
       "      <td>553.63</td>\n",
       "      <td>-41.7</td>\n",
       "      <td>-78.3</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>0.02346</td>\n",
       "      <td>0.02938</td>\n",
       "      <td>1039</td>\n",
       "      <td>inferiorparietal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>-2.805</td>\n",
       "      <td>22352</td>\n",
       "      <td>827.42</td>\n",
       "      <td>-50.6</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-31.2</td>\n",
       "      <td>0.00120</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.00180</td>\n",
       "      <td>1328</td>\n",
       "      <td>middletemporal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>-2.772</td>\n",
       "      <td>74742</td>\n",
       "      <td>530.57</td>\n",
       "      <td>-19.4</td>\n",
       "      <td>-62.1</td>\n",
       "      <td>24.1</td>\n",
       "      <td>0.03332</td>\n",
       "      <td>0.03017</td>\n",
       "      <td>0.03666</td>\n",
       "      <td>1048</td>\n",
       "      <td>precuneus</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>-2.610</td>\n",
       "      <td>86018</td>\n",
       "      <td>522.52</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-33.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.03764</td>\n",
       "      <td>0.03430</td>\n",
       "      <td>0.04117</td>\n",
       "      <td>1142</td>\n",
       "      <td>bankssts</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>base</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HC_PDnonMCI_rh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>long</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HC_PDnonMCI_rh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.948</td>\n",
       "      <td>130993</td>\n",
       "      <td>894.78</td>\n",
       "      <td>26.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>47.2</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>2100</td>\n",
       "      <td>caudalmiddlefrontal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>-2.684</td>\n",
       "      <td>52375</td>\n",
       "      <td>1077.85</td>\n",
       "      <td>57.5</td>\n",
       "      <td>-26.2</td>\n",
       "      <td>38.6</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>2697</td>\n",
       "      <td>supramarginal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ClusterNo     Max  VtxMax Size(mm^2)   MNIX   MNIY   MNIZ      CWP  \\\n",
       "0             base                                                            \n",
       "1   HC_PDnonMCI_lh                                                            \n",
       "2                1  -3.450   80915     901.98  -50.0  -17.8   36.8  0.04938   \n",
       "3             long                                                            \n",
       "4   HC_PDnonMCI_lh                                                            \n",
       "5                1  -3.815   97664     682.70  -41.3  -33.6  -21.9  0.00659   \n",
       "6                2  -3.009  142353     553.63  -41.7  -78.3   21.1  0.02642   \n",
       "7                3  -2.805   22352     827.42  -50.6   -3.8  -31.2  0.00120   \n",
       "8                4  -2.772   74742     530.57  -19.4  -62.1   24.1  0.03332   \n",
       "9                5  -2.610   86018     522.52  -63.0  -33.4    4.3  0.03764   \n",
       "10            base                                                            \n",
       "11  HC_PDnonMCI_rh                                                            \n",
       "12            long                                                            \n",
       "13  HC_PDnonMCI_rh                                                            \n",
       "14               1  -3.948  130993     894.78   26.3    5.3   47.2  0.00020   \n",
       "15               2  -2.684   52375    1077.85   57.5  -26.2   38.6  0.00020   \n",
       "\n",
       "     CWPLow    CWPHi NVtxs              WghtVtx Annot  \n",
       "0                                                      \n",
       "1                                                      \n",
       "2   0.04547  0.05327  1947          postcentral        \n",
       "3                                                      \n",
       "4                                                      \n",
       "5   0.00519  0.00798  1214             fusiform        \n",
       "6   0.02346  0.02938  1039     inferiorparietal        \n",
       "7   0.00060  0.00180  1328       middletemporal        \n",
       "8   0.03017  0.03666  1048            precuneus        \n",
       "9   0.03430  0.04117  1142             bankssts        \n",
       "10                                                     \n",
       "11                                                     \n",
       "12                                                     \n",
       "13                                                     \n",
       "14  0.00000  0.00040  2100  caudalmiddlefrontal        \n",
       "15  0.00000  0.00040  2697        supramarginal        "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_group = pd.read_csv(\n",
    "    \"result_group_FS5.txt\",\n",
    "    sep=\"\\\\s+\",\n",
    "    keep_default_na=False,\n",
    "    na_values=\" \",\n",
    "    comment=\"#\",\n",
    "    names=[\n",
    "        \"ClusterNo\",\n",
    "        \"Max\",\n",
    "        \"VtxMax\",\n",
    "        \"Size(mm^2)\",\n",
    "        \"MNIX\",\n",
    "        \"MNIY\",\n",
    "        \"MNIZ\",\n",
    "        \"CWP\",\n",
    "        \"CWPLow\",\n",
    "        \"CWPHi\",\n",
    "        \"NVtxs\",\n",
    "        \"WghtVtx\",\n",
    "        \"Annot\",\n",
    "    ],\n",
    ")\n",
    "results_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e04a9e",
   "metadata": {},
   "source": [
    "## Correlational analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "670f1c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group differences\n",
    "\n",
    "result_group = open(\"result_corr_FS5.txt\", \"w\")\n",
    "\n",
    "# print(\"Group analysis\\n\")\n",
    "for pair in [\"PDnonMCI\"]:\n",
    "    # print(\"** Significant group differences between {pair} **\\n\".format(pair=pair))\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        for time in [\"base\", \"long\"]:\n",
    "            # print(\"Hemisphere {hemi}\\n\".format(hemi=hemi))\n",
    "            file = open(\n",
    "                \"stats/results/FS5/results_corr_{pair}_{hemi}_{time}/con_corr_UPDRS_{time}/cache.th13.abs.sig.cluster.summary\".format(\n",
    "                    time=time, hemi=hemi, pair=pair\n",
    "                ),\n",
    "                \"r\",\n",
    "            )\n",
    "            always_print = False\n",
    "            lines = file.readlines()\n",
    "            result_group.write(time + \"\\n\")\n",
    "            result_group.write(pair + \"_\" + hemi + \"\\n\")\n",
    "            for line in lines:\n",
    "                if always_print or \"ClusterNo\" in line:\n",
    "                    # print(line)\n",
    "                    result_group.write(line)\n",
    "                    always_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "55364032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClusterNo</th>\n",
       "      <th>Max</th>\n",
       "      <th>VtxMax</th>\n",
       "      <th>Size(mm^2)</th>\n",
       "      <th>MNIX</th>\n",
       "      <th>MNIY</th>\n",
       "      <th>MNIZ</th>\n",
       "      <th>CWP</th>\n",
       "      <th>CWPLow</th>\n",
       "      <th>CWPHi</th>\n",
       "      <th>NVtxs</th>\n",
       "      <th>WghtVtx</th>\n",
       "      <th>Annot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PDnonMCI_lh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-5.065</td>\n",
       "      <td>29703</td>\n",
       "      <td>1867.74</td>\n",
       "      <td>-42.9</td>\n",
       "      <td>-12.9</td>\n",
       "      <td>42.1</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>4529</td>\n",
       "      <td>precentral</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-3.924</td>\n",
       "      <td>151042</td>\n",
       "      <td>2290.73</td>\n",
       "      <td>-35.3</td>\n",
       "      <td>-34.5</td>\n",
       "      <td>60.8</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>5527</td>\n",
       "      <td>postcentral</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>-3.341</td>\n",
       "      <td>87046</td>\n",
       "      <td>1562.93</td>\n",
       "      <td>-29.3</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>3134</td>\n",
       "      <td>inferiorparietal</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>long</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PDnonMCI_lh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>base</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PDnonMCI_rh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>-5.134</td>\n",
       "      <td>131252</td>\n",
       "      <td>2054.26</td>\n",
       "      <td>23.5</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>50.3</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>4768</td>\n",
       "      <td>precentral</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>-2.968</td>\n",
       "      <td>132539</td>\n",
       "      <td>949.84</td>\n",
       "      <td>30.4</td>\n",
       "      <td>-85.8</td>\n",
       "      <td>-12.9</td>\n",
       "      <td>0.04703</td>\n",
       "      <td>0.04332</td>\n",
       "      <td>0.05093</td>\n",
       "      <td>1211</td>\n",
       "      <td>lateraloccipital</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>long</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PDnonMCI_rh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ClusterNo     Max  VtxMax Size(mm^2)   MNIX   MNIY   MNIZ      CWP  \\\n",
       "0          base                                                            \n",
       "1   PDnonMCI_lh                                                            \n",
       "2             1  -5.065   29703    1867.74  -42.9  -12.9   42.1  0.00020   \n",
       "3             2  -3.924  151042    2290.73  -35.3  -34.5   60.8  0.00020   \n",
       "4             3  -3.341   87046    1562.93  -29.3  -66.0   29.3  0.00020   \n",
       "5          long                                                            \n",
       "6   PDnonMCI_lh                                                            \n",
       "7          base                                                            \n",
       "8   PDnonMCI_rh                                                            \n",
       "9             1  -5.134  131252    2054.26   23.5  -26.0   50.3  0.00020   \n",
       "10            2  -2.968  132539     949.84   30.4  -85.8  -12.9  0.04703   \n",
       "11         long                                                            \n",
       "12  PDnonMCI_rh                                                            \n",
       "\n",
       "     CWPLow    CWPHi NVtxs           WghtVtx Annot  \n",
       "0                                                   \n",
       "1                                                   \n",
       "2   0.00000  0.00040  4529        precentral        \n",
       "3   0.00000  0.00040  5527       postcentral        \n",
       "4   0.00000  0.00040  3134  inferiorparietal        \n",
       "5                                                   \n",
       "6                                                   \n",
       "7                                                   \n",
       "8                                                   \n",
       "9   0.00000  0.00040  4768        precentral        \n",
       "10  0.04332  0.05093  1211  lateraloccipital        \n",
       "11                                                  \n",
       "12                                                  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_group = pd.read_csv(\n",
    "    \"result_corr_FS5.txt\",\n",
    "    sep=\"\\\\s+\",\n",
    "    keep_default_na=False,\n",
    "    na_values=\" \",\n",
    "    comment=\"#\",\n",
    "    names=[\n",
    "        \"ClusterNo\",\n",
    "        \"Max\",\n",
    "        \"VtxMax\",\n",
    "        \"Size(mm^2)\",\n",
    "        \"MNIX\",\n",
    "        \"MNIY\",\n",
    "        \"MNIZ\",\n",
    "        \"CWP\",\n",
    "        \"CWPLow\",\n",
    "        \"CWPHi\",\n",
    "        \"NVtxs\",\n",
    "        \"WghtVtx\",\n",
    "        \"Annot\",\n",
    "    ],\n",
    ")\n",
    "results_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c570d998",
   "metadata": {},
   "source": [
    "## FS 6 - whole-brain results\n",
    "\n",
    "## Group analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "765c3357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group differences\n",
    "\n",
    "result_group = open(\"result_group_FS6.txt\", \"w\")\n",
    "\n",
    "# print(\"Group analysis\\n\")\n",
    "for pair in [\"HC_PDnonMCI\"]:\n",
    "    # print(\"** Significant group differences between {pair} **\\n\".format(pair=pair))\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        for time in [\"base\", \"long\"]:\n",
    "            # print(\"Hemisphere {hemi}\\n\".format(hemi=hemi))\n",
    "            file = open(\n",
    "                \"stats/results/FS6/results_group_{time}_{pair}_{hemi}/con_group_{pair}_{time}/cache.th13.abs.sig.cluster.summary\".format(\n",
    "                    time=time, hemi=hemi, pair=pair\n",
    "                ),\n",
    "                \"r\",\n",
    "            )\n",
    "            always_print = False\n",
    "            lines = file.readlines()\n",
    "            result_group.write(time + \"\\n\")\n",
    "            result_group.write(pair + \"_\" + hemi + \"\\n\")\n",
    "            for line in lines:\n",
    "                if always_print or \"ClusterNo\" in line:\n",
    "                    # print(line)\n",
    "                    result_group.write(line)\n",
    "                    always_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cbed0fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClusterNo</th>\n",
       "      <th>Max</th>\n",
       "      <th>VtxMax</th>\n",
       "      <th>Size(mm^2)</th>\n",
       "      <th>MNIX</th>\n",
       "      <th>MNIY</th>\n",
       "      <th>MNIZ</th>\n",
       "      <th>CWP</th>\n",
       "      <th>CWPLow</th>\n",
       "      <th>CWPHi</th>\n",
       "      <th>NVtxs</th>\n",
       "      <th>WghtVtx</th>\n",
       "      <th>Annot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HC_PDnonMCI_lh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>long</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HC_PDnonMCI_lh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.496</td>\n",
       "      <td>150034</td>\n",
       "      <td>794.25</td>\n",
       "      <td>-51.1</td>\n",
       "      <td>-40.4</td>\n",
       "      <td>45.2</td>\n",
       "      <td>0.00080</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>0.00140</td>\n",
       "      <td>1861</td>\n",
       "      <td>-3279.51</td>\n",
       "      <td>supramarginal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>-2.760</td>\n",
       "      <td>156489</td>\n",
       "      <td>688.44</td>\n",
       "      <td>-60.7</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.00400</td>\n",
       "      <td>0.00280</td>\n",
       "      <td>0.00519</td>\n",
       "      <td>1499</td>\n",
       "      <td>-2568.41</td>\n",
       "      <td>superiortemporal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>base</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HC_PDnonMCI_rh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>long</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HC_PDnonMCI_rh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ClusterNo     Max  VtxMax Size(mm^2)   MNIX   MNIY  MNIZ      CWP  \\\n",
       "0            base                                                           \n",
       "1  HC_PDnonMCI_lh                                                           \n",
       "2            long                                                           \n",
       "3  HC_PDnonMCI_lh                                                           \n",
       "4               1  -2.496  150034     794.25  -51.1  -40.4  45.2  0.00080   \n",
       "5               2  -2.760  156489     688.44  -60.7  -31.0   1.1  0.00400   \n",
       "6            base                                                           \n",
       "7  HC_PDnonMCI_rh                                                           \n",
       "8            long                                                           \n",
       "9  HC_PDnonMCI_rh                                                           \n",
       "\n",
       "    CWPLow    CWPHi NVtxs   WghtVtx             Annot  \n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  0.00040  0.00140  1861  -3279.51     supramarginal  \n",
       "5  0.00280  0.00519  1499  -2568.41  superiortemporal  \n",
       "6                                                      \n",
       "7                                                      \n",
       "8                                                      \n",
       "9                                                      "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_group = pd.read_csv(\n",
    "    \"result_group_FS6.txt\",\n",
    "    sep=\"\\\\s+\",\n",
    "    keep_default_na=False,\n",
    "    na_values=\" \",\n",
    "    comment=\"#\",\n",
    "    names=[\n",
    "        \"ClusterNo\",\n",
    "        \"Max\",\n",
    "        \"VtxMax\",\n",
    "        \"Size(mm^2)\",\n",
    "        \"MNIX\",\n",
    "        \"MNIY\",\n",
    "        \"MNIZ\",\n",
    "        \"CWP\",\n",
    "        \"CWPLow\",\n",
    "        \"CWPHi\",\n",
    "        \"NVtxs\",\n",
    "        \"WghtVtx\",\n",
    "        \"Annot\",\n",
    "    ],\n",
    ")\n",
    "results_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb1715",
   "metadata": {},
   "source": [
    "## Correlational analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6d1ff397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group differences\n",
    "\n",
    "result_group = open(\"result_corr_FS6.txt\", \"w\")\n",
    "\n",
    "# print(\"Group analysis\\n\")\n",
    "for pair in [\"PDnonMCI\"]:\n",
    "    # print(\"** Significant group differences between {pair} **\\n\".format(pair=pair))\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        for time in [\"base\", \"long\"]:\n",
    "            # print(\"Hemisphere {hemi}\\n\".format(hemi=hemi))\n",
    "            file = open(\n",
    "                \"stats/results/FS6/results_corr_{time}_{pair}_{hemi}/con_corr_UPDRS_{time}/cache.th13.abs.sig.cluster.summary\".format(\n",
    "                    time=time, hemi=hemi, pair=pair\n",
    "                ),\n",
    "                \"r\",\n",
    "            )\n",
    "            always_print = False\n",
    "            lines = file.readlines()\n",
    "            result_group.write(time + \"\\n\")\n",
    "            result_group.write(pair + \"_\" + hemi + \"\\n\")\n",
    "            for line in lines:\n",
    "                if always_print or \"ClusterNo\" in line:\n",
    "                    # print(line)\n",
    "                    result_group.write(line)\n",
    "                    always_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ee8246d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClusterNo</th>\n",
       "      <th>Max</th>\n",
       "      <th>VtxMax</th>\n",
       "      <th>Size(mm^2)</th>\n",
       "      <th>MNIX</th>\n",
       "      <th>MNIY</th>\n",
       "      <th>MNIZ</th>\n",
       "      <th>CWP</th>\n",
       "      <th>CWPLow</th>\n",
       "      <th>CWPHi</th>\n",
       "      <th>NVtxs</th>\n",
       "      <th>WghtVtx</th>\n",
       "      <th>Annot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PDnonMCI_lh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.411</td>\n",
       "      <td>128177</td>\n",
       "      <td>1364.72</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>-93.4</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>0.00639</td>\n",
       "      <td>0.00499</td>\n",
       "      <td>0.00778</td>\n",
       "      <td>1673</td>\n",
       "      <td>-3148.12</td>\n",
       "      <td>lingual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-4.430</td>\n",
       "      <td>41366</td>\n",
       "      <td>1328.38</td>\n",
       "      <td>-35.4</td>\n",
       "      <td>-33.9</td>\n",
       "      <td>63.9</td>\n",
       "      <td>0.00798</td>\n",
       "      <td>0.00639</td>\n",
       "      <td>0.00958</td>\n",
       "      <td>3207</td>\n",
       "      <td>-7188.52</td>\n",
       "      <td>postcentral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>long</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PDnonMCI_lh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>base</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PDnonMCI_rh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>-4.361</td>\n",
       "      <td>69960</td>\n",
       "      <td>2315.16</td>\n",
       "      <td>15.2</td>\n",
       "      <td>-98.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>3214</td>\n",
       "      <td>-6845.89</td>\n",
       "      <td>lateraloccipital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>long</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PDnonMCI_rh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.139</td>\n",
       "      <td>46539</td>\n",
       "      <td>572.21</td>\n",
       "      <td>60.4</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>-24.6</td>\n",
       "      <td>0.02307</td>\n",
       "      <td>0.02030</td>\n",
       "      <td>0.02583</td>\n",
       "      <td>991</td>\n",
       "      <td>-1763.55</td>\n",
       "      <td>middletemporal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ClusterNo     Max  VtxMax Size(mm^2)   MNIX   MNIY   MNIZ      CWP  \\\n",
       "0          base                                                            \n",
       "1   PDnonMCI_lh                                                            \n",
       "2             1  -3.411  128177    1364.72   -7.4  -93.4   -7.3  0.00639   \n",
       "3             2  -4.430   41366    1328.38  -35.4  -33.9   63.9  0.00798   \n",
       "4          long                                                            \n",
       "5   PDnonMCI_lh                                                            \n",
       "6          base                                                            \n",
       "7   PDnonMCI_rh                                                            \n",
       "8             1  -4.361   69960    2315.16   15.2  -98.6    1.8  0.00020   \n",
       "9          long                                                            \n",
       "10  PDnonMCI_rh                                                            \n",
       "11            1  -3.139   46539     572.21   60.4   -5.2  -24.6  0.02307   \n",
       "\n",
       "     CWPLow    CWPHi NVtxs   WghtVtx             Annot  \n",
       "0                                                       \n",
       "1                                                       \n",
       "2   0.00499  0.00778  1673  -3148.12           lingual  \n",
       "3   0.00639  0.00958  3207  -7188.52       postcentral  \n",
       "4                                                       \n",
       "5                                                       \n",
       "6                                                       \n",
       "7                                                       \n",
       "8   0.00000  0.00040  3214  -6845.89  lateraloccipital  \n",
       "9                                                       \n",
       "10                                                      \n",
       "11  0.02030  0.02583   991  -1763.55    middletemporal  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_group = pd.read_csv(\n",
    "    \"result_corr_FS6.txt\",\n",
    "    sep=\"\\\\s+\",\n",
    "    keep_default_na=False,\n",
    "    na_values=\" \",\n",
    "    comment=\"#\",\n",
    "    names=[\n",
    "        \"ClusterNo\",\n",
    "        \"Max\",\n",
    "        \"VtxMax\",\n",
    "        \"Size(mm^2)\",\n",
    "        \"MNIX\",\n",
    "        \"MNIY\",\n",
    "        \"MNIZ\",\n",
    "        \"CWP\",\n",
    "        \"CWPLow\",\n",
    "        \"CWPHi\",\n",
    "        \"NVtxs\",\n",
    "        \"WghtVtx\",\n",
    "        \"Annot\",\n",
    "    ],\n",
    ")\n",
    "results_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b3f273",
   "metadata": {},
   "source": [
    "## FS 7 - whole-brain results\n",
    "\n",
    "### Group analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "12d50036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group differences\n",
    "\n",
    "result_group = open(\"result_group_FS7.txt\", \"w\")\n",
    "\n",
    "# print(\"Group analysis\\n\")\n",
    "for pair in [\"HC_PDnonMCI\"]:\n",
    "    # print(\"** Significant group differences between {pair} **\\n\".format(pair=pair))\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        for time in [\"base\", \"long\"]:\n",
    "            # print(\"Hemisphere {hemi}\\n\".format(hemi=hemi))\n",
    "            file = open(\n",
    "                \"stats/results/FS7/results_group_{time}_{pair}_{hemi}/con_group_{pair}_{time}/cache.th13.abs.sig.cluster.summary\".format(\n",
    "                    time=time, hemi=hemi, pair=pair\n",
    "                ),\n",
    "                \"r\",\n",
    "            )\n",
    "            always_print = False\n",
    "            lines = file.readlines()\n",
    "            result_group.write(time + \"\\n\")\n",
    "            result_group.write(pair + \"_\" + hemi + \"\\n\")\n",
    "            for line in lines:\n",
    "                if always_print or \"ClusterNo\" in line:\n",
    "                    # print(line)\n",
    "                    result_group.write(line)\n",
    "                    always_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "566e4897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClusterNo</th>\n",
       "      <th>Max</th>\n",
       "      <th>VtxMax</th>\n",
       "      <th>Size(mm^2)</th>\n",
       "      <th>MNIX</th>\n",
       "      <th>MNIY</th>\n",
       "      <th>MNIZ</th>\n",
       "      <th>CWP</th>\n",
       "      <th>CWPLow</th>\n",
       "      <th>CWPHi</th>\n",
       "      <th>NVtxs</th>\n",
       "      <th>WghtVtx</th>\n",
       "      <th>Annot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HC_PDnonMCI_lh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>long</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HC_PDnonMCI_lh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.8970</td>\n",
       "      <td>60996</td>\n",
       "      <td>553.47</td>\n",
       "      <td>-46.7</td>\n",
       "      <td>-17.9</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>0.02721</td>\n",
       "      <td>0.02425</td>\n",
       "      <td>0.03017</td>\n",
       "      <td>1255</td>\n",
       "      <td>-2283.57</td>\n",
       "      <td>superiortemporal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>base</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HC_PDnonMCI_rh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>long</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HC_PDnonMCI_rh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ClusterNo      Max VtxMax Size(mm^2)   MNIX   MNIY  MNIZ      CWP  \\\n",
       "0            base                                                           \n",
       "1  HC_PDnonMCI_lh                                                           \n",
       "2            long                                                           \n",
       "3  HC_PDnonMCI_lh                                                           \n",
       "4               1  -2.8970  60996     553.47  -46.7  -17.9  -6.2  0.02721   \n",
       "5            base                                                           \n",
       "6  HC_PDnonMCI_rh                                                           \n",
       "7            long                                                           \n",
       "8  HC_PDnonMCI_rh                                                           \n",
       "\n",
       "    CWPLow    CWPHi NVtxs   WghtVtx             Annot  \n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  0.02425  0.03017  1255  -2283.57  superiortemporal  \n",
       "5                                                      \n",
       "6                                                      \n",
       "7                                                      \n",
       "8                                                      "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_group = pd.read_csv(\n",
    "    \"result_group_FS7.txt\",\n",
    "    sep=\"\\\\s+\",\n",
    "    keep_default_na=False,\n",
    "    na_values=\" \",\n",
    "    comment=\"#\",\n",
    "    names=[\n",
    "        \"ClusterNo\",\n",
    "        \"Max\",\n",
    "        \"VtxMax\",\n",
    "        \"Size(mm^2)\",\n",
    "        \"MNIX\",\n",
    "        \"MNIY\",\n",
    "        \"MNIZ\",\n",
    "        \"CWP\",\n",
    "        \"CWPLow\",\n",
    "        \"CWPHi\",\n",
    "        \"NVtxs\",\n",
    "        \"WghtVtx\",\n",
    "        \"Annot\",\n",
    "    ],\n",
    ")\n",
    "results_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547e1477",
   "metadata": {},
   "source": [
    "### Correlational analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8fed289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group differences\n",
    "\n",
    "result_group = open(\"result_corr_FS7.txt\", \"w\")\n",
    "\n",
    "# print(\"Group analysis\\n\")\n",
    "for pair in [\"PDnonMCI\"]:\n",
    "    # print(\"** Significant group differences between {pair} **\\n\".format(pair=pair))\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        for time in [\"base\", \"long\"]:\n",
    "            # print(\"Hemisphere {hemi}\\n\".format(hemi=hemi))\n",
    "            file = open(\n",
    "                \"stats/results/FS7/results_corr_{time}_{pair}_{hemi}/con_corr_UPDRS_{time}/cache.th13.abs.sig.cluster.summary\".format(\n",
    "                    time=time, hemi=hemi, pair=pair\n",
    "                ),\n",
    "                \"r\",\n",
    "            )\n",
    "            always_print = False\n",
    "            lines = file.readlines()\n",
    "            result_group.write(time + \"\\n\")\n",
    "            result_group.write(pair + \"_\" + hemi + \"\\n\")\n",
    "            for line in lines:\n",
    "                if always_print or \"ClusterNo\" in line:\n",
    "                    # print(line)\n",
    "                    result_group.write(line)\n",
    "                    always_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "677c0dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClusterNo</th>\n",
       "      <th>Max</th>\n",
       "      <th>VtxMax</th>\n",
       "      <th>Size(mm^2)</th>\n",
       "      <th>MNIX</th>\n",
       "      <th>MNIY</th>\n",
       "      <th>MNIZ</th>\n",
       "      <th>CWP</th>\n",
       "      <th>CWPLow</th>\n",
       "      <th>CWPHi</th>\n",
       "      <th>NVtxs</th>\n",
       "      <th>WghtVtx</th>\n",
       "      <th>Annot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PDnonMCI_lh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-3.0173</td>\n",
       "      <td>14043</td>\n",
       "      <td>1160.12</td>\n",
       "      <td>-46.9</td>\n",
       "      <td>-11.1</td>\n",
       "      <td>45.9</td>\n",
       "      <td>0.01077</td>\n",
       "      <td>0.00898</td>\n",
       "      <td>0.01256</td>\n",
       "      <td>2359</td>\n",
       "      <td>-4588.21</td>\n",
       "      <td>precentral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>long</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PDnonMCI_lh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>base</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PDnonMCI_rh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>long</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PDnonMCI_rh</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ClusterNo      Max VtxMax Size(mm^2)   MNIX   MNIY  MNIZ      CWP  \\\n",
       "0         base                                                           \n",
       "1  PDnonMCI_lh                                                           \n",
       "2            1  -3.0173  14043    1160.12  -46.9  -11.1  45.9  0.01077   \n",
       "3         long                                                           \n",
       "4  PDnonMCI_lh                                                           \n",
       "5         base                                                           \n",
       "6  PDnonMCI_rh                                                           \n",
       "7         long                                                           \n",
       "8  PDnonMCI_rh                                                           \n",
       "\n",
       "    CWPLow    CWPHi NVtxs   WghtVtx       Annot  \n",
       "0                                                \n",
       "1                                                \n",
       "2  0.00898  0.01256  2359  -4588.21  precentral  \n",
       "3                                                \n",
       "4                                                \n",
       "5                                                \n",
       "6                                                \n",
       "7                                                \n",
       "8                                                "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_group = pd.read_csv(\n",
    "    \"result_corr_FS7.txt\",\n",
    "    sep=\"\\\\s+\",\n",
    "    keep_default_na=False,\n",
    "    na_values=\" \",\n",
    "    comment=\"#\",\n",
    "    names=[\n",
    "        \"ClusterNo\",\n",
    "        \"Max\",\n",
    "        \"VtxMax\",\n",
    "        \"Size(mm^2)\",\n",
    "        \"MNIX\",\n",
    "        \"MNIY\",\n",
    "        \"MNIZ\",\n",
    "        \"CWP\",\n",
    "        \"CWPLow\",\n",
    "        \"CWPHi\",\n",
    "        \"NVtxs\",\n",
    "        \"WghtVtx\",\n",
    "        \"Annot\",\n",
    "    ],\n",
    ")\n",
    "results_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d791148",
   "metadata": {},
   "source": [
    "## Vertex-wise results\n",
    "\n",
    "<img src=\"images/brain_baseline_corr.png\"/>\n",
    "\n",
    "#### Vertex-wise correlation between UPDRS score and cortical thickness at baseline.\n",
    "<br>\n",
    "\n",
    "<img src=\"images/brain_long_corr.png\"/>\n",
    "\n",
    "#### Vertex-wise correlation between the rate of change in UPDRS and the rate of change in cortical thickness. Correlations in FreeSurfer 5 and 7 were not significant.\n",
    "<br>\n",
    "\n",
    "<img src=\"images/brain_baseline_group.png\"/>\n",
    "\n",
    "#### Group differences (HC vs PD-non-MCI) in cortical thickness at baseline. Differences in FreeSurfer 6 and 7 were not significant.\n",
    "<br>\n",
    "\n",
    "<img src=\"images/brain_long_group.png\"/>\n",
    "\n",
    "#### Group differences (HC vs PD-non-MCI) in the rate of change in cortical thickness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e37659",
   "metadata": {},
   "source": [
    "# QPN - replication sample\n",
    "\n",
    "Data in the QPN sample was preprocessed outside this notebook using the same preprocessing pipeline as the main sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7fc51c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "QPN = pd.read_csv(\"qpn/QPN_subjects.csv\")[[\"PATNO\", \"sex\", \"age\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dccd6beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57 woman and 103 men in the QPN sample (Mage = 64.693125; SDage =9.257742786106702)\n"
     ]
    }
   ],
   "source": [
    "sex_f = QPN[QPN[\"sex\"] == \"F\"][\"PATNO\"].nunique()\n",
    "sex_m = QPN[QPN[\"sex\"] == \"M\"][\"PATNO\"].nunique()\n",
    "age_m = QPN[\"age\"].mean()\n",
    "age_sd = QPN[\"age\"].std()\n",
    "\n",
    "print(\n",
    "    f\"There are {sex_f} woman and {sex_m} men in the QPN sample (Mage = {age_m}; SDage ={age_sd})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7663efed",
   "metadata": {},
   "source": [
    "## QC - preprocessed images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1360e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio as iio\n",
    "from pathlib import Path\n",
    "\n",
    "for ver in [\"FS5\", \"FS6\", \"FS7\"]:\n",
    "    for view in [\"axial\", \"sagittal\", \"coronal\"]:\n",
    "        images = list()\n",
    "        for file in Path(f\"qpn/segm/{ver}/{view}\").iterdir():\n",
    "            if not file.is_file():\n",
    "                continue\n",
    "\n",
    "            images.append(iio.imread(file))\n",
    "            iio.mimsave(f\"qpn/segm/{ver}/segm_{view}.gif\", images, duration=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e40e28",
   "metadata": {},
   "source": [
    "## FS5\n",
    "\n",
    "### FS 5 axial view\n",
    "![SegmentLocal](images/segm_qpn_FS5_axial.gif \"segment\")\n",
    "\n",
    "### FS 5 coronal view\n",
    "![SegmentLocal](images/segm_qpn_FS5_coronal.gif \"segment\")\n",
    "\n",
    "### FS 5 sagittal view\n",
    "![SegmentLocal](images/segm_qpn_FS5_sagittal.gif \"segment\")\n",
    "\n",
    "## FS6\n",
    "\n",
    "### FS 6 axial view\n",
    "![SegmentLocal](images/segm_qpn_FS6_axial.gif \"segment\")\n",
    "\n",
    "### FS 6 coronal view\n",
    "![SegmentLocal](images/segm_qpn_FS6_coronal.gif \"segment\")\n",
    "\n",
    "### FS 6 sagittal view\n",
    "![SegmentLocal](images/segm_qpn_FS6_sagittal.gif \"segment\")\n",
    "\n",
    "## FS7\n",
    "\n",
    "### FS 7 axial view\n",
    "![SegmentLocal](images/segm_qpn_FS7_axial.gif \"segment\")\n",
    "\n",
    "### FS 7 coronal view\n",
    "![SegmentLocal](images/segm_qpn_FS7_coronal.gif \"segment\")\n",
    "\n",
    "### FS 7 sagittal view\n",
    "![SegmentLocal](images/segm_qpn_FS7_sagittal.gif \"segment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2397ca9",
   "metadata": {},
   "source": [
    "## MRIQC - QPN sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "aed5b246",
   "metadata": {},
   "outputs": [],
   "source": [
    "qpn_qc = QPN\n",
    "\n",
    "metrics = [\n",
    "    \"cjv\",\n",
    "    \"cnr\",\n",
    "    \"fber\",\n",
    "    \"qi_1\",\n",
    "    \"qi_2\",\n",
    "    \"rpve_gm\",\n",
    "    \"snr_gm\",\n",
    "    \"snr_total\",\n",
    "    \"snrd_gm\",\n",
    "    \"snrd_total\",\n",
    "]\n",
    "\n",
    "for subj in qpn_qc[\"PATNO\"]:\n",
    "    for metric in metrics:\n",
    "        file = f\"mriqc/output_qpn/sub-{subj}/ses-01/anat/sub-{subj}_T1w.json\"\n",
    "\n",
    "        with open(file, \"r\") as fp:\n",
    "            lines = fp.readlines()\n",
    "            for line in lines:\n",
    "                if line.find(f\"{metric}\") != -1:\n",
    "                    # print(float(line.split()[1].rstrip(',')))\n",
    "                    qpn_qc.loc[\n",
    "                        qpn_qc[\"PATNO\"] == subj,\n",
    "                        metric,\n",
    "                    ] = float(line.split()[1].rstrip(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "41d1039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "group1 = qpn_qc\n",
    "group2 = df_qc[df_qc[\"dx_group\"] == \"HC\"]\n",
    "\n",
    "group_qpn_qc = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    group_qpn_qc[f\"t_{metric}\"], group_qpn_qc[f\"p_{metric}\"] = ttest_ind(\n",
    "        group1[f\"{metric}\"], group2[f\"{metric}\"], nan_policy=\"omit\"\n",
    "    )\n",
    "    group_qpn_qc[f\"t_{metric}\"], group_qpn_qc[f\"p_{metric}\"] = ttest_ind(\n",
    "        group1[f\"{metric}\"], group2[f\"{metric}\"], nan_policy=\"omit\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "377dcf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "group1 = qpn_qc\n",
    "group2 = df_qc.loc[df_qc[\"dx_group\"].isin([\"PD-MCI\", \"PD-non-MCI\"])]\n",
    "\n",
    "group_qpn_qc = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    group_qpn_qc[f\"t_{metric}\"], group_qpn_qc[f\"p_{metric}\"] = ttest_ind(\n",
    "        group1[f\"{metric}\"], group2[f\"{metric}\"], nan_policy=\"omit\"\n",
    "    )\n",
    "    group_qpn_qc[f\"t_{metric}\"], group_qpn_qc[f\"p_{metric}\"] = ttest_ind(\n",
    "        group1[f\"{metric}\"], group2[f\"{metric}\"], nan_policy=\"omit\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "42028756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t_cjv': -6.763859688845938,\n",
       " 'p_cjv': 5.316963356736623e-11,\n",
       " 't_cnr': 4.811368912621079,\n",
       " 'p_cnr': 2.192988737860178e-06,\n",
       " 't_fber': -3.0755981046313727,\n",
       " 'p_fber': 0.00225830673151779,\n",
       " 't_qi_1': -3.229634190571152,\n",
       " 'p_qi_1': 0.0013513070439365076,\n",
       " 't_qi_2': 18.811036899561103,\n",
       " 'p_qi_2': 9.413008754289686e-56,\n",
       " 't_rpve_gm': 7.644308068341183,\n",
       " 'p_rpve_gm': 1.8558014247670732e-13,\n",
       " 't_snr_gm': 5.150529912718178,\n",
       " 'p_snr_gm': 4.2477662109811526e-07,\n",
       " 't_snr_total': 7.746357252611505,\n",
       " 'p_snr_total': 9.334384688115598e-14,\n",
       " 't_snrd_gm': 3.5367217299713682,\n",
       " 'p_snrd_gm': 0.00045703848188444304,\n",
       " 't_snrd_total': 3.507188213873324,\n",
       " 'p_snrd_total': 0.0005090260317772093}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_qpn_qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4cb43e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract structural measures\n",
    "\n",
    "qpn_table = QPN\n",
    "\n",
    "ROIs = [\n",
    "    \"Left-Lateral-Ventricle\",\n",
    "    \"Left-Inf-Lat-Vent\",\n",
    "    \"Left-Cerebellum-White-Matter\",\n",
    "    \"Left-Cerebellum-Cortex\",\n",
    "    \"Left-Thalamus\",\n",
    "    \"Left-Caudate\",\n",
    "    \"Left-Putamen\",\n",
    "    \"Left-Pallidum\",\n",
    "    \"3rd-Ventricle\",\n",
    "    \"4th-Ventricle\",\n",
    "    \"Brain-Stem\",\n",
    "    \"Left-Hippocampus\",\n",
    "    \"Left-Amygdala\",\n",
    "    \"CSF\",\n",
    "    \"Left-Accumbens-area\",\n",
    "    \"Left-VentralDC\",\n",
    "    \"Left-vessel\",\n",
    "    \"Left-choroid-plexus\",\n",
    "    \"Right-Lateral-Ventricle\",\n",
    "    \"Right-Inf-Lat-Vent\",\n",
    "    \"Right-Cerebellum-White-Matter\",\n",
    "    \"Right-Cerebellum-Cortex\",\n",
    "    \"Right-Thalamus\",\n",
    "    \"Right-Caudate\",\n",
    "    \"Right-Putamen\",\n",
    "    \"Right-Pallidum\",\n",
    "    \"Right-Hippocampus\",\n",
    "    \"Right-Amygdala\",\n",
    "    \"Right-Accumbens-area\",\n",
    "    \"Right-VentralDC\",\n",
    "    \"Right-vessel\",\n",
    "    \"Right-choroid-plexus\",\n",
    "    \"5th-Ventricle\",\n",
    "    \"Optic-Chiasm\",\n",
    "    \"CC_Posterior\",\n",
    "    \"CC_Mid_Posterior\",\n",
    "    \"CC_Central\",\n",
    "    \"CC_Mid_Anterior\",\n",
    "    \"CC_Anterior\",\n",
    "]\n",
    "\n",
    "ROIs_aparc = [\n",
    "    \"G_and_S_frontomargin\",\n",
    "    \"G_and_S_occipital_inf\",\n",
    "    \"G_and_S_paracentral\",\n",
    "    \"G_and_S_subcentral\",\n",
    "    \"G_and_S_transv_frontopol\",\n",
    "    \"G_and_S_cingul-Ant\",\n",
    "    \"G_and_S_cingul-Mid-Ant\",\n",
    "    \"G_and_S_cingul-Mid-Post\",\n",
    "    \"G_cingul-Post-dorsal\",\n",
    "    \"G_cingul-Post-ventral\",\n",
    "    \"G_cuneus\",\n",
    "    \"G_front_inf-Opercular\",\n",
    "    \"G_front_inf-Orbital\",\n",
    "    \"G_front_inf-Triangul\",\n",
    "    \"G_front_middle\",\n",
    "    \"G_front_sup\",\n",
    "    \"G_Ins_lg_and_S_cent_ins\",\n",
    "    \"G_insular_short\",\n",
    "    \"G_occipital_middle\",\n",
    "    \"G_occipital_sup\",\n",
    "    \"G_oc-temp_lat-fusifor\",\n",
    "    \"G_oc-temp_med-Lingual\",\n",
    "    \"G_oc-temp_med-Parahip\",\n",
    "    \"G_orbital\",\n",
    "    \"G_pariet_inf-Angular\",\n",
    "    \"G_pariet_inf-Supramar\",\n",
    "    \"G_parietal_sup\",\n",
    "    \"G_postcentral\",\n",
    "    \"G_precentral\",\n",
    "    \"G_precuneus\",\n",
    "    \"G_rectus\",\n",
    "    \"G_subcallosal\",\n",
    "    \"G_temp_sup-G_T_transv\",\n",
    "    \"G_temp_sup-Lateral\",\n",
    "    \"G_temp_sup-Plan_polar\",\n",
    "    \"G_temp_sup-Plan_tempo\",\n",
    "    \"G_temporal_inf\",\n",
    "    \"G_temporal_middle\",\n",
    "    \"Lat_Fis-ant-Horizont\",\n",
    "    \"Lat_Fis-ant-Vertical\",\n",
    "    \"Lat_Fis-post\",\n",
    "    \"Pole_occipital\",\n",
    "    \"Pole_temporal\",\n",
    "    \"S_calcarine\",\n",
    "    \"S_central\",\n",
    "    \"S_cingul-Marginalis\",\n",
    "    \"S_circular_insula_ant\",\n",
    "    \"S_circular_insula_inf\",\n",
    "    \"S_circular_insula_sup\",\n",
    "    \"S_collat_transv_ant\",\n",
    "    \"S_collat_transv_post\",\n",
    "    \"S_front_inf\",\n",
    "    \"S_front_middle\",\n",
    "    \"S_front_sup\",\n",
    "    \"S_interm_prim-Jensen\",\n",
    "    \"S_intrapariet_and_P_trans\",\n",
    "    \"S_oc_middle_and_Lunatus\",\n",
    "    \"S_oc_sup_and_transversal\",\n",
    "    \"S_occipital_ant\",\n",
    "    \"S_oc-temp_lat\",\n",
    "    \"S_oc-temp_med_and_Lingual\",\n",
    "    \"S_orbital_lateral\",\n",
    "    \"S_orbital_med-olfact\",\n",
    "    \"S_orbital-H_Shaped\",\n",
    "    \"S_parieto_occipital\",\n",
    "    \"S_pericallosal\",\n",
    "    \"S_postcentral\",\n",
    "    \"S_precentral-inf-part\",\n",
    "    \"S_precentral-sup-part\",\n",
    "    \"S_suborbital\",\n",
    "    \"S_subparietal\",\n",
    "    \"S_temporal_inf\",\n",
    "    \"S_temporal_sup\",\n",
    "    \"S_temporal_transverse\",\n",
    "]\n",
    "\n",
    "# FS 6 has different ROI labels\n",
    "ROIs_aparc_FS6 = [\n",
    "    \"G&S_frontomargin\",\n",
    "    \"G&S_occipital_inf\",\n",
    "    \"G&S_paracentral\",\n",
    "    \"G&S_subcentral\",\n",
    "    \"G&S_transv_frontopol\",\n",
    "    \"G&S_cingul-Ant\",\n",
    "    \"G&S_cingul-Mid-Ant\",\n",
    "    \"G&S_cingul-Mid-Post\",\n",
    "    \"G_Ins_lg&S_cent_ins\",\n",
    "    \"S_intrapariet&P_trans\",\n",
    "    \"S_oc_middle&Lunatus\",\n",
    "    \"S_oc_sup&transversal\",\n",
    "    \"S_oc-temp_med&Lingual\",\n",
    "]\n",
    "\n",
    "for subj in qpn_table[\"PATNO\"]:\n",
    "    for version in [\"FS5\", \"FS6\", \"FS7\"]:\n",
    "        # extract TIV\n",
    "        file = \"qpn/stats/{version}/{subidd}/stats/aseg.stats\".format(\n",
    "            subidd=subj, version=version\n",
    "        )\n",
    "        with open(file, \"r\") as fp:\n",
    "            # read all lines in a list\n",
    "            lines = fp.readlines()\n",
    "            for line in lines:\n",
    "                # check if string present on a current line\n",
    "                if line.find(\"Estimated Total Intracranial Volume\") != -1:\n",
    "                    qpn_table.loc[\n",
    "                        qpn_table[\"PATNO\"] == subj,\n",
    "                        \"TIV_{version}\".format(version=version),\n",
    "                    ] = float(line.split(\",\")[3])\n",
    "\n",
    "                    # aseg_table[\"TIV{ses}\".format(ses = session)] = float(out)\n",
    "\n",
    "        # extract ROIs volume\n",
    "        for roi in ROIs:\n",
    "\n",
    "            file = \"qpn/stats/{version}/{subidd}/stats/aseg.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        qpn_table.loc[\n",
    "                            qpn_table[\"PATNO\"] == subj,\n",
    "                            roi + \"_\" + version,\n",
    "                        ] = float(line.split()[3])\n",
    "        # volumes\n",
    "        # extract cortical lh volumes\n",
    "        for roi in ROIs_aparc:\n",
    "\n",
    "            file = \"qpn/stats/{version}/{subidd}/stats/lh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        qpn_table.loc[\n",
    "                            qpn_table[\"PATNO\"] == subj,\n",
    "                            roi + \"_lh_vol_\" + version,\n",
    "                        ] = float(line.split()[3])\n",
    "\n",
    "        # extract cortical rh volumes\n",
    "        for roi in ROIs_aparc:\n",
    "\n",
    "            file = \"qpn/stats/{version}/{subidd}/stats/rh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        qpn_table.loc[\n",
    "                            qpn_table[\"PATNO\"] == subj,\n",
    "                            roi + \"_rh_vol_\" + version,\n",
    "                        ] = float(line.split()[3])\n",
    "\n",
    "        # surface area\n",
    "        # extract cortical lh surface area\n",
    "        for roi in ROIs_aparc:\n",
    "\n",
    "            file = \"qpn/stats/{version}/{subidd}/stats/lh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        qpn_table.loc[\n",
    "                            qpn_table[\"PATNO\"] == subj,\n",
    "                            roi + \"_lh_surf_\" + version,\n",
    "                        ] = float(line.split()[2])\n",
    "\n",
    "        # extract cortical rh surface area\n",
    "        for roi in ROIs_aparc:\n",
    "\n",
    "            file = \"qpn/stats/{version}/{subidd}/stats/rh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        qpn_table.loc[\n",
    "                            qpn_table[\"PATNO\"] == subj,\n",
    "                            roi + \"_rh_surf_\" + version,\n",
    "                        ] = float(line.split()[2])\n",
    "\n",
    "        # cortical thickness\n",
    "        # extract cortical lh cortical thickness\n",
    "        for roi in ROIs_aparc:\n",
    "\n",
    "            file = \"qpn/stats/{version}/{subidd}/stats/lh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        qpn_table.loc[\n",
    "                            qpn_table[\"PATNO\"] == subj,\n",
    "                            roi + \"_lh_ct_\" + version,\n",
    "                        ] = float(line.split()[4])\n",
    "\n",
    "        # extract cortical rh cortical thickness\n",
    "        for roi in ROIs_aparc:\n",
    "\n",
    "            file = \"qpn/stats/{version}/{subidd}/stats/rh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        qpn_table.loc[\n",
    "                            qpn_table[\"PATNO\"] == subj,\n",
    "                            roi + \"_rh_ct_\" + version,\n",
    "                        ] = float(line.split()[4])\n",
    "\n",
    "\n",
    "for subj in qpn_table[\"PATNO\"]:\n",
    "    for version in [\"FS6\"]:\n",
    "\n",
    "        # extract cortical lh volume\n",
    "        for roi in ROIs_aparc_FS6:\n",
    "\n",
    "            file = \"qpn/stats/{version}/{subidd}/stats/lh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        qpn_table.loc[\n",
    "                            qpn_table[\"PATNO\"] == subj,\n",
    "                            roi + \"_lh_vol_\" + version,\n",
    "                        ] = float(line.split()[3])\n",
    "\n",
    "        # extract cortical rh volume\n",
    "        for roi in ROIs_aparc_FS6:\n",
    "\n",
    "            file = \"qpn/stats/{version}/{subidd}/stats/rh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        qpn_table.loc[\n",
    "                            qpn_table[\"PATNO\"] == subj,\n",
    "                            roi + \"_rh_vol_\" + version,\n",
    "                        ] = float(line.split()[3])\n",
    "\n",
    "        # extract cortical lh surface area\n",
    "        for roi in ROIs_aparc_FS6:\n",
    "\n",
    "            file = \"qpn/stats/{version}/{subidd}/stats/lh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        qpn_table.loc[\n",
    "                            qpn_table[\"PATNO\"] == subj,\n",
    "                            roi + \"_lh_surf_\" + version,\n",
    "                        ] = float(line.split()[2])\n",
    "\n",
    "        # extract cortical rh surface area\n",
    "        for roi in ROIs_aparc_FS6:\n",
    "\n",
    "            file = \"qpn/stats/{version}/{subidd}/stats/rh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        qpn_table.loc[\n",
    "                            qpn_table[\"PATNO\"] == subj,\n",
    "                            roi + \"_rh_surf_\" + version,\n",
    "                        ] = float(line.split()[2])\n",
    "\n",
    "        # extract cortical lh cortical thickness\n",
    "        for roi in ROIs_aparc_FS6:\n",
    "\n",
    "            file = \"qpn/stats/{version}/{subidd}/stats/lh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        qpn_table.loc[\n",
    "                            qpn_table[\"PATNO\"] == subj,\n",
    "                            roi + \"_lh_ct_\" + version,\n",
    "                        ] = float(line.split()[4])\n",
    "\n",
    "        # extract cortical rh cortical thickness\n",
    "        for roi in ROIs_aparc_FS6:\n",
    "\n",
    "            file = \"qpn/stats/{version}/{subidd}/stats/rh.aparc.a2009s.stats\".format(\n",
    "                subidd=subj, version=version\n",
    "            )\n",
    "            with open(file, \"r\") as fp:\n",
    "                lines = fp.readlines()\n",
    "                for line in lines:\n",
    "                    if line.find(roi) != -1:\n",
    "                        qpn_table.loc[\n",
    "                            qpn_table[\"PATNO\"] == subj,\n",
    "                            roi + \"_rh_ct_\" + version,\n",
    "                        ] = float(line.split()[4])\n",
    "\n",
    "# rename FS6 ROIs to match ROI labels in FS5 and 7\n",
    "qpn_table.columns = qpn_table.columns.str.replace(\"&\", \"_and_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "34cb6b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate V2-V1/V1 and take an absolute value\n",
    "\n",
    "ROIs = [\n",
    "    \"Left-Lateral-Ventricle\",\n",
    "    \"Left-Inf-Lat-Vent\",\n",
    "    \"Left-Cerebellum-White-Matter\",\n",
    "    \"Left-Cerebellum-Cortex\",\n",
    "    \"Left-Thalamus\",\n",
    "    \"Left-Caudate\",\n",
    "    \"Left-Putamen\",\n",
    "    \"Left-Pallidum\",\n",
    "    \"3rd-Ventricle\",\n",
    "    \"4th-Ventricle\",\n",
    "    \"Brain-Stem\",\n",
    "    \"Left-Hippocampus\",\n",
    "    \"Left-Amygdala\",\n",
    "    \"CSF\",\n",
    "    \"Left-Accumbens-area\",\n",
    "    \"Left-VentralDC\",\n",
    "    \"Left-vessel\",\n",
    "    \"Left-choroid-plexus\",\n",
    "    \"Right-Lateral-Ventricle\",\n",
    "    \"Right-Inf-Lat-Vent\",\n",
    "    \"Right-Cerebellum-White-Matter\",\n",
    "    \"Right-Cerebellum-Cortex\",\n",
    "    \"Right-Thalamus\",\n",
    "    \"Right-Caudate\",\n",
    "    \"Right-Putamen\",\n",
    "    \"Right-Pallidum\",\n",
    "    \"Right-Hippocampus\",\n",
    "    \"Right-Amygdala\",\n",
    "    \"Right-Accumbens-area\",\n",
    "    \"Right-VentralDC\",\n",
    "    \"Right-vessel\",\n",
    "    \"Right-choroid-plexus\",\n",
    "    \"5th-Ventricle\",\n",
    "    \"Optic-Chiasm\",\n",
    "    \"CC_Posterior\",\n",
    "    \"CC_Mid_Posterior\",\n",
    "    \"CC_Central\",\n",
    "    \"CC_Mid_Anterior\",\n",
    "    \"CC_Anterior\",\n",
    "]\n",
    "\n",
    "ROIs_bil = [\n",
    "    \"G_and_S_frontomargin\",\n",
    "    \"G_and_S_occipital_inf\",\n",
    "    \"G_and_S_paracentral\",\n",
    "    \"G_and_S_subcentral\",\n",
    "    \"G_and_S_transv_frontopol\",\n",
    "    \"G_and_S_cingul-Ant\",\n",
    "    \"G_and_S_cingul-Mid-Ant\",\n",
    "    \"G_and_S_cingul-Mid-Post\",\n",
    "    \"G_cingul-Post-dorsal\",\n",
    "    \"G_cingul-Post-ventral\",\n",
    "    \"G_cuneus\",\n",
    "    \"G_front_inf-Opercular\",\n",
    "    \"G_front_inf-Orbital\",\n",
    "    \"G_front_inf-Triangul\",\n",
    "    \"G_front_middle\",\n",
    "    \"G_front_sup\",\n",
    "    \"G_Ins_lg_and_S_cent_ins\",\n",
    "    \"G_insular_short\",\n",
    "    \"G_occipital_middle\",\n",
    "    \"G_occipital_sup\",\n",
    "    \"G_oc-temp_lat-fusifor\",\n",
    "    \"G_oc-temp_med-Lingual\",\n",
    "    \"G_oc-temp_med-Parahip\",\n",
    "    \"G_orbital\",\n",
    "    \"G_pariet_inf-Angular\",\n",
    "    \"G_pariet_inf-Supramar\",\n",
    "    \"G_parietal_sup\",\n",
    "    \"G_postcentral\",\n",
    "    \"G_precentral\",\n",
    "    \"G_precuneus\",\n",
    "    \"G_rectus\",\n",
    "    \"G_subcallosal\",\n",
    "    \"G_temp_sup-G_T_transv\",\n",
    "    \"G_temp_sup-Lateral\",\n",
    "    \"G_temp_sup-Plan_polar\",\n",
    "    \"G_temp_sup-Plan_tempo\",\n",
    "    \"G_temporal_inf\",\n",
    "    \"G_temporal_middle\",\n",
    "    \"Lat_Fis-ant-Horizont\",\n",
    "    \"Lat_Fis-ant-Vertical\",\n",
    "    \"Lat_Fis-post\",\n",
    "    \"Pole_occipital\",\n",
    "    \"Pole_temporal\",\n",
    "    \"S_calcarine\",\n",
    "    \"S_central\",\n",
    "    \"S_cingul-Marginalis\",\n",
    "    \"S_circular_insula_ant\",\n",
    "    \"S_circular_insula_inf\",\n",
    "    \"S_circular_insula_sup\",\n",
    "    \"S_collat_transv_ant\",\n",
    "    \"S_collat_transv_post\",\n",
    "    \"S_front_inf\",\n",
    "    \"S_front_middle\",\n",
    "    \"S_front_sup\",\n",
    "    \"S_interm_prim-Jensen\",\n",
    "    \"S_intrapariet_and_P_trans\",\n",
    "    \"S_oc_middle_and_Lunatus\",\n",
    "    \"S_oc_sup_and_transversal\",\n",
    "    \"S_occipital_ant\",\n",
    "    \"S_oc-temp_lat\",\n",
    "    \"S_oc-temp_med_and_Lingual\",\n",
    "    \"S_orbital_lateral\",\n",
    "    \"S_orbital_med-olfact\",\n",
    "    \"S_orbital-H_Shaped\",\n",
    "    \"S_parieto_occipital\",\n",
    "    \"S_pericallosal\",\n",
    "    \"S_postcentral\",\n",
    "    \"S_precentral-inf-part\",\n",
    "    \"S_precentral-sup-part\",\n",
    "    \"S_suborbital\",\n",
    "    \"S_subparietal\",\n",
    "    \"S_temporal_inf\",\n",
    "    \"S_temporal_sup\",\n",
    "    \"S_temporal_transverse\",\n",
    "]\n",
    "\n",
    "\n",
    "for roi in ROIs:\n",
    "    for subj in qpn_table[\"PATNO\"]:\n",
    "        # calculate (Vol 2 - Vol 1) / Vol 1\n",
    "        qpn_table[\"FS7_6_pct_{roi}\".format(roi=roi)] = (\n",
    "            (\n",
    "                qpn_table[\"{roi}_FS7\".format(roi=roi)]\n",
    "                - qpn_table[\"{roi}_FS6\".format(roi=roi)]\n",
    "            )\n",
    "            / qpn_table[\"{roi}_FS6\".format(roi=roi)]\n",
    "        ).abs()\n",
    "        qpn_table[\"FS7_5_pct_{roi}\".format(roi=roi)] = (\n",
    "            (\n",
    "                qpn_table[\"{roi}_FS7\".format(roi=roi)]\n",
    "                - qpn_table[\"{roi}_FS5\".format(roi=roi)]\n",
    "            )\n",
    "            / qpn_table[\"{roi}_FS5\".format(roi=roi)]\n",
    "        ).abs()\n",
    "        qpn_table[\"FS6_5_pct_{roi}\".format(roi=roi)] = (\n",
    "            (\n",
    "                qpn_table[\"{roi}_FS6\".format(roi=roi)]\n",
    "                - qpn_table[\"{roi}_FS5\".format(roi=roi)]\n",
    "            )\n",
    "            / qpn_table[\"{roi}_FS5\".format(roi=roi)]\n",
    "        ).abs()\n",
    "\n",
    "for roi in ROIs_bil:\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        for subj in qpn_table[\"PATNO\"]:\n",
    "            for i in [\"vol\", \"surf\", \"ct\"]:\n",
    "                # calculate (Vol 2 - Vol 1) / Vol 1\n",
    "                qpn_table[\n",
    "                    \"FS7_6_pct_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)\n",
    "                ] = (\n",
    "                    (\n",
    "                        qpn_table[\n",
    "                            \"{roi}_{hemi}_{i}_FS7\".format(roi=roi, hemi=hemi, i=i)\n",
    "                        ]\n",
    "                        - qpn_table[\n",
    "                            \"{roi}_{hemi}_{i}_FS6\".format(roi=roi, hemi=hemi, i=i)\n",
    "                        ]\n",
    "                    )\n",
    "                    / qpn_table[\"{roi}_{hemi}_{i}_FS6\".format(roi=roi, hemi=hemi, i=i)]\n",
    "                ).abs()\n",
    "                qpn_table[\n",
    "                    \"FS7_5_pct_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)\n",
    "                ] = (\n",
    "                    (\n",
    "                        qpn_table[\n",
    "                            \"{roi}_{hemi}_{i}_FS7\".format(roi=roi, hemi=hemi, i=i)\n",
    "                        ]\n",
    "                        - qpn_table[\n",
    "                            \"{roi}_{hemi}_{i}_FS5\".format(roi=roi, hemi=hemi, i=i)\n",
    "                        ]\n",
    "                    )\n",
    "                    / qpn_table[\"{roi}_{hemi}_{i}_FS5\".format(roi=roi, hemi=hemi, i=i)]\n",
    "                ).abs()\n",
    "                qpn_table[\n",
    "                    \"FS6_5_pct_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)\n",
    "                ] = (\n",
    "                    (\n",
    "                        qpn_table[\n",
    "                            \"{roi}_{hemi}_{i}_FS6\".format(roi=roi, hemi=hemi, i=i)\n",
    "                        ]\n",
    "                        - qpn_table[\n",
    "                            \"{roi}_{hemi}_{i}_FS5\".format(roi=roi, hemi=hemi, i=i)\n",
    "                        ]\n",
    "                    )\n",
    "                    / qpn_table[\"{roi}_{hemi}_{i}_FS5\".format(roi=roi, hemi=hemi, i=i)]\n",
    "                ).abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e13aa1",
   "metadata": {},
   "source": [
    "## stats - software variability in QPN sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "811f9c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paired t-test\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "t_paired_76 = {}\n",
    "t_paired_75 = {}\n",
    "t_paired_65 = {}\n",
    "\n",
    "for roi in ROIs:\n",
    "    (\n",
    "        t_paired_76[\"t_{roi}\".format(roi=roi)],\n",
    "        t_paired_76[\"p_{roi}\".format(roi=roi)],\n",
    "    ) = stats.ttest_rel(\n",
    "        qpn_table[\"{roi}_FS7\".format(roi=roi)],\n",
    "        qpn_table[\"{roi}_FS6\".format(roi=roi)],\n",
    "        nan_policy=\"omit\",\n",
    "    )\n",
    "    (\n",
    "        t_paired_75[\"t_{roi}\".format(roi=roi)],\n",
    "        t_paired_75[\"p_{roi}\".format(roi=roi)],\n",
    "    ) = stats.ttest_rel(\n",
    "        qpn_table[\"{roi}_FS7\".format(roi=roi)],\n",
    "        qpn_table[\"{roi}_FS5\".format(roi=roi)],\n",
    "        nan_policy=\"omit\",\n",
    "    )\n",
    "    (\n",
    "        t_paired_65[\"t_{roi}\".format(roi=roi)],\n",
    "        t_paired_65[\"p_{roi}\".format(roi=roi)],\n",
    "    ) = stats.ttest_rel(\n",
    "        qpn_table[\"{roi}_FS6\".format(roi=roi)],\n",
    "        qpn_table[\"{roi}_FS5\".format(roi=roi)],\n",
    "        nan_policy=\"omit\",\n",
    "    )\n",
    "\n",
    "for i in [\"vol\", \"surf\", \"ct\"]:\n",
    "    for roi in ROIs_bil:\n",
    "        for hemi in [\"lh\", \"rh\"]:\n",
    "            (\n",
    "                t_paired_76[\"t_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                t_paired_76[\"p_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "            ) = stats.ttest_rel(\n",
    "                qpn_table[\"{roi}_{hemi}_{i}_FS7\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                qpn_table[\"{roi}_{hemi}_{i}_FS6\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "            (\n",
    "                t_paired_75[\"t_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                t_paired_75[\"p_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "            ) = stats.ttest_rel(\n",
    "                qpn_table[\"{roi}_{hemi}_{i}_FS7\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                qpn_table[\"{roi}_{hemi}_{i}_FS5\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "            (\n",
    "                t_paired_65[\"t_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                t_paired_65[\"p_{hemi}_{roi}_{i}\".format(roi=roi, hemi=hemi, i=i)],\n",
    "            ) = stats.ttest_rel(\n",
    "                qpn_table[\"{roi}_{hemi}_{i}_FS6\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                qpn_table[\"{roi}_{hemi}_{i}_FS5\".format(roi=roi, hemi=hemi, i=i)],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "\n",
    "# temp = pd.DataFrame.from_dict(t_paired_76, orient = 'index')\n",
    "# temp.to_csv(\"results_qpn_ttest_paired_76.csv\")\n",
    "# temp = pd.DataFrame.from_dict(t_paired_75, orient = 'index')\n",
    "# temp.to_csv(\"results_qpn_ttest_paired_75.csv\")\n",
    "# temp = pd.DataFrame.from_dict(t_paired_65, orient = 'index')\n",
    "# temp.to_csv(\"results_qpn_ttest_paired_65.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e294bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group differences QPN vs HC\n",
    "\n",
    "group1 = qpn_table\n",
    "group2 = aseg_table[aseg_table[\"dx_group\"] == \"HC\"]\n",
    "\n",
    "t_groups_76 = {}\n",
    "t_groups_75 = {}\n",
    "t_groups_65 = {}\n",
    "\n",
    "for roi in ROIs:\n",
    "    (\n",
    "        t_groups_76[\"t_{roi}\".format(roi=roi)],\n",
    "        t_groups_76[\"p_{roi}\".format(roi=roi)],\n",
    "    ) = ttest_ind(\n",
    "        group1[\"FS7_6_pct_{roi}\".format(roi=roi)],\n",
    "        group2[\"FS7_6_pct_{roi}\".format(roi=roi)],\n",
    "        nan_policy=\"omit\",\n",
    "    )\n",
    "    (\n",
    "        t_groups_75[\"t_{roi}\".format(roi=roi)],\n",
    "        t_groups_75[\"p_{roi}\".format(roi=roi)],\n",
    "    ) = ttest_ind(\n",
    "        group1[\"FS7_5_pct_{roi}\".format(roi=roi)],\n",
    "        group2[\"FS7_5_pct_{roi}\".format(roi=roi)],\n",
    "        nan_policy=\"omit\",\n",
    "    )\n",
    "    (\n",
    "        t_groups_65[\"t_{roi}\".format(roi=roi)],\n",
    "        t_groups_65[\"p_{roi}\".format(roi=roi)],\n",
    "    ) = ttest_ind(\n",
    "        group1[\"FS6_5_pct_{roi}\".format(roi=roi)],\n",
    "        group2[\"FS6_5_pct_{roi}\".format(roi=roi)],\n",
    "        nan_policy=\"omit\",\n",
    "    )\n",
    "\n",
    "for i in [\"vol\", \"surf\", \"ct\"]:\n",
    "    for roi in ROIs_bil:\n",
    "        for hemi in [\"lh\", \"rh\"]:\n",
    "            (\n",
    "                t_groups_76[\"t_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "                t_groups_76[\"p_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "            ) = ttest_ind(\n",
    "                group1[\"FS7_6_pct_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "                group2[\"FS7_6_pct_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "            (\n",
    "                t_groups_75[\"t_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "                t_groups_75[\"p_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "            ) = ttest_ind(\n",
    "                group1[\"FS7_5_pct_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "                group2[\"FS7_5_pct_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "            (\n",
    "                t_groups_65[\"t_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "                t_groups_65[\"p_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "            ) = ttest_ind(\n",
    "                group1[\"FS6_5_pct_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "                group2[\"FS6_5_pct_{hemi}_{roi}_{i}\".format(hemi=hemi, roi=roi, i=i)],\n",
    "                nan_policy=\"omit\",\n",
    "            )\n",
    "\n",
    "\n",
    "# temp = pd.DataFrame.from_dict(t_groups_76, orient = 'index')\n",
    "# temp.to_csv(\"results_qpn_ttest_groups_76.csv\")\n",
    "# temp = pd.DataFrame.from_dict(t_groups_75, orient = 'index')\n",
    "# temp.to_csv(\"results_qpn_ttest_groups_75.csv\")\n",
    "# temp = pd.DataFrame.from_dict(t_groups_65, orient = 'index')\n",
    "# temp.to_csv(\"results_qpn_ttest_groups_65.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94013cc8",
   "metadata": {},
   "source": [
    "## Sørensen–Dice coefficient variability in the replication sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c5fcac64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5401069518716578 % regions differed in volume between FS7 and FS6\n",
      "0.7486631016042781 % regions differed in volume between FS7 and FS5\n",
      "0.7112299465240641 % regions differed in volume between FS6 and FS5\n",
      "0.6554054054054054 % regions differed in surface between FS7 and FS6\n",
      "0.6891891891891891 % regions differed in surface between FS7 and FS5\n",
      "0.668918918918919 % regions differed in surface between FS6 and FS5\n",
      "0.7297297297297297 % regions differed in thickness between FS7 and FS6\n",
      "0.6486486486486487 % regions differed in thickness between FS7 and FS5\n",
      "0.8378378378378378 % regions differed in thickness between FS6 and FS5\n",
      "\n",
      "The Sørensen–Dice coefficients for software variability are:\n",
      " Volume 76 vs 75 = 0.6307053941908713\n",
      " Volume 76 vs 65 = 0.5811965811965812\n",
      " Volume 75 vs 65 = 0.8498168498168498\n",
      " Surface 76 vs 75 = 0.7236180904522613\n",
      " Surface 76 vs 65 = 0.6428571428571429\n",
      " Surface 75 vs 65 = 0.7661691542288557\n",
      " Thickness 76 vs 75 = 0.6862745098039216\n",
      " Thickness 76 vs 65 = 0.8362068965517241\n",
      " Thickness 75 vs 65 = 0.8\n"
     ]
    }
   ],
   "source": [
    "# build sets of significant results\n",
    "\n",
    "set_76_vol = {}\n",
    "set_75_vol = {}\n",
    "set_65_vol = {}\n",
    "set_76_surf = {}\n",
    "set_75_surf = {}\n",
    "set_65_surf = {}\n",
    "set_76_ct = {}\n",
    "set_75_ct = {}\n",
    "set_65_ct = {}\n",
    "\n",
    "for roi in ROIs:\n",
    "    set_76_vol[f\"p_{roi}\"] = t_paired_76[f\"p_{roi}\"] < (0.05 / 187)\n",
    "    set_75_vol[f\"p_{roi}\"] = t_paired_75[f\"p_{roi}\"] < (0.05 / 187)\n",
    "    set_65_vol[f\"p_{roi}\"] = t_paired_65[f\"p_{roi}\"] < (0.05 / 187)\n",
    "\n",
    "for roi in ROIs_bil:\n",
    "    for hemi in [\"lh\", \"rh\"]:\n",
    "        set_76_vol[f\"{hemi}_{roi}_vol\"] = t_paired_76[f\"p_{hemi}_{roi}_vol\"] < (\n",
    "            0.05 / 187\n",
    "        )\n",
    "        set_75_vol[f\"{hemi}_{roi}_vol\"] = t_paired_75[f\"p_{hemi}_{roi}_vol\"] < (\n",
    "            0.05 / 187\n",
    "        )\n",
    "        set_65_vol[f\"{hemi}_{roi}_vol\"] = t_paired_65[f\"p_{hemi}_{roi}_vol\"] < (\n",
    "            0.05 / 187\n",
    "        )\n",
    "\n",
    "        set_76_surf[f\"{hemi}_{roi}_surf\"] = t_paired_76[f\"p_{hemi}_{roi}_surf\"] < (\n",
    "            0.05 / 148\n",
    "        )\n",
    "        set_75_surf[f\"{hemi}_{roi}_surf\"] = t_paired_75[f\"p_{hemi}_{roi}_surf\"] < (\n",
    "            0.05 / 148\n",
    "        )\n",
    "        set_65_surf[f\"{hemi}_{roi}_surf\"] = t_paired_65[f\"p_{hemi}_{roi}_surf\"] < (\n",
    "            0.05 / 148\n",
    "        )\n",
    "\n",
    "        set_76_ct[f\"{hemi}_{roi}_ct\"] = t_paired_76[f\"p_{hemi}_{roi}_ct\"] < (0.05 / 148)\n",
    "        set_75_ct[f\"{hemi}_{roi}_ct\"] = t_paired_75[f\"p_{hemi}_{roi}_ct\"] < (0.05 / 148)\n",
    "        set_65_ct[f\"{hemi}_{roi}_ct\"] = t_paired_65[f\"p_{hemi}_{roi}_ct\"] < (0.05 / 148)\n",
    "\n",
    "set_76_vol = pd.DataFrame.from_dict(set_76_vol, orient=\"index\")\n",
    "set_75_vol = pd.DataFrame.from_dict(set_75_vol, orient=\"index\")\n",
    "set_65_vol = pd.DataFrame.from_dict(set_65_vol, orient=\"index\")\n",
    "\n",
    "set_76_surf = pd.DataFrame.from_dict(set_76_surf, orient=\"index\")\n",
    "set_75_surf = pd.DataFrame.from_dict(set_75_surf, orient=\"index\")\n",
    "set_65_surf = pd.DataFrame.from_dict(set_65_surf, orient=\"index\")\n",
    "\n",
    "set_76_ct = pd.DataFrame.from_dict(set_76_ct, orient=\"index\")\n",
    "set_75_ct = pd.DataFrame.from_dict(set_75_ct, orient=\"index\")\n",
    "set_65_ct = pd.DataFrame.from_dict(set_65_ct, orient=\"index\")\n",
    "\n",
    "set_76_vol = set_76_vol.loc[set_76_vol[0] == True]\n",
    "set_75_vol = set_75_vol.loc[set_75_vol[0] == True]\n",
    "set_65_vol = set_65_vol.loc[set_65_vol[0] == True]\n",
    "set_76_surf = set_76_surf.loc[set_76_surf[0] == True]\n",
    "set_75_surf = set_75_surf.loc[set_75_surf[0] == True]\n",
    "set_65_surf = set_65_surf.loc[set_65_surf[0] == True]\n",
    "set_76_ct = set_76_ct.loc[set_76_ct[0] == True]\n",
    "set_75_ct = set_75_ct.loc[set_75_ct[0] == True]\n",
    "set_65_ct = set_65_ct.loc[set_65_ct[0] == True]\n",
    "\n",
    "\n",
    "# calculate intersection between the sets\n",
    "\n",
    "set_76_75_vol_inter = set_76_vol.index.intersection(set_75_vol.index)\n",
    "set_76_65_vol_inter = set_76_vol.index.intersection(set_65_vol.index)\n",
    "set_75_65_vol_inter = set_75_vol.index.intersection(set_65_vol.index)\n",
    "\n",
    "set_76_75_surf_inter = set_76_surf.index.intersection(set_75_surf.index)\n",
    "set_76_65_surf_inter = set_76_surf.index.intersection(set_65_surf.index)\n",
    "set_75_65_surf_inter = set_75_surf.index.intersection(set_65_surf.index)\n",
    "\n",
    "set_76_75_ct_inter = set_76_ct.index.intersection(set_75_ct.index)\n",
    "set_76_65_ct_inter = set_76_ct.index.intersection(set_65_ct.index)\n",
    "set_75_65_ct_inter = set_75_ct.index.intersection(set_65_ct.index)\n",
    "\n",
    "\n",
    "# calculate coefficients\n",
    "\n",
    "dice_76_75_vol = (2 * len(set_76_75_vol_inter)) / (len(set_76_vol) + len(set_75_vol))\n",
    "dice_76_65_vol = (2 * len(set_76_65_vol_inter)) / (len(set_76_vol) + len(set_65_vol))\n",
    "dice_75_65_vol = (2 * len(set_75_65_vol_inter)) / (len(set_75_vol) + len(set_65_vol))\n",
    "\n",
    "dice_76_75_surf = (2 * len(set_76_75_surf_inter)) / (\n",
    "    len(set_76_surf) + len(set_75_surf)\n",
    ")\n",
    "dice_76_65_surf = (2 * len(set_76_65_surf_inter)) / (\n",
    "    len(set_76_surf) + len(set_65_surf)\n",
    ")\n",
    "dice_75_65_surf = (2 * len(set_75_65_surf_inter)) / (\n",
    "    len(set_75_surf) + len(set_65_surf)\n",
    ")\n",
    "\n",
    "dice_76_75_ct = (2 * len(set_76_75_ct_inter)) / (len(set_76_ct) + len(set_75_ct))\n",
    "dice_76_65_ct = (2 * len(set_76_65_ct_inter)) / (len(set_76_ct) + len(set_65_ct))\n",
    "dice_75_65_ct = (2 * len(set_75_65_ct_inter)) / (len(set_75_ct) + len(set_65_ct))\n",
    "\n",
    "\n",
    "print(\n",
    "    str(len(set_76_vol) / 187)\n",
    "    + \" % regions differed in volume between FS7 and FS6\\n\"\n",
    "    + str(len(set_75_vol) / 187)\n",
    "    + \" % regions differed in volume between FS7 and FS5\\n\"\n",
    "    + str(len(set_65_vol) / 187)\n",
    "    + \" % regions differed in volume between FS6 and FS5\\n\"\n",
    "    + str(len(set_76_surf) / 148)\n",
    "    + \" % regions differed in surface between FS7 and FS6\\n\"\n",
    "    + str(len(set_75_surf) / 148)\n",
    "    + \" % regions differed in surface between FS7 and FS5\\n\"\n",
    "    + str(len(set_65_surf) / 148)\n",
    "    + \" % regions differed in surface between FS6 and FS5\\n\"\n",
    "    + str(len(set_76_ct) / 148)\n",
    "    + \" % regions differed in thickness between FS7 and FS6\\n\"\n",
    "    + str(len(set_75_ct) / 148)\n",
    "    + \" % regions differed in thickness between FS7 and FS5\\n\"\n",
    "    + str(len(set_65_ct) / 148)\n",
    "    + \" % regions differed in thickness between FS6 and FS5\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "    \"The Sørensen–Dice coefficients for software variability are:\\n Volume 76 vs 75 = \"\n",
    "    + str(dice_76_75_vol)\n",
    "    + \"\\n Volume 76 vs 65 = \"\n",
    "    + str(dice_76_65_vol)\n",
    "    + \"\\n Volume 75 vs 65 = \"\n",
    "    + str(dice_75_65_vol)\n",
    "    + \"\\n Surface 76 vs 75 = \"\n",
    "    + str(dice_76_75_surf)\n",
    "    + \"\\n Surface 76 vs 65 = \"\n",
    "    + str(dice_76_65_surf)\n",
    "    + \"\\n Surface 75 vs 65 = \"\n",
    "    + str(dice_75_65_surf)\n",
    "    + \"\\n Thickness 76 vs 75 = \"\n",
    "    + str(dice_76_75_ct)\n",
    "    + \"\\n Thickness 76 vs 65 = \"\n",
    "    + str(dice_76_65_ct)\n",
    "    + \"\\n Thickness 75 vs 65 = \"\n",
    "    + str(dice_75_65_ct)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d3fbb9",
   "metadata": {},
   "source": [
    "## Correlation between MRIQC and software variability - QPN sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "12772568",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    \"cjv\",\n",
    "    \"cnr\",\n",
    "    \"fber\",\n",
    "    \"qi_1\",\n",
    "    \"qi_2\",\n",
    "    \"rpve_gm\",\n",
    "    \"snr_gm\",\n",
    "    \"snr_total\",\n",
    "    \"snrd_gm\",\n",
    "    \"snrd_total\",\n",
    "]\n",
    "\n",
    "qc_table = qpn_qc\n",
    "\n",
    "qc_corr_76 = {}\n",
    "qc_corr_75 = {}\n",
    "qc_corr_65 = {}\n",
    "\n",
    "for i in [\"vol\", \"surf\", \"ct\"]:\n",
    "    for roi in ROIs_bil:\n",
    "        for hemi in [\"lh\", \"rh\"]:\n",
    "            for m in metrics:\n",
    "                qc_table_stat = qc_table.dropna(subset=f\"FS7_6_pct_{hemi}_{roi}_{i}\")\n",
    "                qc_table_stat = qc_table_stat.dropna(subset=f\"{m}\")\n",
    "                (\n",
    "                    qc_corr_76[f\"r_{hemi}_{roi}_{i}_{m}\"],\n",
    "                    qc_corr_76[f\"p_{hemi}_{roi}_{i}_{m}\"],\n",
    "                ) = correlation(qc_table_stat, f\"FS7_6_pct_{hemi}_{roi}_{i}\", f\"{m}\")\n",
    "\n",
    "                qc_table_stat = qc_table.dropna(subset=f\"FS7_5_pct_{hemi}_{roi}_{i}\")\n",
    "                qc_table_stat = qc_table_stat.dropna(subset=f\"{m}\")\n",
    "                (\n",
    "                    qc_corr_75[f\"r_{hemi}_{roi}_{i}_{m}\"],\n",
    "                    qc_corr_75[f\"p_{hemi}_{roi}_{i}_{m}\"],\n",
    "                ) = correlation(qc_table_stat, f\"FS7_5_pct_{hemi}_{roi}_{i}\", f\"{m}\")\n",
    "\n",
    "                qc_table_stat = qc_table.dropna(subset=f\"FS6_5_pct_{hemi}_{roi}_{i}\")\n",
    "                qc_table_stat = qc_table_stat.dropna(subset=f\"{m}\")\n",
    "                (\n",
    "                    qc_corr_65[f\"r_{hemi}_{roi}_{i}_{m}\"],\n",
    "                    qc_corr_65[f\"p_{hemi}_{roi}_{i}_{m}\"],\n",
    "                ) = correlation(qc_table_stat, f\"FS6_5_pct_{hemi}_{roi}_{i}\", f\"{m}\")\n",
    "\n",
    "for roi in ROIs:\n",
    "    for m in metrics:\n",
    "        qc_table_stat = qc_table.replace(np.inf, np.nan)\n",
    "        qc_table_stat = qc_table_stat.dropna(subset=f\"FS7_6_pct_{roi}\")\n",
    "        qc_table_stat = qc_table_stat.dropna(subset=f\"{m}\")\n",
    "        qc_corr_76[f\"r_{roi}_{m}\"], qc_corr_76[f\"p_{roi}_{m}\"] = correlation(\n",
    "            qc_table_stat, f\"FS7_6_pct_{roi}\", f\"{m}\"\n",
    "        )\n",
    "\n",
    "        qc_table_stat = qc_table.replace(np.inf, np.nan)\n",
    "        qc_table_stat = qc_table_stat.dropna(subset=f\"FS7_5_pct_{roi}\")\n",
    "        qc_table_stat = qc_table_stat.dropna(subset=f\"{m}\")\n",
    "        qc_corr_75[f\"r_{roi}_{m}\"], qc_corr_75[f\"p_{roi}_{m}\"] = correlation(\n",
    "            qc_table_stat, f\"FS7_5_pct_{roi}\", f\"{m}\"\n",
    "        )\n",
    "\n",
    "        qc_table_stat = qc_table.replace(np.inf, np.nan)\n",
    "        qc_table_stat = qc_table_stat.dropna(subset=f\"FS6_5_pct_{roi}\")\n",
    "        qc_table_stat = qc_table_stat.dropna(subset=f\"{m}\")\n",
    "        qc_corr_65[f\"r_{roi}_{m}\"], qc_corr_65[f\"p_{roi}_{m}\"] = correlation(\n",
    "            qc_table_stat, f\"FS6_5_pct_{roi}\", f\"{m}\"\n",
    "        )\n",
    "\n",
    "# temp = pd.DataFrame.from_dict(qc_corr_76, orient = 'index')\n",
    "# temp.to_csv(\"qc_qpn_corr_76.csv\")\n",
    "# temp = pd.DataFrame.from_dict(qc_corr_75, orient = 'index')\n",
    "# temp.to_csv(\"qc_qpn_corr_75.csv\")\n",
    "# temp = pd.DataFrame.from_dict(qc_corr_65, orient = 'index')\n",
    "# temp.to_csv(\"qc_qpn_corr_65.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94e43dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
